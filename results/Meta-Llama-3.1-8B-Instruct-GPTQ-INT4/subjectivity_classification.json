[
  {
    "sample_idx": 0,
    "sentence": "Blanco established himself earlier in his career working for Dr. Luke's Kasz Money Productions.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.028319576755166054
          ]
        ],
        "inference_time": 2.0172929763793945
      },
      {
        "repetition": 1,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.025518056005239487
          ]
        ],
        "inference_time": 1.7516505718231201
      },
      {
        "repetition": 2,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.07082558423280716
          ]
        ],
        "inference_time": 1.7491204738616943
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.43385928869247437
          ]
        ],
        "inference_time": 1.7496743202209473
      },
      {
        "repetition": 4,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.07082558423280716
          ]
        ],
        "inference_time": 1.751342535018921
      },
      {
        "repetition": 5,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.07082558423280716
          ]
        ],
        "inference_time": 1.7536532878875732
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.43385928869247437
          ]
        ],
        "inference_time": 1.753237247467041
      },
      {
        "repetition": 7,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.14532466232776642
          ]
        ],
        "inference_time": 1.7561955451965332
      },
      {
        "repetition": 8,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.07082558423280716
          ]
        ],
        "inference_time": 1.7567620277404785
      },
      {
        "repetition": 9,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.14532466232776642
          ]
        ],
        "inference_time": 1.7588400840759277
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 1,
    "sentence": "RULE 13: ARTIFICIAL INTELLIGENCE  Not only this, but Gina also created an AI model of herself to achieve immortality.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.09805067628622055
          ]
        ],
        "inference_time": 1.7612240314483643
      },
      {
        "repetition": 1,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.014125538058578968
          ]
        ],
        "inference_time": 1.7630727291107178
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.2637673318386078
          ]
        ],
        "inference_time": 1.7618141174316406
      },
      {
        "repetition": 3,
        "generated_text": " 1",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "1",
            0.011232568882405758
          ]
        ],
        "inference_time": 1.7595489025115967
      },
      {
        "repetition": 4,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "70",
            0.015353099443018436
          ]
        ],
        "inference_time": 1.7620339393615723
      },
      {
        "repetition": 5,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.09805067628622055
          ]
        ],
        "inference_time": 1.7629833221435547
      },
      {
        "repetition": 6,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.06738918274641037
          ]
        ],
        "inference_time": 1.7654774188995361
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.2637673318386078
          ]
        ],
        "inference_time": 1.7639856338500977
      },
      {
        "repetition": 8,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.06738918274641037
          ]
        ],
        "inference_time": 1.763915777206421
      },
      {
        "repetition": 9,
        "generated_text": " 4",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "4",
            0.01233656331896782
          ]
        ],
        "inference_time": 1.7657268047332764
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 2,
    "sentence": "The valuation is required by law and the figure is assessed independently by a pension specialist and has been reviewed by the National Audit Office.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 12",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "12",
            0.0127424830570817
          ]
        ],
        "inference_time": 1.7663724422454834
      },
      {
        "repetition": 1,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.1504591405391693
          ]
        ],
        "inference_time": 1.7645440101623535
      },
      {
        "repetition": 2,
        "generated_text": " 7",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "7",
            0.010027771815657616
          ]
        ],
        "inference_time": 1.7650504112243652
      },
      {
        "repetition": 3,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.027832139283418655
          ]
        ],
        "inference_time": 1.7647788524627686
      },
      {
        "repetition": 4,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.09125807881355286
          ]
        ],
        "inference_time": 1.7675511837005615
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4089903235435486
          ]
        ],
        "inference_time": 1.7659990787506104
      },
      {
        "repetition": 6,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.09125807881355286
          ]
        ],
        "inference_time": 1.7652933597564697
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4089903235435486
          ]
        ],
        "inference_time": 1.76908540725708
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4089903235435486
          ]
        ],
        "inference_time": 1.7692055702209473
      },
      {
        "repetition": 9,
        "generated_text": " 3",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "3",
            0.016361672431230545
          ]
        ],
        "inference_time": 1.7691388130187988
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 3,
    "sentence": "A sip can really hit the spot after a long bike ride or a walk.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11871856451034546
          ]
        ],
        "inference_time": 1.767296552658081
      },
      {
        "repetition": 1,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.02084621973335743
          ]
        ],
        "inference_time": 1.768570899963379
      },
      {
        "repetition": 2,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11871856451034546
          ]
        ],
        "inference_time": 1.7684409618377686
      },
      {
        "repetition": 3,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.022895094007253647
          ]
        ],
        "inference_time": 1.7681963443756104
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.14320191740989685
          ]
        ],
        "inference_time": 1.770129680633545
      },
      {
        "repetition": 5,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.08418405801057816
          ]
        ],
        "inference_time": 1.770439863204956
      },
      {
        "repetition": 6,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.02084621973335743
          ]
        ],
        "inference_time": 1.769299030303955
      },
      {
        "repetition": 7,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "60",
            0.02219068631529808
          ]
        ],
        "inference_time": 1.7699148654937744
      },
      {
        "repetition": 8,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.022657835856080055
          ]
        ],
        "inference_time": 1.77134108543396
      },
      {
        "repetition": 9,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11871856451034546
          ]
        ],
        "inference_time": 1.771043062210083
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 4,
    "sentence": "Lobster!\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9640209674835205
          ],
          [
            "80",
            0.012948860414326191
          ]
        ],
        "inference_time": 1.7428371906280518
      },
      {
        "repetition": 1,
        "generated_text": "  ",
        "token_probs": [
          [
            " ",
            0.9640209674835205
          ],
          [
            " ",
            0.020692219957709312
          ]
        ],
        "inference_time": 1.7387287616729736
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9640209674835205
          ],
          [
            "0",
            0.5621910095214844
          ]
        ],
        "inference_time": 1.7413256168365479
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9640209674835205
          ],
          [
            "0",
            0.5621910095214844
          ]
        ],
        "inference_time": 1.7398548126220703
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9640209674835205
          ],
          [
            "0",
            0.5621910095214844
          ]
        ],
        "inference_time": 1.7393758296966553
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9640209674835205
          ],
          [
            "0",
            0.5621910095214844
          ]
        ],
        "inference_time": 1.7402944564819336
      },
      {
        "repetition": 6,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9640209674835205
          ],
          [
            "20",
            0.033066071569919586
          ]
        ],
        "inference_time": 1.7426338195800781
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9640209674835205
          ],
          [
            "0",
            0.5621910095214844
          ]
        ],
        "inference_time": 1.7398369312286377
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9640209674835205
          ],
          [
            "0",
            0.5621910095214844
          ]
        ],
        "inference_time": 1.7410285472869873
      },
      {
        "repetition": 9,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            0.9640209674835205
          ],
          [
            "60",
            0.010190182365477085
          ]
        ],
        "inference_time": 1.741825819015503
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 5,
    "sentence": "But this is precisely the reason why Labour must reject the austerian urges that, inevitably, spring from the credit card analogy.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "95",
            0.1070142462849617
          ]
        ],
        "inference_time": 1.7735767364501953
      },
      {
        "repetition": 1,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "70",
            0.04554932937026024
          ]
        ],
        "inference_time": 1.776595115661621
      },
      {
        "repetition": 2,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.05494298040866852
          ]
        ],
        "inference_time": 1.7743470668792725
      },
      {
        "repetition": 3,
        "generated_text": " 99",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "99",
            0.018791016191244125
          ]
        ],
        "inference_time": 1.7790076732635498
      },
      {
        "repetition": 4,
        "generated_text": " 82",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "82",
            0.014184203930199146
          ]
        ],
        "inference_time": 1.7783987522125244
      },
      {
        "repetition": 5,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.14475546777248383
          ]
        ],
        "inference_time": 1.7746753692626953
      },
      {
        "repetition": 6,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.130435511469841
          ]
        ],
        "inference_time": 1.7751147747039795
      },
      {
        "repetition": 7,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.14475546777248383
          ]
        ],
        "inference_time": 1.7773411273956299
      },
      {
        "repetition": 8,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "40",
            0.00838200282305479
          ]
        ],
        "inference_time": 1.7761118412017822
      },
      {
        "repetition": 9,
        "generated_text": " 87",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "87",
            0.023385798558592796
          ]
        ],
        "inference_time": 1.776602029800415
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 6,
    "sentence": "Googled how to cook a good lobster and I read how hard it is to get it good because it can turn very tough, rubbery.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.056027911603450775
          ]
        ],
        "inference_time": 1.7772915363311768
      },
      {
        "repetition": 1,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "70",
            0.027880655601620674
          ]
        ],
        "inference_time": 1.776167392730713
      },
      {
        "repetition": 2,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.12495242059230804
          ]
        ],
        "inference_time": 1.775217056274414
      },
      {
        "repetition": 3,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.03693586587905884
          ]
        ],
        "inference_time": 1.7751483917236328
      },
      {
        "repetition": 4,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.12495242059230804
          ]
        ],
        "inference_time": 1.777770757675171
      },
      {
        "repetition": 5,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.025385625660419464
          ]
        ],
        "inference_time": 1.7766928672790527
      },
      {
        "repetition": 6,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "70",
            0.027880655601620674
          ]
        ],
        "inference_time": 1.7768666744232178
      },
      {
        "repetition": 7,
        "generated_text": "  ",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            " ",
            0.012116885744035244
          ]
        ],
        "inference_time": 1.7782232761383057
      },
      {
        "repetition": 8,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.03693586587905884
          ]
        ],
        "inference_time": 1.7774460315704346
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.10912740975618362
          ]
        ],
        "inference_time": 1.775888204574585
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 7,
    "sentence": "Apartments cost from \u00a3392 per week to rent, which makes it more expensive than an average room in first-year halls (a single room without bathroom typically costs \u00a3250 per week) but more affordable than a lot of the postgraduate accommodation on offer.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.32607245445251465
          ]
        ],
        "inference_time": 1.780325174331665
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.32607245445251465
          ]
        ],
        "inference_time": 1.7802958488464355
      },
      {
        "repetition": 2,
        "generated_text": " 12",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "12",
            0.015571660362184048
          ]
        ],
        "inference_time": 1.7795205116271973
      },
      {
        "repetition": 3,
        "generated_text": " 8",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "8",
            0.022189509123563766
          ]
        ],
        "inference_time": 1.781106948852539
      },
      {
        "repetition": 4,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.15891502797603607
          ]
        ],
        "inference_time": 1.781484603881836
      },
      {
        "repetition": 5,
        "generated_text": " 12",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "12",
            0.015571660362184048
          ]
        ],
        "inference_time": 1.7790889739990234
      },
      {
        "repetition": 6,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.10367754846811295
          ]
        ],
        "inference_time": 1.7802236080169678
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.32607245445251465
          ]
        ],
        "inference_time": 1.7807588577270508
      },
      {
        "repetition": 8,
        "generated_text": " 8",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "8",
            0.022189509123563766
          ]
        ],
        "inference_time": 1.780898094177246
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.32607245445251465
          ]
        ],
        "inference_time": 1.7788023948669434
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 8,
    "sentence": "We apologise to TikTok for not approaching it for comment prior to publication.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 4",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "4",
            0.020143069326877594
          ]
        ],
        "inference_time": 1.7740509510040283
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3880729377269745
          ]
        ],
        "inference_time": 1.7738862037658691
      },
      {
        "repetition": 2,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.07562419772148132
          ]
        ],
        "inference_time": 1.7746529579162598
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3880729377269745
          ]
        ],
        "inference_time": 1.777390480041504
      },
      {
        "repetition": 4,
        "generated_text": "  ",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            " ",
            0.010894699022173882
          ]
        ],
        "inference_time": 1.774332046508789
      },
      {
        "repetition": 5,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.04539310559630394
          ]
        ],
        "inference_time": 1.7738242149353027
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3880729377269745
          ]
        ],
        "inference_time": 1.7790489196777344
      },
      {
        "repetition": 7,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.026408694684505463
          ]
        ],
        "inference_time": 1.7776823043823242
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3880729377269745
          ]
        ],
        "inference_time": 1.7776896953582764
      },
      {
        "repetition": 9,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.12730811536312103
          ]
        ],
        "inference_time": 1.7777118682861328
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 9,
    "sentence": "Crumbling parliament patched up with a few fig leaves  Parliament gained some new residents yesterday, and there are already questions as to their expenses.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9056892395019531
          ],
          [
            "50",
            0.11937220394611359
          ]
        ],
        "inference_time": 1.7797365188598633
      },
      {
        "repetition": 1,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9056892395019531
          ],
          [
            "75",
            0.036787692457437515
          ]
        ],
        "inference_time": 1.7774949073791504
      },
      {
        "repetition": 2,
        "generated_text": "? \n\n\n\n",
        "token_probs": [
          [
            "?",
            0.013398666866123676
          ],
          [
            " \n\n\n\n",
            0.011201589368283749
          ]
        ],
        "inference_time": 1.7798113822937012
      },
      {
        "repetition": 3,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9056892395019531
          ],
          [
            "20",
            0.13668285310268402
          ]
        ],
        "inference_time": 1.7812912464141846
      },
      {
        "repetition": 4,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            0.9056892395019531
          ],
          [
            "10",
            0.035655856132507324
          ]
        ],
        "inference_time": 1.779764175415039
      },
      {
        "repetition": 5,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9056892395019531
          ],
          [
            "75",
            0.036787692457437515
          ]
        ],
        "inference_time": 1.7807331085205078
      },
      {
        "repetition": 6,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.9056892395019531
          ],
          [
            "25",
            0.0731610655784607
          ]
        ],
        "inference_time": 1.7796299457550049
      },
      {
        "repetition": 7,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.9056892395019531
          ],
          [
            "25",
            0.0731610655784607
          ]
        ],
        "inference_time": 1.7792036533355713
      },
      {
        "repetition": 8,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9056892395019531
          ],
          [
            "75",
            0.036787692457437515
          ]
        ],
        "inference_time": 1.7749340534210205
      },
      {
        "repetition": 9,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9056892395019531
          ],
          [
            "20",
            0.13668285310268402
          ]
        ],
        "inference_time": 1.7658793926239014
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 10,
    "sentence": "In 2019, he bagged a role in the ensemble movie Berlin, I Love You - which was labelled a 'empty, boring flop' by The Observer.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.08834806084632874
          ]
        ],
        "inference_time": 1.7660129070281982
      },
      {
        "repetition": 1,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.08834806084632874
          ]
        ],
        "inference_time": 1.767409324645996
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.10328935831785202
          ]
        ],
        "inference_time": 1.7652084827423096
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.10328935831785202
          ]
        ],
        "inference_time": 1.765763282775879
      },
      {
        "repetition": 4,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "40",
            0.03760429844260216
          ]
        ],
        "inference_time": 1.7662785053253174
      },
      {
        "repetition": 5,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.04778450354933739
          ]
        ],
        "inference_time": 1.7647502422332764
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.10328935831785202
          ]
        ],
        "inference_time": 1.7658629417419434
      },
      {
        "repetition": 7,
        "generated_text": " 26",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "26",
            0.007176906336098909
          ]
        ],
        "inference_time": 1.766545057296753
      },
      {
        "repetition": 8,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.12202200293540955
          ]
        ],
        "inference_time": 1.7665083408355713
      },
      {
        "repetition": 9,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.15997768938541412
          ]
        ],
        "inference_time": 1.767073392868042
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 11,
    "sentence": "By the way, she is honestly the best cook.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.13007628917694092
          ]
        ],
        "inference_time": 1.7318394184112549
      },
      {
        "repetition": 1,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "100",
            0.18729878962039948
          ]
        ],
        "inference_time": 1.7320563793182373
      },
      {
        "repetition": 2,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.09033619612455368
          ]
        ],
        "inference_time": 1.7325172424316406
      },
      {
        "repetition": 3,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.12219537794589996
          ]
        ],
        "inference_time": 1.7319388389587402
      },
      {
        "repetition": 4,
        "generated_text": " 99",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "99",
            0.008851802907884121
          ]
        ],
        "inference_time": 1.7319517135620117
      },
      {
        "repetition": 5,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "100",
            0.18729878962039948
          ]
        ],
        "inference_time": 1.7322273254394531
      },
      {
        "repetition": 6,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.12219537794589996
          ]
        ],
        "inference_time": 1.7308125495910645
      },
      {
        "repetition": 7,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.12219537794589996
          ]
        ],
        "inference_time": 1.7316038608551025
      },
      {
        "repetition": 8,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.13007628917694092
          ]
        ],
        "inference_time": 1.732027292251587
      },
      {
        "repetition": 9,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "85",
            0.029634974896907806
          ]
        ],
        "inference_time": 1.7311592102050781
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 12,
    "sentence": "Families are doubling down on calls for perpetrators to be brought to justice, and say changes on the handling of femicide cases are necessary.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.8709211349487305
          ],
          [
            "20",
            0.19409088790416718
          ]
        ],
        "inference_time": 1.7626619338989258
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.8709211349487305
          ],
          [
            "0",
            0.07521943002939224
          ]
        ],
        "inference_time": 1.7651045322418213
      },
      {
        "repetition": 2,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            0.8709211349487305
          ],
          [
            "10",
            0.04562288895249367
          ]
        ],
        "inference_time": 1.764869213104248
      },
      {
        "repetition": 3,
        "generated_text": " 45",
        "token_probs": [
          [
            " ",
            0.8709211349487305
          ],
          [
            "45",
            0.008983679115772247
          ]
        ],
        "inference_time": 1.7645313739776611
      },
      {
        "repetition": 4,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.8709211349487305
          ],
          [
            "20",
            0.19409088790416718
          ]
        ],
        "inference_time": 1.7635364532470703
      },
      {
        "repetition": 5,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            0.8709211349487305
          ],
          [
            "40",
            0.06848806887865067
          ]
        ],
        "inference_time": 1.764486312866211
      },
      {
        "repetition": 6,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.8709211349487305
          ],
          [
            "25",
            0.06569307297468185
          ]
        ],
        "inference_time": 1.7622742652893066
      },
      {
        "repetition": 7,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.8709211349487305
          ],
          [
            "20",
            0.19409088790416718
          ]
        ],
        "inference_time": 1.7651019096374512
      },
      {
        "repetition": 8,
        "generated_text": " \n45",
        "token_probs": [
          [
            " \n",
            0.017702722921967506
          ],
          [
            "45",
            0.0371660515666008
          ]
        ],
        "inference_time": 1.7660536766052246
      },
      {
        "repetition": 9,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            0.8709211349487305
          ],
          [
            "40",
            0.06848806887865067
          ]
        ],
        "inference_time": 1.7656450271606445
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 13,
    "sentence": "Anything we can actually do, we can afford.\u201d Britain\u2019s conundrum, today, is that the next government, whose job will be to fix the Tories\u2019 mess, is led by politicians who share neither Keynes\u2019s aims nor his innovative approach to public finance.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            0.9737088680267334
          ],
          [
            "40",
            0.02627718262374401
          ]
        ],
        "inference_time": 1.7674660682678223
      },
      {
        "repetition": 1,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            0.9737088680267334
          ],
          [
            "85",
            0.05335858464241028
          ]
        ],
        "inference_time": 1.7681808471679688
      },
      {
        "repetition": 2,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9737088680267334
          ],
          [
            "50",
            0.10392826795578003
          ]
        ],
        "inference_time": 1.7687559127807617
      },
      {
        "repetition": 3,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            0.9737088680267334
          ],
          [
            "30",
            0.01679002307355404
          ]
        ],
        "inference_time": 1.7679553031921387
      },
      {
        "repetition": 4,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9737088680267334
          ],
          [
            "75",
            0.06046319752931595
          ]
        ],
        "inference_time": 1.7676844596862793
      },
      {
        "repetition": 5,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            0.9737088680267334
          ],
          [
            "85",
            0.05335858464241028
          ]
        ],
        "inference_time": 1.7678229808807373
      },
      {
        "repetition": 6,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            0.9737088680267334
          ],
          [
            "95",
            0.04516705498099327
          ]
        ],
        "inference_time": 1.7676572799682617
      },
      {
        "repetition": 7,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9737088680267334
          ],
          [
            "80",
            0.19215165078639984
          ]
        ],
        "inference_time": 1.7683968544006348
      },
      {
        "repetition": 8,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9737088680267334
          ],
          [
            "90",
            0.09968696534633636
          ]
        ],
        "inference_time": 1.7692747116088867
      },
      {
        "repetition": 9,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            0.9737088680267334
          ],
          [
            "60",
            0.0636957511305809
          ]
        ],
        "inference_time": 1.7678148746490479
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 14,
    "sentence": "\u201cI just believe in being the best version of myself that I can possibly be, it makes me feel good.\u201d  Read more real life stories  Not only does Gina swear by hydration - but she also has 13 other rules she sticks to like glue.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "95",
            0.03379816561937332
          ]
        ],
        "inference_time": 1.7691011428833008
      },
      {
        "repetition": 1,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.03750872239470482
          ]
        ],
        "inference_time": 1.7685809135437012
      },
      {
        "repetition": 2,
        "generated_text": " 67",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "67",
            0.016132300719618797
          ]
        ],
        "inference_time": 1.7680270671844482
      },
      {
        "repetition": 3,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.11920247226953506
          ]
        ],
        "inference_time": 1.770524263381958
      },
      {
        "repetition": 4,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "70",
            0.054574865847826004
          ]
        ],
        "inference_time": 1.767751693725586
      },
      {
        "repetition": 5,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.11920247226953506
          ]
        ],
        "inference_time": 1.767913818359375
      },
      {
        "repetition": 6,
        "generated_text": " 86",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "86",
            0.0071214791387319565
          ]
        ],
        "inference_time": 1.7692570686340332
      },
      {
        "repetition": 7,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.1612420231103897
          ]
        ],
        "inference_time": 1.7687251567840576
      },
      {
        "repetition": 8,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "100",
            0.03175043687224388
          ]
        ],
        "inference_time": 1.768972396850586
      },
      {
        "repetition": 9,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.11920247226953506
          ]
        ],
        "inference_time": 1.7692646980285645
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 15,
    "sentence": "\u201cRussia\u2019s dominance in the Black Sea is now challenged.\u201d  The Boxing Day blast saw Vlad's valuable landing ship - docked in Crimea - turned into a raging fireball.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9691058993339539
          ],
          [
            "50",
            0.21168909966945648
          ]
        ],
        "inference_time": 1.767667293548584
      },
      {
        "repetition": 1,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            0.9691058993339539
          ],
          [
            "95",
            0.008424638770520687
          ]
        ],
        "inference_time": 1.7682163715362549
      },
      {
        "repetition": 2,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9691058993339539
          ],
          [
            "50",
            0.21168909966945648
          ]
        ],
        "inference_time": 1.7691478729248047
      },
      {
        "repetition": 3,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9691058993339539
          ],
          [
            "50",
            0.21168909966945648
          ]
        ],
        "inference_time": 1.7679696083068848
      },
      {
        "repetition": 4,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.9691058993339539
          ],
          [
            "25",
            0.05187664553523064
          ]
        ],
        "inference_time": 1.767730951309204
      },
      {
        "repetition": 5,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            0.9691058993339539
          ],
          [
            "60",
            0.06872538477182388
          ]
        ],
        "inference_time": 1.7679479122161865
      },
      {
        "repetition": 6,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            0.9691058993339539
          ],
          [
            "40",
            0.03565426170825958
          ]
        ],
        "inference_time": 1.7679245471954346
      },
      {
        "repetition": 7,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9691058993339539
          ],
          [
            "100",
            0.030496707186102867
          ]
        ],
        "inference_time": 1.7673311233520508
      },
      {
        "repetition": 8,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            0.9691058993339539
          ],
          [
            "40",
            0.03565426170825958
          ]
        ],
        "inference_time": 1.769176721572876
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9691058993339539
          ],
          [
            "0",
            0.04168405011296272
          ]
        ],
        "inference_time": 1.7675881385803223
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 16,
    "sentence": "Sea drones & anti-ship missiles  The February 1 attack came after Ukraine unveiled its new underwater robot drone, a stealth Autonomous Underwater Vehicle (AUV).",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.15170933306217194
          ]
        ],
        "inference_time": 1.7673180103302002
      },
      {
        "repetition": 1,
        "generated_text": " 3",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "3",
            0.019693713635206223
          ]
        ],
        "inference_time": 1.7688038349151611
      },
      {
        "repetition": 2,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.15170933306217194
          ]
        ],
        "inference_time": 1.7663953304290771
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.21844832599163055
          ]
        ],
        "inference_time": 1.7683939933776855
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.21844832599163055
          ]
        ],
        "inference_time": 1.7692615985870361
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.21844832599163055
          ]
        ],
        "inference_time": 1.7712268829345703
      },
      {
        "repetition": 6,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.12446809560060501
          ]
        ],
        "inference_time": 1.7693791389465332
      },
      {
        "repetition": 7,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.09795091301202774
          ]
        ],
        "inference_time": 1.7685210704803467
      },
      {
        "repetition": 8,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.09795091301202774
          ]
        ],
        "inference_time": 1.7687113285064697
      },
      {
        "repetition": 9,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.09795091301202774
          ]
        ],
        "inference_time": 1.7688603401184082
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 17,
    "sentence": "\u201cThey\u2019re people who appreciate the onsite facilities such as the restaurant and gym and see living around older people as a lifestyle benefit rather than a hindrance,\u201d she explains.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 35",
        "token_probs": [
          [
            " ",
            0.9503043293952942
          ],
          [
            "35",
            0.01416163519024849
          ]
        ],
        "inference_time": 1.7718214988708496
      },
      {
        "repetition": 1,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9503043293952942
          ],
          [
            "50",
            0.08857676386833191
          ]
        ],
        "inference_time": 1.7705564498901367
      },
      {
        "repetition": 2,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9503043293952942
          ],
          [
            "75",
            0.030931856483221054
          ]
        ],
        "inference_time": 1.7698426246643066
      },
      {
        "repetition": 3,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9503043293952942
          ],
          [
            "50",
            0.08857676386833191
          ]
        ],
        "inference_time": 1.768099069595337
      },
      {
        "repetition": 4,
        "generated_text": " 6",
        "token_probs": [
          [
            " ",
            0.9503043293952942
          ],
          [
            "6",
            0.009287427179515362
          ]
        ],
        "inference_time": 1.7693381309509277
      },
      {
        "repetition": 5,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            0.9503043293952942
          ],
          [
            "95",
            0.010469366796314716
          ]
        ],
        "inference_time": 1.770268201828003
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9503043293952942
          ],
          [
            "0",
            0.06686124950647354
          ]
        ],
        "inference_time": 1.7676432132720947
      },
      {
        "repetition": 7,
        "generated_text": " (50",
        "token_probs": [
          [
            " (",
            0.008010396733880043
          ],
          [
            "50",
            0.010938048362731934
          ]
        ],
        "inference_time": 1.7694458961486816
      },
      {
        "repetition": 8,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9503043293952942
          ],
          [
            "80",
            0.06480414420366287
          ]
        ],
        "inference_time": 1.769002914428711
      },
      {
        "repetition": 9,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            0.9503043293952942
          ],
          [
            "60",
            0.0571894571185112
          ]
        ],
        "inference_time": 1.7699098587036133
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 18,
    "sentence": "But none of this means that the ditched \u00a328bn policy was optimal or, indeed, that an incoming chancellor can safely commit the Treasury to borrow and spend unlimited amounts.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "60",
            0.050456203520298004
          ]
        ],
        "inference_time": 1.769700527191162
      },
      {
        "repetition": 1,
        "generated_text": " 8",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "8",
            0.011984399519860744
          ]
        ],
        "inference_time": 1.7688875198364258
      },
      {
        "repetition": 2,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "95",
            0.03691454604268074
          ]
        ],
        "inference_time": 1.7693405151367188
      },
      {
        "repetition": 3,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.05541529878973961
          ]
        ],
        "inference_time": 1.7711236476898193
      },
      {
        "repetition": 4,
        "generated_text": " 78",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "78",
            0.012757325544953346
          ]
        ],
        "inference_time": 1.7720310688018799
      },
      {
        "repetition": 5,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.06684361398220062
          ]
        ],
        "inference_time": 1.7705392837524414
      },
      {
        "repetition": 6,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.10793429613113403
          ]
        ],
        "inference_time": 1.770247220993042
      },
      {
        "repetition": 7,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.06684361398220062
          ]
        ],
        "inference_time": 1.768702507019043
      },
      {
        "repetition": 8,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.03257697448134422
          ]
        ],
        "inference_time": 1.7680389881134033
      },
      {
        "repetition": 9,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.10793429613113403
          ]
        ],
        "inference_time": 1.7697863578796387
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 19,
    "sentence": "The record, which topped out at 41 on the Billboard 200, included contributions from Bieber, Halsey, Calvin Harris, Omar Apollo and Gracie Abrams.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5195347666740417
          ]
        ],
        "inference_time": 1.771773338317871
      },
      {
        "repetition": 1,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.025598065927624702
          ]
        ],
        "inference_time": 1.7727901935577393
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5195347666740417
          ]
        ],
        "inference_time": 1.7715578079223633
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5195347666740417
          ]
        ],
        "inference_time": 1.771463394165039
      },
      {
        "repetition": 4,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.15518216788768768
          ]
        ],
        "inference_time": 1.769580602645874
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5195347666740417
          ]
        ],
        "inference_time": 1.7715718746185303
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5195347666740417
          ]
        ],
        "inference_time": 1.769881248474121
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5195347666740417
          ]
        ],
        "inference_time": 1.7705373764038086
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5195347666740417
          ]
        ],
        "inference_time": 1.7687709331512451
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5195347666740417
          ]
        ],
        "inference_time": 1.771064281463623
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 20,
    "sentence": "The journalist Mike Smith was struck yesterday when he noticed",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.6197538375854492
          ]
        ],
        "inference_time": 1.7348041534423828
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.6197538375854492
          ]
        ],
        "inference_time": 1.7357172966003418
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.6197538375854492
          ]
        ],
        "inference_time": 1.7346701622009277
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.6197538375854492
          ]
        ],
        "inference_time": 1.7353665828704834
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.6197538375854492
          ]
        ],
        "inference_time": 1.733738660812378
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.6197538375854492
          ]
        ],
        "inference_time": 1.7359628677368164
      },
      {
        "repetition": 6,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.026118800044059753
          ]
        ],
        "inference_time": 1.7363033294677734
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.6197538375854492
          ]
        ],
        "inference_time": 1.7355122566223145
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.6197538375854492
          ]
        ],
        "inference_time": 1.735158920288086
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.6197538375854492
          ]
        ],
        "inference_time": 1.7347168922424316
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 21,
    "sentence": "Two years later, he stepped into a leading man role once again when he appeared in The Other Me - about a architect who has an eye disease which enables him to see people's real motives.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.10976985096931458
          ]
        ],
        "inference_time": 1.7692654132843018
      },
      {
        "repetition": 1,
        "generated_text": " 4",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "4",
            0.023493384942412376
          ]
        ],
        "inference_time": 1.7694368362426758
      },
      {
        "repetition": 2,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.1180729791522026
          ]
        ],
        "inference_time": 1.7702431678771973
      },
      {
        "repetition": 3,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.1180729791522026
          ]
        ],
        "inference_time": 1.7697601318359375
      },
      {
        "repetition": 4,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.08030933886766434
          ]
        ],
        "inference_time": 1.769826889038086
      },
      {
        "repetition": 5,
        "generated_text": " 14",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "14",
            0.026072625070810318
          ]
        ],
        "inference_time": 1.7703139781951904
      },
      {
        "repetition": 6,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.1180729791522026
          ]
        ],
        "inference_time": 1.7694964408874512
      },
      {
        "repetition": 7,
        "generated_text": " 1",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "1",
            0.02116931788623333
          ]
        ],
        "inference_time": 1.7680130004882812
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.1735939383506775
          ]
        ],
        "inference_time": 1.7682974338531494
      },
      {
        "repetition": 9,
        "generated_text": " 23",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "23",
            0.021390970796346664
          ]
        ],
        "inference_time": 1.767998218536377
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 22,
    "sentence": "At the time, Time magazine dubbed the film 'disjoined' - saying that 'characters that Nicholls brought so cunningly to life in the book feel rushed through a timeline, tied to an agenda'.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.960864782333374
          ],
          [
            "75",
            0.022375566884875298
          ]
        ],
        "inference_time": 1.7696125507354736
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.960864782333374
          ],
          [
            "0",
            0.09036016464233398
          ]
        ],
        "inference_time": 1.7699558734893799
      },
      {
        "repetition": 2,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.960864782333374
          ],
          [
            "20",
            0.09821279346942902
          ]
        ],
        "inference_time": 1.7700073719024658
      },
      {
        "repetition": 3,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.960864782333374
          ],
          [
            "20",
            0.09821279346942902
          ]
        ],
        "inference_time": 1.769709587097168
      },
      {
        "repetition": 4,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.960864782333374
          ],
          [
            "25",
            0.053676195442676544
          ]
        ],
        "inference_time": 1.7710039615631104
      },
      {
        "repetition": 5,
        "generated_text": " 45",
        "token_probs": [
          [
            " ",
            0.960864782333374
          ],
          [
            "45",
            0.014905340038239956
          ]
        ],
        "inference_time": 1.7686445713043213
      },
      {
        "repetition": 6,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.960864782333374
          ],
          [
            "50",
            0.08313530683517456
          ]
        ],
        "inference_time": 1.7693700790405273
      },
      {
        "repetition": 7,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            0.960864782333374
          ],
          [
            "70",
            0.038863424211740494
          ]
        ],
        "inference_time": 1.7710349559783936
      },
      {
        "repetition": 8,
        "generated_text": " \n53",
        "token_probs": [
          [
            " \n",
            0.009225770831108093
          ],
          [
            "53",
            0.048170093446969986
          ]
        ],
        "inference_time": 1.7693331241607666
      },
      {
        "repetition": 9,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.960864782333374
          ],
          [
            "20",
            0.09821279346942902
          ]
        ],
        "inference_time": 1.7712178230285645
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 23,
    "sentence": "\u201cWe were in shock,\u201d says Wangari\u2019s father.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.09031429141759872
          ]
        ],
        "inference_time": 1.7344260215759277
      },
      {
        "repetition": 1,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.09031429141759872
          ]
        ],
        "inference_time": 1.7358241081237793
      },
      {
        "repetition": 2,
        "generated_text": " 45",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "45",
            0.01287618838250637
          ]
        ],
        "inference_time": 1.7359166145324707
      },
      {
        "repetition": 3,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "70",
            0.017783937975764275
          ]
        ],
        "inference_time": 1.7363152503967285
      },
      {
        "repetition": 4,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.09031429141759872
          ]
        ],
        "inference_time": 1.735917329788208
      },
      {
        "repetition": 5,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.07565721124410629
          ]
        ],
        "inference_time": 1.7350993156433105
      },
      {
        "repetition": 6,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.02057608962059021
          ]
        ],
        "inference_time": 1.7339379787445068
      },
      {
        "repetition": 7,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.1740853637456894
          ]
        ],
        "inference_time": 1.7320597171783447
      },
      {
        "repetition": 8,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "40",
            0.05831129103899002
          ]
        ],
        "inference_time": 1.7369248867034912
      },
      {
        "repetition": 9,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "60",
            0.031211785972118378
          ]
        ],
        "inference_time": 1.7334990501403809
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 24,
    "sentence": "House Democrats and the remaining pro-Ukraine House Republicans are casting about behind the scenes for a solution.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.05215972289443016
          ]
        ],
        "inference_time": 1.7656030654907227
      },
      {
        "repetition": 1,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.014038598164916039
          ]
        ],
        "inference_time": 1.7654204368591309
      },
      {
        "repetition": 2,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.10265703499317169
          ]
        ],
        "inference_time": 1.766136884689331
      },
      {
        "repetition": 3,
        "generated_text": " 26",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "26",
            0.013606676831841469
          ]
        ],
        "inference_time": 1.7648906707763672
      },
      {
        "repetition": 4,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.10265703499317169
          ]
        ],
        "inference_time": 1.7662019729614258
      },
      {
        "repetition": 5,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.06697440892457962
          ]
        ],
        "inference_time": 1.765631914138794
      },
      {
        "repetition": 6,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.17830179631710052
          ]
        ],
        "inference_time": 1.7658026218414307
      },
      {
        "repetition": 7,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.07279472798109055
          ]
        ],
        "inference_time": 1.76737380027771
      },
      {
        "repetition": 8,
        "generated_text": " 13",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "13",
            0.011163434013724327
          ]
        ],
        "inference_time": 1.7661845684051514
      },
      {
        "repetition": 9,
        "generated_text": " 15",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "15",
            0.0282114427536726
          ]
        ],
        "inference_time": 1.7670345306396484
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 25,
    "sentence": "Austerity, and the credit card analogy that provides its thin veneer of logic, is not just bad for workers and people in desperate need of state support during tough times; it also depresses investment.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "100",
            0.19625607132911682
          ]
        ],
        "inference_time": 1.7693021297454834
      },
      {
        "repetition": 1,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.1544448882341385
          ]
        ],
        "inference_time": 1.7691316604614258
      },
      {
        "repetition": 2,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "70",
            0.048598241060972214
          ]
        ],
        "inference_time": 1.768864393234253
      },
      {
        "repetition": 3,
        "generated_text": " 98",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "98",
            0.026012763381004333
          ]
        ],
        "inference_time": 1.7702772617340088
      },
      {
        "repetition": 4,
        "generated_text": " 98",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "98",
            0.026012763381004333
          ]
        ],
        "inference_time": 1.7699158191680908
      },
      {
        "repetition": 5,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.1544448882341385
          ]
        ],
        "inference_time": 1.7700514793395996
      },
      {
        "repetition": 6,
        "generated_text": " 98",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "98",
            0.026012763381004333
          ]
        ],
        "inference_time": 1.7679369449615479
      },
      {
        "repetition": 7,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.059234507381916046
          ]
        ],
        "inference_time": 1.7693145275115967
      },
      {
        "repetition": 8,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.14209619164466858
          ]
        ],
        "inference_time": 1.7686481475830078
      },
      {
        "repetition": 9,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "100",
            0.19625607132911682
          ]
        ],
        "inference_time": 1.7686429023742676
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 26,
    "sentence": "In a pre-dawn vote on Tuesday, Graham joined the majority of Senate Republicans in opposing a foreign aid package that would rush wartime assistance to Ukraine as it approaches the second anniversary of Russia\u2019s full invasion.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.09981375932693481
          ]
        ],
        "inference_time": 1.7677438259124756
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.33416637778282166
          ]
        ],
        "inference_time": 1.7694454193115234
      },
      {
        "repetition": 2,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.17336323857307434
          ]
        ],
        "inference_time": 1.7704391479492188
      },
      {
        "repetition": 3,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.03240478038787842
          ]
        ],
        "inference_time": 1.770674467086792
      },
      {
        "repetition": 4,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11915069818496704
          ]
        ],
        "inference_time": 1.7711563110351562
      },
      {
        "repetition": 5,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11915069818496704
          ]
        ],
        "inference_time": 1.7701258659362793
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.33416637778282166
          ]
        ],
        "inference_time": 1.7687478065490723
      },
      {
        "repetition": 7,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11915069818496704
          ]
        ],
        "inference_time": 1.7680437564849854
      },
      {
        "repetition": 8,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.09981375932693481
          ]
        ],
        "inference_time": 1.7667241096496582
      },
      {
        "repetition": 9,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11915069818496704
          ]
        ],
        "inference_time": 1.769988775253296
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 27,
    "sentence": "The Observer's Philip French dubbed it 'thin, superficial and sentimental' and said the casting of Anne Hathway was 'disastrous'.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " \"30",
        "token_probs": [
          [
            " \"",
            0.01072768960148096
          ],
          [
            "30",
            0.011334151960909367
          ]
        ],
        "inference_time": 1.7673921585083008
      },
      {
        "repetition": 1,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9408524036407471
          ],
          [
            "100",
            0.19983221590518951
          ]
        ],
        "inference_time": 1.7692735195159912
      },
      {
        "repetition": 2,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9408524036407471
          ],
          [
            "90",
            0.1838545799255371
          ]
        ],
        "inference_time": 1.769097089767456
      },
      {
        "repetition": 3,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9408524036407471
          ],
          [
            "90",
            0.1838545799255371
          ]
        ],
        "inference_time": 1.7661588191986084
      },
      {
        "repetition": 4,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9408524036407471
          ],
          [
            "90",
            0.1838545799255371
          ]
        ],
        "inference_time": 1.7682783603668213
      },
      {
        "repetition": 5,
        "generated_text": " 67",
        "token_probs": [
          [
            " ",
            0.9408524036407471
          ],
          [
            "67",
            0.009153580293059349
          ]
        ],
        "inference_time": 1.7653253078460693
      },
      {
        "repetition": 6,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9408524036407471
          ],
          [
            "90",
            0.1838545799255371
          ]
        ],
        "inference_time": 1.769496202468872
      },
      {
        "repetition": 7,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9408524036407471
          ],
          [
            "80",
            0.1317376047372818
          ]
        ],
        "inference_time": 1.7689807415008545
      },
      {
        "repetition": 8,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9408524036407471
          ],
          [
            "100",
            0.19983221590518951
          ]
        ],
        "inference_time": 1.769378662109375
      },
      {
        "repetition": 9,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9408524036407471
          ],
          [
            "90",
            0.1838545799255371
          ]
        ],
        "inference_time": 1.7699971199035645
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 28,
    "sentence": "A third commented: \"$20 for $6k - not bad!\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9556751847267151
          ],
          [
            "50",
            0.1195472851395607
          ]
        ],
        "inference_time": 1.7672173976898193
      },
      {
        "repetition": 1,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            0.9556751847267151
          ],
          [
            "40",
            0.03425087034702301
          ]
        ],
        "inference_time": 1.7664902210235596
      },
      {
        "repetition": 2,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9556751847267151
          ],
          [
            "75",
            0.04681538790464401
          ]
        ],
        "inference_time": 1.769310474395752
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9556751847267151
          ],
          [
            "0",
            0.07559414952993393
          ]
        ],
        "inference_time": 1.7684319019317627
      },
      {
        "repetition": 4,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            0.9556751847267151
          ],
          [
            "85",
            0.018719131126999855
          ]
        ],
        "inference_time": 1.7710776329040527
      },
      {
        "repetition": 5,
        "generated_text": " 68",
        "token_probs": [
          [
            " ",
            0.9556751847267151
          ],
          [
            "68",
            0.009711356833577156
          ]
        ],
        "inference_time": 1.7715678215026855
      },
      {
        "repetition": 6,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            0.9556751847267151
          ],
          [
            "10",
            0.028394969180226326
          ]
        ],
        "inference_time": 1.7679250240325928
      },
      {
        "repetition": 7,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.9556751847267151
          ],
          [
            "25",
            0.0639890506863594
          ]
        ],
        "inference_time": 1.7682857513427734
      },
      {
        "repetition": 8,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9556751847267151
          ],
          [
            "20",
            0.07881048321723938
          ]
        ],
        "inference_time": 1.769028663635254
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9556751847267151
          ],
          [
            "0",
            0.07559414952993393
          ]
        ],
        "inference_time": 1.768836259841919
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 29,
    "sentence": "The plan incorporates cash payments supplemented by contingent contributions.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4416576027870178
          ]
        ],
        "inference_time": 1.7369415760040283
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4416576027870178
          ]
        ],
        "inference_time": 1.7376272678375244
      },
      {
        "repetition": 2,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.008173946291208267
          ]
        ],
        "inference_time": 1.7359516620635986
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4416576027870178
          ]
        ],
        "inference_time": 1.7359004020690918
      },
      {
        "repetition": 4,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.1418994814157486
          ]
        ],
        "inference_time": 1.7347133159637451
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4416576027870178
          ]
        ],
        "inference_time": 1.736640214920044
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4416576027870178
          ]
        ],
        "inference_time": 1.735844612121582
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4416576027870178
          ]
        ],
        "inference_time": 1.736262321472168
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4416576027870178
          ]
        ],
        "inference_time": 1.735454797744751
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4416576027870178
          ]
        ],
        "inference_time": 1.7348341941833496
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 30,
    "sentence": "It is true that the Tories will leave scorched earth behind for the next government, with a budget dripping in red ink and a pitiful level of investment in the technologies and services the UK needs to escape a long-term slump.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.8946670889854431
          ],
          [
            "80",
            0.13430413603782654
          ]
        ],
        "inference_time": 1.77351975440979
      },
      {
        "repetition": 1,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.8946670889854431
          ],
          [
            "75",
            0.054831940680742264
          ]
        ],
        "inference_time": 1.773494005203247
      },
      {
        "repetition": 2,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            0.8946670889854431
          ],
          [
            "70",
            0.07264051586389542
          ]
        ],
        "inference_time": 1.774794340133667
      },
      {
        "repetition": 3,
        "generated_text": " 78",
        "token_probs": [
          [
            " ",
            0.8946670889854431
          ],
          [
            "78",
            0.016897909343242645
          ]
        ],
        "inference_time": 1.7707266807556152
      },
      {
        "repetition": 4,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.8946670889854431
          ],
          [
            "50",
            0.09724074602127075
          ]
        ],
        "inference_time": 1.772092580795288
      },
      {
        "repetition": 5,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            0.8946670889854431
          ],
          [
            "70",
            0.07264051586389542
          ]
        ],
        "inference_time": 1.7722938060760498
      },
      {
        "repetition": 6,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.8946670889854431
          ],
          [
            "80",
            0.13430413603782654
          ]
        ],
        "inference_time": 1.7718772888183594
      },
      {
        "repetition": 7,
        "generated_text": " << Your",
        "token_probs": [
          [
            " <<",
            0.009583019651472569
          ],
          [
            " Your",
            0.026857662945985794
          ]
        ],
        "inference_time": 1.7715749740600586
      },
      {
        "repetition": 8,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.8946670889854431
          ],
          [
            "100",
            0.013577851466834545
          ]
        ],
        "inference_time": 1.770399808883667
      },
      {
        "repetition": 9,
        "generated_text": "? \n\n\n",
        "token_probs": [
          [
            "?",
            0.014842471107840538
          ],
          [
            " \n\n\n",
            0.01592716947197914
          ]
        ],
        "inference_time": 1.7705390453338623
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 31,
    "sentence": "A WOMAN who has been dubbed \u2018the world\u2019s hottest gran\u2019 has revealed how she stays looking eternally young at the age of 53.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.008315078914165497
          ]
        ],
        "inference_time": 1.768620252609253
      },
      {
        "repetition": 1,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.07971737533807755
          ]
        ],
        "inference_time": 1.7693474292755127
      },
      {
        "repetition": 2,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.14738829433918
          ]
        ],
        "inference_time": 1.7677719593048096
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.18925032019615173
          ]
        ],
        "inference_time": 1.7709555625915527
      },
      {
        "repetition": 4,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.0458972193300724
          ]
        ],
        "inference_time": 1.7690174579620361
      },
      {
        "repetition": 5,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.14738829433918
          ]
        ],
        "inference_time": 1.7704041004180908
      },
      {
        "repetition": 6,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.08224787563085556
          ]
        ],
        "inference_time": 1.7724690437316895
      },
      {
        "repetition": 7,
        "generated_text": " 35",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "35",
            0.01045664306730032
          ]
        ],
        "inference_time": 1.7699706554412842
      },
      {
        "repetition": 8,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "40",
            0.029022477567195892
          ]
        ],
        "inference_time": 1.7703502178192139
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.18925032019615173
          ]
        ],
        "inference_time": 1.7708044052124023
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 32,
    "sentence": "Couldn't say everything I wanted to in the video.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            0.9739075899124146
          ],
          [
            "30",
            0.03774586692452431
          ]
        ],
        "inference_time": 1.7353301048278809
      },
      {
        "repetition": 1,
        "generated_text": " 8",
        "token_probs": [
          [
            " ",
            0.9739075899124146
          ],
          [
            "8",
            0.013112736865878105
          ]
        ],
        "inference_time": 1.7356324195861816
      },
      {
        "repetition": 2,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9739075899124146
          ],
          [
            "20",
            0.07125700265169144
          ]
        ],
        "inference_time": 1.7370719909667969
      },
      {
        "repetition": 3,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.9739075899124146
          ],
          [
            "25",
            0.08595234155654907
          ]
        ],
        "inference_time": 1.7366294860839844
      },
      {
        "repetition": 4,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.9739075899124146
          ],
          [
            "25",
            0.08595234155654907
          ]
        ],
        "inference_time": 1.7349035739898682
      },
      {
        "repetition": 5,
        "generated_text": " 26",
        "token_probs": [
          [
            " ",
            0.9739075899124146
          ],
          [
            "26",
            0.011099699884653091
          ]
        ],
        "inference_time": 1.7361986637115479
      },
      {
        "repetition": 6,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9739075899124146
          ],
          [
            "20",
            0.07125700265169144
          ]
        ],
        "inference_time": 1.736426591873169
      },
      {
        "repetition": 7,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9739075899124146
          ],
          [
            "50",
            0.12121223658323288
          ]
        ],
        "inference_time": 1.736084222793579
      },
      {
        "repetition": 8,
        "generated_text": " 15",
        "token_probs": [
          [
            " ",
            0.9739075899124146
          ],
          [
            "15",
            0.011274494230747223
          ]
        ],
        "inference_time": 1.736645221710205
      },
      {
        "repetition": 9,
        "generated_text": " 87",
        "token_probs": [
          [
            " ",
            0.9739075899124146
          ],
          [
            "87",
            0.012842385098338127
          ]
        ],
        "inference_time": 1.7360639572143555
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 33,
    "sentence": "From the Senate floor, Senator Mitch McConnell, the top Republican, delivered increasingly urgent pleas for his conference to rise to the occasion and support America\u2019s allies, even after his plan to tie border security to foreign aid collapsed, torpedoed by Trump\u2019s opposition.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            0.9416037797927856
          ],
          [
            "40",
            0.05525710806250572
          ]
        ],
        "inference_time": 1.7713384628295898
      },
      {
        "repetition": 1,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            0.9416037797927856
          ],
          [
            "40",
            0.05525710806250572
          ]
        ],
        "inference_time": 1.7733030319213867
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9416037797927856
          ],
          [
            "0",
            0.09399550408124924
          ]
        ],
        "inference_time": 1.774169921875
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9416037797927856
          ],
          [
            "0",
            0.09399550408124924
          ]
        ],
        "inference_time": 1.77164888381958
      },
      {
        "repetition": 4,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            0.9416037797927856
          ],
          [
            "10",
            0.05642040818929672
          ]
        ],
        "inference_time": 1.7715318202972412
      },
      {
        "repetition": 5,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            0.9416037797927856
          ],
          [
            "5",
            0.06327016651630402
          ]
        ],
        "inference_time": 1.7720870971679688
      },
      {
        "repetition": 6,
        "generated_text": " 15",
        "token_probs": [
          [
            " ",
            0.9416037797927856
          ],
          [
            "15",
            0.01929630897939205
          ]
        ],
        "inference_time": 1.7723596096038818
      },
      {
        "repetition": 7,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9416037797927856
          ],
          [
            "20",
            0.1549723893404007
          ]
        ],
        "inference_time": 1.7740099430084229
      },
      {
        "repetition": 8,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            0.9416037797927856
          ],
          [
            "10",
            0.05642040818929672
          ]
        ],
        "inference_time": 1.770683765411377
      },
      {
        "repetition": 9,
        "generated_text": " 35",
        "token_probs": [
          [
            " ",
            0.9416037797927856
          ],
          [
            "35",
            0.01441467646509409
          ]
        ],
        "inference_time": 1.7695870399475098
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 34,
    "sentence": "The Hollywood Reporter was particularly gushing of Jim Sturgess' performance - saying the actor had 'staked his claim as the new Hugh Grant only without the fussy mannerisms'.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " {20",
        "token_probs": [
          [
            " {",
            0.010030816309154034
          ],
          [
            "20",
            0.023710688576102257
          ]
        ],
        "inference_time": 1.7716941833496094
      },
      {
        "repetition": 1,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9267687201499939
          ],
          [
            "80",
            0.16786324977874756
          ]
        ],
        "inference_time": 1.7693889141082764
      },
      {
        "repetition": 2,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9267687201499939
          ],
          [
            "20",
            0.02740292251110077
          ]
        ],
        "inference_time": 1.7700636386871338
      },
      {
        "repetition": 3,
        "generated_text": " (choose",
        "token_probs": [
          [
            " (",
            0.008806182071566582
          ],
          [
            "choose",
            0.027481287717819214
          ]
        ],
        "inference_time": 1.7722325325012207
      },
      {
        "repetition": 4,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9267687201499939
          ],
          [
            "90",
            0.10181421041488647
          ]
        ],
        "inference_time": 1.7734253406524658
      },
      {
        "repetition": 5,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9267687201499939
          ],
          [
            "80",
            0.16786324977874756
          ]
        ],
        "inference_time": 1.7717716693878174
      },
      {
        "repetition": 6,
        "generated_text": " 87",
        "token_probs": [
          [
            " ",
            0.9267687201499939
          ],
          [
            "87",
            0.016620712354779243
          ]
        ],
        "inference_time": 1.7714312076568604
      },
      {
        "repetition": 7,
        "generated_text": " \n100",
        "token_probs": [
          [
            " \n",
            0.010083192959427834
          ],
          [
            "100",
            0.0778292715549469
          ]
        ],
        "inference_time": 1.7693512439727783
      },
      {
        "repetition": 8,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9267687201499939
          ],
          [
            "20",
            0.02740292251110077
          ]
        ],
        "inference_time": 1.7686059474945068
      },
      {
        "repetition": 9,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9267687201499939
          ],
          [
            "20",
            0.02740292251110077
          ]
        ],
        "inference_time": 1.769932746887207
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 35,
    "sentence": "The Neptune \"super missile\", revealed in August last year, was reportedly snatched from behind enemy lines during a raid on Putin's prized \u00a3200million air defence system.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            0.9358113408088684
          ],
          [
            "10",
            0.0698864758014679
          ]
        ],
        "inference_time": 1.7692949771881104
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9358113408088684
          ],
          [
            "0",
            0.1711781919002533
          ]
        ],
        "inference_time": 1.7700049877166748
      },
      {
        "repetition": 2,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9358113408088684
          ],
          [
            "20",
            0.15749159455299377
          ]
        ],
        "inference_time": 1.7714414596557617
      },
      {
        "repetition": 3,
        "generated_text": " 15",
        "token_probs": [
          [
            " ",
            0.9358113408088684
          ],
          [
            "15",
            0.02708432637155056
          ]
        ],
        "inference_time": 1.7685613632202148
      },
      {
        "repetition": 4,
        "generated_text": " 13",
        "token_probs": [
          [
            " ",
            0.9358113408088684
          ],
          [
            "13",
            0.008566961623728275
          ]
        ],
        "inference_time": 1.76790189743042
      },
      {
        "repetition": 5,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9358113408088684
          ],
          [
            "50",
            0.0470418706536293
          ]
        ],
        "inference_time": 1.769338846206665
      },
      {
        "repetition": 6,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            0.9358113408088684
          ],
          [
            "5",
            0.10937563329935074
          ]
        ],
        "inference_time": 1.7712066173553467
      },
      {
        "repetition": 7,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9358113408088684
          ],
          [
            "80",
            0.02316644974052906
          ]
        ],
        "inference_time": 1.771942138671875
      },
      {
        "repetition": 8,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9358113408088684
          ],
          [
            "50",
            0.0470418706536293
          ]
        ],
        "inference_time": 1.770122766494751
      },
      {
        "repetition": 9,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            0.9358113408088684
          ],
          [
            "70",
            0.01017351821064949
          ]
        ],
        "inference_time": 1.770352840423584
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 36,
    "sentence": "- Actor was on track to become a Hollywood star when he appeared in One Day  - Read More: How Taylor Swift's savvy marketing executive mother Andrea turned her daughter into a superstar  David Nicholls' romantic novel One Day became an overnight fan favourite when it was first released in 2009 and is now being rediscovered by a new audience thanks to Netflix's adaptation.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.12364040315151215
          ]
        ],
        "inference_time": 1.7743055820465088
      },
      {
        "repetition": 1,
        "generated_text": " 15",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "15",
            0.04692860692739487
          ]
        ],
        "inference_time": 1.771737813949585
      },
      {
        "repetition": 2,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11140936613082886
          ]
        ],
        "inference_time": 1.7740051746368408
      },
      {
        "repetition": 3,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11140936613082886
          ]
        ],
        "inference_time": 1.7741451263427734
      },
      {
        "repetition": 4,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.0385020449757576
          ]
        ],
        "inference_time": 1.7757372856140137
      },
      {
        "repetition": 5,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.09140446782112122
          ]
        ],
        "inference_time": 1.7724628448486328
      },
      {
        "repetition": 6,
        "generated_text": " 18",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "18",
            0.013445270247757435
          ]
        ],
        "inference_time": 1.775533676147461
      },
      {
        "repetition": 7,
        "generated_text": " 14",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "14",
            0.0185699425637722
          ]
        ],
        "inference_time": 1.7735612392425537
      },
      {
        "repetition": 8,
        "generated_text": " 1",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "1",
            0.015235486440360546
          ]
        ],
        "inference_time": 1.773543119430542
      },
      {
        "repetition": 9,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.09140446782112122
          ]
        ],
        "inference_time": 1.7751123905181885
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 37,
    "sentence": "\"$6k is a lot of money,\" wrote one.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9716985821723938
          ],
          [
            "50",
            0.20544448494911194
          ]
        ],
        "inference_time": 1.7339041233062744
      },
      {
        "repetition": 1,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            0.9716985821723938
          ],
          [
            "10",
            0.01832946389913559
          ]
        ],
        "inference_time": 1.736325979232788
      },
      {
        "repetition": 2,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9716985821723938
          ],
          [
            "90",
            0.061365194618701935
          ]
        ],
        "inference_time": 1.7337439060211182
      },
      {
        "repetition": 3,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9716985821723938
          ],
          [
            "20",
            0.03840135410428047
          ]
        ],
        "inference_time": 1.7346057891845703
      },
      {
        "repetition": 4,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            0.9716985821723938
          ],
          [
            "60",
            0.06464596837759018
          ]
        ],
        "inference_time": 1.7360937595367432
      },
      {
        "repetition": 5,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9716985821723938
          ],
          [
            "90",
            0.061365194618701935
          ]
        ],
        "inference_time": 1.7355637550354004
      },
      {
        "repetition": 6,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            0.9716985821723938
          ],
          [
            "95",
            0.020447993651032448
          ]
        ],
        "inference_time": 1.7339956760406494
      },
      {
        "repetition": 7,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9716985821723938
          ],
          [
            "50",
            0.20544448494911194
          ]
        ],
        "inference_time": 1.7347891330718994
      },
      {
        "repetition": 8,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9716985821723938
          ],
          [
            "100",
            0.04632088169455528
          ]
        ],
        "inference_time": 1.733689785003662
      },
      {
        "repetition": 9,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9716985821723938
          ],
          [
            "75",
            0.0830070748925209
          ]
        ],
        "inference_time": 1.7358639240264893
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 38,
    "sentence": "He told The Independent in 2021: 'If someone does a bad one, I can\u2019t watch the film.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.06901933252811432
          ]
        ],
        "inference_time": 1.7675135135650635
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.19356949627399445
          ]
        ],
        "inference_time": 1.7705535888671875
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.19356949627399445
          ]
        ],
        "inference_time": 1.7712624073028564
      },
      {
        "repetition": 3,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.02127012610435486
          ]
        ],
        "inference_time": 1.76878023147583
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.19356949627399445
          ]
        ],
        "inference_time": 1.7674951553344727
      },
      {
        "repetition": 5,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "70",
            0.01800476759672165
          ]
        ],
        "inference_time": 1.769195556640625
      },
      {
        "repetition": 6,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.012634986080229282
          ]
        ],
        "inference_time": 1.7690415382385254
      },
      {
        "repetition": 7,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.03811608999967575
          ]
        ],
        "inference_time": 1.76814603805542
      },
      {
        "repetition": 8,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.06901933252811432
          ]
        ],
        "inference_time": 1.7693657875061035
      },
      {
        "repetition": 9,
        "generated_text": " 26",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "26",
            0.00815775990486145
          ]
        ],
        "inference_time": 1.7713685035705566
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 39,
    "sentence": "Gina Stewart has previously hit the headlines for her youthful appearance and most recently, immortalising herself as an AI model.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.11619457602500916
          ]
        ],
        "inference_time": 1.7701375484466553
      },
      {
        "repetition": 1,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.12629231810569763
          ]
        ],
        "inference_time": 1.7699899673461914
      },
      {
        "repetition": 2,
        "generated_text": " 12",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "12",
            0.03694506734609604
          ]
        ],
        "inference_time": 1.7706303596496582
      },
      {
        "repetition": 3,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.11619457602500916
          ]
        ],
        "inference_time": 1.771902322769165
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.1330443024635315
          ]
        ],
        "inference_time": 1.767641305923462
      },
      {
        "repetition": 5,
        "generated_text": " 35",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "35",
            0.01359133142977953
          ]
        ],
        "inference_time": 1.7684268951416016
      },
      {
        "repetition": 6,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.12629231810569763
          ]
        ],
        "inference_time": 1.7676403522491455
      },
      {
        "repetition": 7,
        "generated_text": " 4",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "4",
            0.02907414548099041
          ]
        ],
        "inference_time": 1.7676067352294922
      },
      {
        "repetition": 8,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.04503091052174568
          ]
        ],
        "inference_time": 1.7692818641662598
      },
      {
        "repetition": 9,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.07985928654670715
          ]
        ],
        "inference_time": 1.7700676918029785
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 40,
    "sentence": "Anne is a very warm actress.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9431830644607544
          ],
          [
            "50",
            0.17371302843093872
          ]
        ],
        "inference_time": 1.7325358390808105
      },
      {
        "repetition": 1,
        "generated_text": " 67",
        "token_probs": [
          [
            " ",
            0.9431830644607544
          ],
          [
            "67",
            0.018119482323527336
          ]
        ],
        "inference_time": 1.736335039138794
      },
      {
        "repetition": 2,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9431830644607544
          ],
          [
            "90",
            0.05639636516571045
          ]
        ],
        "inference_time": 1.7334928512573242
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9431830644607544
          ],
          [
            "0",
            0.05466122925281525
          ]
        ],
        "inference_time": 1.7335193157196045
      },
      {
        "repetition": 4,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9431830644607544
          ],
          [
            "50",
            0.17371302843093872
          ]
        ],
        "inference_time": 1.733957052230835
      },
      {
        "repetition": 5,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9431830644607544
          ],
          [
            "50",
            0.17371302843093872
          ]
        ],
        "inference_time": 1.7355263233184814
      },
      {
        "repetition": 6,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9431830644607544
          ],
          [
            "80",
            0.11939110606908798
          ]
        ],
        "inference_time": 1.7348823547363281
      },
      {
        "repetition": 7,
        "generated_text": "?\n\nGo",
        "token_probs": [
          [
            "?\n\n",
            0.011567720212042332
          ],
          [
            "Go",
            0.03128364682197571
          ]
        ],
        "inference_time": 1.734975814819336
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9431830644607544
          ],
          [
            "0",
            0.05466122925281525
          ]
        ],
        "inference_time": 1.7312498092651367
      },
      {
        "repetition": 9,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            0.9431830644607544
          ],
          [
            "85",
            0.023024773225188255
          ]
        ],
        "inference_time": 1.734419822692871
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 41,
    "sentence": "And I was good at it.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9790636897087097
          ],
          [
            "75",
            0.11166504770517349
          ]
        ],
        "inference_time": 1.734278678894043
      },
      {
        "repetition": 1,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9790636897087097
          ],
          [
            "100",
            0.12264005839824677
          ]
        ],
        "inference_time": 1.733297348022461
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9790636897087097
          ],
          [
            "0",
            0.13191670179367065
          ]
        ],
        "inference_time": 1.733088493347168
      },
      {
        "repetition": 3,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9790636897087097
          ],
          [
            "90",
            0.05059423670172691
          ]
        ],
        "inference_time": 1.7332088947296143
      },
      {
        "repetition": 4,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.9790636897087097
          ],
          [
            "25",
            0.038994502276182175
          ]
        ],
        "inference_time": 1.731459617614746
      },
      {
        "repetition": 5,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9790636897087097
          ],
          [
            "75",
            0.11166504770517349
          ]
        ],
        "inference_time": 1.7322735786437988
      },
      {
        "repetition": 6,
        "generated_text": " 78",
        "token_probs": [
          [
            " ",
            0.9790636897087097
          ],
          [
            "78",
            0.0075594293884932995
          ]
        ],
        "inference_time": 1.735583782196045
      },
      {
        "repetition": 7,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9790636897087097
          ],
          [
            "50",
            0.1803087592124939
          ]
        ],
        "inference_time": 1.7326464653015137
      },
      {
        "repetition": 8,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9790636897087097
          ],
          [
            "100",
            0.12264005839824677
          ]
        ],
        "inference_time": 1.7324812412261963
      },
      {
        "repetition": 9,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9790636897087097
          ],
          [
            "90",
            0.05059423670172691
          ]
        ],
        "inference_time": 1.7339935302734375
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 42,
    "sentence": "\u201cOn matters like femicide which society takes lightly, you don\u2019t just get justice,\u201d says Kamande.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "?\n \n",
        "token_probs": [
          [
            "?\n",
            0.0071060387417674065
          ],
          [
            " \n",
            0.070499949157238
          ]
        ],
        "inference_time": 1.767777919769287
      },
      {
        "repetition": 1,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9355681538581848
          ],
          [
            "80",
            0.13364270329475403
          ]
        ],
        "inference_time": 1.767735242843628
      },
      {
        "repetition": 2,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9355681538581848
          ],
          [
            "50",
            0.12295714020729065
          ]
        ],
        "inference_time": 1.7693204879760742
      },
      {
        "repetition": 3,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            0.9355681538581848
          ],
          [
            "95",
            0.0461856834590435
          ]
        ],
        "inference_time": 1.7687792778015137
      },
      {
        "repetition": 4,
        "generated_text": "?           ",
        "token_probs": [
          [
            "?",
            0.01941709592938423
          ],
          [
            "           ",
            0.025316845625638962
          ]
        ],
        "inference_time": 1.7675180435180664
      },
      {
        "repetition": 5,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9355681538581848
          ],
          [
            "50",
            0.12295714020729065
          ]
        ],
        "inference_time": 1.769437551498413
      },
      {
        "repetition": 6,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9355681538581848
          ],
          [
            "75",
            0.04967917874455452
          ]
        ],
        "inference_time": 1.7682678699493408
      },
      {
        "repetition": 7,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9355681538581848
          ],
          [
            "80",
            0.13364270329475403
          ]
        ],
        "inference_time": 1.7700612545013428
      },
      {
        "repetition": 8,
        "generated_text": " 97",
        "token_probs": [
          [
            " ",
            0.9355681538581848
          ],
          [
            "97",
            0.007500434294342995
          ]
        ],
        "inference_time": 1.7676310539245605
      },
      {
        "repetition": 9,
        "generated_text": " 83",
        "token_probs": [
          [
            " ",
            0.9355681538581848
          ],
          [
            "83",
            0.008067776449024677
          ]
        ],
        "inference_time": 1.7695510387420654
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 43,
    "sentence": "hosted by Laura Rangeley and Michael Deakin).",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3801083564758301
          ]
        ],
        "inference_time": 1.735755443572998
      },
      {
        "repetition": 1,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.16178841888904572
          ]
        ],
        "inference_time": 1.7362399101257324
      },
      {
        "repetition": 2,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.08306499570608139
          ]
        ],
        "inference_time": 1.7365965843200684
      },
      {
        "repetition": 3,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.05951862782239914
          ]
        ],
        "inference_time": 1.7341790199279785
      },
      {
        "repetition": 4,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.05951862782239914
          ]
        ],
        "inference_time": 1.73872971534729
      },
      {
        "repetition": 5,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.05951862782239914
          ]
        ],
        "inference_time": 1.7392733097076416
      },
      {
        "repetition": 6,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.05951862782239914
          ]
        ],
        "inference_time": 1.7363638877868652
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3801083564758301
          ]
        ],
        "inference_time": 1.7363097667694092
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3801083564758301
          ]
        ],
        "inference_time": 1.734287977218628
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3801083564758301
          ]
        ],
        "inference_time": 1.7356274127960205
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 44,
    "sentence": "Following One Day, the actor was dubbed the 'new Hugh Grant'  Pictured: Jim Sturgess - who is now a musician - opposite David Jason in A Touch of Frost in March 2003  Speaking to The Telegraph at the time, Jim - who starred in the Beatles-inspired movie Across the Universe beforehand - admitted that he hadn't read the book when he had his first audition.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.16258041560649872
          ]
        ],
        "inference_time": 1.7949013710021973
      },
      {
        "repetition": 1,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.08090346306562424
          ]
        ],
        "inference_time": 1.7975244522094727
      },
      {
        "repetition": 2,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.12272212654352188
          ]
        ],
        "inference_time": 1.8007686138153076
      },
      {
        "repetition": 3,
        "generated_text": " 29",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "29",
            0.008179161697626114
          ]
        ],
        "inference_time": 1.8011786937713623
      },
      {
        "repetition": 4,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11771383881568909
          ]
        ],
        "inference_time": 1.797027349472046
      },
      {
        "repetition": 5,
        "generated_text": " 7",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "7",
            0.012025226838886738
          ]
        ],
        "inference_time": 1.798408031463623
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.16258041560649872
          ]
        ],
        "inference_time": 1.8002376556396484
      },
      {
        "repetition": 7,
        "generated_text": " 3",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "3",
            0.015440696850419044
          ]
        ],
        "inference_time": 1.8012611865997314
      },
      {
        "repetition": 8,
        "generated_text": " 16",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "16",
            0.014657068066298962
          ]
        ],
        "inference_time": 1.801501989364624
      },
      {
        "repetition": 9,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.08090346306562424
          ]
        ],
        "inference_time": 1.8005545139312744
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 45,
    "sentence": "He has collaborated with a bevy of big name artists - including Gomez herself, on tracks such as 2023's Single Soon, and his 2019 song I Can\u2019t Get Enough.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.12598758935928345
          ]
        ],
        "inference_time": 1.7715904712677002
      },
      {
        "repetition": 1,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.12598758935928345
          ]
        ],
        "inference_time": 1.7718331813812256
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.2211151272058487
          ]
        ],
        "inference_time": 1.7691068649291992
      },
      {
        "repetition": 3,
        "generated_text": " 8",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "8",
            0.024045154452323914
          ]
        ],
        "inference_time": 1.771040439605713
      },
      {
        "repetition": 4,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.12598758935928345
          ]
        ],
        "inference_time": 1.770298957824707
      },
      {
        "repetition": 5,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.1814112365245819
          ]
        ],
        "inference_time": 1.7704834938049316
      },
      {
        "repetition": 6,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.04047831892967224
          ]
        ],
        "inference_time": 1.7724688053131104
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.2211151272058487
          ]
        ],
        "inference_time": 1.7699410915374756
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.2211151272058487
          ]
        ],
        "inference_time": 1.7688000202178955
      },
      {
        "repetition": 9,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.10664617270231247
          ]
        ],
        "inference_time": 1.7664012908935547
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 46,
    "sentence": "RULE 4: MOISTURISE  Gina uses organic coconut oil every day on her body, as she admitted \"I have moisturised my entire body every day since I was 19.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.1285949945449829
          ]
        ],
        "inference_time": 1.7667303085327148
      },
      {
        "repetition": 1,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.07718852907419205
          ]
        ],
        "inference_time": 1.7670660018920898
      },
      {
        "repetition": 2,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.14271289110183716
          ]
        ],
        "inference_time": 1.7702322006225586
      },
      {
        "repetition": 3,
        "generated_text": " 6",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "6",
            0.010230954736471176
          ]
        ],
        "inference_time": 1.7702510356903076
      },
      {
        "repetition": 4,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.14271289110183716
          ]
        ],
        "inference_time": 1.7703516483306885
      },
      {
        "repetition": 5,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "40",
            0.04444124177098274
          ]
        ],
        "inference_time": 1.7717232704162598
      },
      {
        "repetition": 6,
        "generated_text": "  ",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            " ",
            0.00893522147089243
          ]
        ],
        "inference_time": 1.769688367843628
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.1285949945449829
          ]
        ],
        "inference_time": 1.7711460590362549
      },
      {
        "repetition": 8,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.07718852907419205
          ]
        ],
        "inference_time": 1.7682888507843018
      },
      {
        "repetition": 9,
        "generated_text": " 67",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "67",
            0.015199322253465652
          ]
        ],
        "inference_time": 1.7660009860992432
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 47,
    "sentence": "It\u2019s this second group that Barratt is targeting for Ayrton House \u2013 final year medical students and graduate trainees from the surrounding universities, which include Westminster, Middlesex and UCL.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 3",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "3",
            0.02332204580307007
          ]
        ],
        "inference_time": 1.76578950881958
      },
      {
        "repetition": 1,
        "generated_text": " 22",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "22",
            0.015057845041155815
          ]
        ],
        "inference_time": 1.7681081295013428
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.1834421008825302
          ]
        ],
        "inference_time": 1.76869797706604
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.1834421008825302
          ]
        ],
        "inference_time": 1.770036220550537
      },
      {
        "repetition": 4,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.12739799916744232
          ]
        ],
        "inference_time": 1.770463466644287
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.1834421008825302
          ]
        ],
        "inference_time": 1.7699532508850098
      },
      {
        "repetition": 6,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.1384693682193756
          ]
        ],
        "inference_time": 1.7675843238830566
      },
      {
        "repetition": 7,
        "generated_text": " 15",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "15",
            0.04495442286133766
          ]
        ],
        "inference_time": 1.7650065422058105
      },
      {
        "repetition": 8,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.03254852816462517
          ]
        ],
        "inference_time": 1.7700297832489014
      },
      {
        "repetition": 9,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.1384693682193756
          ]
        ],
        "inference_time": 1.7677724361419678
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 48,
    "sentence": "This is why the more Osborne slashed public spending in the 2010s, the more money he needed to borrow.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            0.9802700281143188
          ],
          [
            "60",
            0.038319606333971024
          ]
        ],
        "inference_time": 1.7651753425598145
      },
      {
        "repetition": 1,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9802700281143188
          ],
          [
            "90",
            0.09484194964170456
          ]
        ],
        "inference_time": 1.7645049095153809
      },
      {
        "repetition": 2,
        "generated_text": " 87",
        "token_probs": [
          [
            " ",
            0.9802700281143188
          ],
          [
            "87",
            0.015482520684599876
          ]
        ],
        "inference_time": 1.7676599025726318
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9802700281143188
          ],
          [
            "0",
            0.04297183081507683
          ]
        ],
        "inference_time": 1.7683031558990479
      },
      {
        "repetition": 4,
        "generated_text": " 82",
        "token_probs": [
          [
            " ",
            0.9802700281143188
          ],
          [
            "82",
            0.010048463940620422
          ]
        ],
        "inference_time": 1.7692320346832275
      },
      {
        "repetition": 5,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9802700281143188
          ],
          [
            "80",
            0.12177945673465729
          ]
        ],
        "inference_time": 1.7645339965820312
      },
      {
        "repetition": 6,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            0.9802700281143188
          ],
          [
            "70",
            0.047689519822597504
          ]
        ],
        "inference_time": 1.766249179840088
      },
      {
        "repetition": 7,
        "generated_text": "  ",
        "token_probs": [
          [
            " ",
            0.9802700281143188
          ],
          [
            " ",
            0.007907697930932045
          ]
        ],
        "inference_time": 1.7669837474822998
      },
      {
        "repetition": 8,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9802700281143188
          ],
          [
            "100",
            0.05812690779566765
          ]
        ],
        "inference_time": 1.764416217803955
      },
      {
        "repetition": 9,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            0.9802700281143188
          ],
          [
            "70",
            0.047689519822597504
          ]
        ],
        "inference_time": 1.7646677494049072
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 49,
    "sentence": "When your credit card is \u201cmaxed out\u201d, you do indeed need immediately to tighten your belt.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11043781787157059
          ]
        ],
        "inference_time": 1.7645657062530518
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.251481294631958
          ]
        ],
        "inference_time": 1.765031099319458
      },
      {
        "repetition": 2,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.1151365339756012
          ]
        ],
        "inference_time": 1.7631149291992188
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.251481294631958
          ]
        ],
        "inference_time": 1.765310525894165
      },
      {
        "repetition": 4,
        "generated_text": " 14",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "14",
            0.009450982324779034
          ]
        ],
        "inference_time": 1.7648983001708984
      },
      {
        "repetition": 5,
        "generated_text": " 8",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "8",
            0.018408004194498062
          ]
        ],
        "inference_time": 1.7667226791381836
      },
      {
        "repetition": 6,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.0521671287715435
          ]
        ],
        "inference_time": 1.7677686214447021
      },
      {
        "repetition": 7,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.1151365339756012
          ]
        ],
        "inference_time": 1.7690622806549072
      },
      {
        "repetition": 8,
        "generated_text": " 35",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "35",
            0.014637965708971024
          ]
        ],
        "inference_time": 1.7680385112762451
      },
      {
        "repetition": 9,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.04020678251981735
          ]
        ],
        "inference_time": 1.7685821056365967
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 50,
    "sentence": "This was inaccurate.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.02331715263426304
          ]
        ],
        "inference_time": 1.726914405822754
      },
      {
        "repetition": 1,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.03726070746779442
          ]
        ],
        "inference_time": 1.7351982593536377
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.31198006868362427
          ]
        ],
        "inference_time": 1.7327001094818115
      },
      {
        "repetition": 3,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.010900103487074375
          ]
        ],
        "inference_time": 1.7339670658111572
      },
      {
        "repetition": 4,
        "generated_text": " 4",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "4",
            0.011482859030365944
          ]
        ],
        "inference_time": 1.736402988433838
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.31198006868362427
          ]
        ],
        "inference_time": 1.732131004333496
      },
      {
        "repetition": 6,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.028125856071710587
          ]
        ],
        "inference_time": 1.733459711074829
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.31198006868362427
          ]
        ],
        "inference_time": 1.733950138092041
      },
      {
        "repetition": 8,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.06677123159170151
          ]
        ],
        "inference_time": 1.7318148612976074
      },
      {
        "repetition": 9,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.03726070746779442
          ]
        ],
        "inference_time": 1.7342488765716553
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 51,
    "sentence": "She now has her 26-year-old granddaughter, Eliza Brunero, lodging with her on Wednesdays each week.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5322448015213013
          ]
        ],
        "inference_time": 1.7660253047943115
      },
      {
        "repetition": 1,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.16064347326755524
          ]
        ],
        "inference_time": 1.7671420574188232
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5322448015213013
          ]
        ],
        "inference_time": 1.7666542530059814
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5322448015213013
          ]
        ],
        "inference_time": 1.769282579421997
      },
      {
        "repetition": 4,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.05971620976924896
          ]
        ],
        "inference_time": 1.7698161602020264
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5322448015213013
          ]
        ],
        "inference_time": 1.7710778713226318
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5322448015213013
          ]
        ],
        "inference_time": 1.7701654434204102
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.5322448015213013
          ]
        ],
        "inference_time": 1.7690143585205078
      },
      {
        "repetition": 8,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.018403125926852226
          ]
        ],
        "inference_time": 1.770719051361084
      },
      {
        "repetition": 9,
        "generated_text": " 12",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "12",
            0.007751896046102047
          ]
        ],
        "inference_time": 1.7691001892089844
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 52,
    "sentence": "Wangari is one of 16 Kenyan women who have died allegedly at the hands of their partners since the start of 2024.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.47189316153526306
          ]
        ],
        "inference_time": 1.7708938121795654
      },
      {
        "repetition": 1,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.12569227814674377
          ]
        ],
        "inference_time": 1.7712643146514893
      },
      {
        "repetition": 2,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.036388494074344635
          ]
        ],
        "inference_time": 1.766852617263794
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.47189316153526306
          ]
        ],
        "inference_time": 1.7711808681488037
      },
      {
        "repetition": 4,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11685334146022797
          ]
        ],
        "inference_time": 1.7707927227020264
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.47189316153526306
          ]
        ],
        "inference_time": 1.7709031105041504
      },
      {
        "repetition": 6,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.12569227814674377
          ]
        ],
        "inference_time": 1.772552251815796
      },
      {
        "repetition": 7,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.12569227814674377
          ]
        ],
        "inference_time": 1.7697341442108154
      },
      {
        "repetition": 8,
        "generated_text": " 15",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "15",
            0.02161569334566593
          ]
        ],
        "inference_time": 1.7707791328430176
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.47189316153526306
          ]
        ],
        "inference_time": 1.7676270008087158
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 53,
    "sentence": "And the Caesar Kunikov's watery demise is just the latest blow to have embarrassed Putin.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 86",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "86",
            0.010505784302949905
          ]
        ],
        "inference_time": 1.7703030109405518
      },
      {
        "repetition": 1,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.11960778385400772
          ]
        ],
        "inference_time": 1.770167589187622
      },
      {
        "repetition": 2,
        "generated_text": " 87",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "87",
            0.02429979480803013
          ]
        ],
        "inference_time": 1.7710800170898438
      },
      {
        "repetition": 3,
        "generated_text": " 87",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "87",
            0.02429979480803013
          ]
        ],
        "inference_time": 1.7670629024505615
      },
      {
        "repetition": 4,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.10230595618486404
          ]
        ],
        "inference_time": 1.7681491374969482
      },
      {
        "repetition": 5,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.1442745327949524
          ]
        ],
        "inference_time": 1.7689037322998047
      },
      {
        "repetition": 6,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.09028469771146774
          ]
        ],
        "inference_time": 1.7710566520690918
      },
      {
        "repetition": 7,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.11960778385400772
          ]
        ],
        "inference_time": 1.7712852954864502
      },
      {
        "repetition": 8,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.11960778385400772
          ]
        ],
        "inference_time": 1.7681481838226318
      },
      {
        "repetition": 9,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.1442745327949524
          ]
        ],
        "inference_time": 1.768336534500122
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 54,
    "sentence": "Beks then shared a clip of what happened straight after and continues: \"It was my lunch break and I just dipped out and didn't tell anybody.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.02001001127064228
          ]
        ],
        "inference_time": 1.7704718112945557
      },
      {
        "repetition": 1,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.05004385858774185
          ]
        ],
        "inference_time": 1.769864797592163
      },
      {
        "repetition": 2,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.05004385858774185
          ]
        ],
        "inference_time": 1.7689952850341797
      },
      {
        "repetition": 3,
        "generated_text": " 13",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "13",
            0.009551036171615124
          ]
        ],
        "inference_time": 1.768244981765747
      },
      {
        "repetition": 4,
        "generated_text": " 35",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "35",
            0.013054720126092434
          ]
        ],
        "inference_time": 1.7685728073120117
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.10930583626031876
          ]
        ],
        "inference_time": 1.7687020301818848
      },
      {
        "repetition": 6,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.09447324275970459
          ]
        ],
        "inference_time": 1.7690956592559814
      },
      {
        "repetition": 7,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.08165334910154343
          ]
        ],
        "inference_time": 1.7675328254699707
      },
      {
        "repetition": 8,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.09447324275970459
          ]
        ],
        "inference_time": 1.7708909511566162
      },
      {
        "repetition": 9,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.07357583940029144
          ]
        ],
        "inference_time": 1.7719838619232178
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 55,
    "sentence": "I know you was heartbroken lol.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9627412557601929
          ],
          [
            "20",
            0.05181027576327324
          ]
        ],
        "inference_time": 1.736485481262207
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9627412557601929
          ],
          [
            "0",
            0.1393754631280899
          ]
        ],
        "inference_time": 1.7365272045135498
      },
      {
        "repetition": 2,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.9627412557601929
          ],
          [
            "25",
            0.049180857837200165
          ]
        ],
        "inference_time": 1.7349739074707031
      },
      {
        "repetition": 3,
        "generated_text": " 99",
        "token_probs": [
          [
            " ",
            0.9627412557601929
          ],
          [
            "99",
            0.013515517115592957
          ]
        ],
        "inference_time": 1.736466646194458
      },
      {
        "repetition": 4,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            0.9627412557601929
          ],
          [
            "95",
            0.04206661507487297
          ]
        ],
        "inference_time": 1.7374300956726074
      },
      {
        "repetition": 5,
        "generated_text": " 8",
        "token_probs": [
          [
            " ",
            0.9627412557601929
          ],
          [
            "8",
            0.013099689036607742
          ]
        ],
        "inference_time": 1.7373061180114746
      },
      {
        "repetition": 6,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9627412557601929
          ],
          [
            "20",
            0.05181027576327324
          ]
        ],
        "inference_time": 1.7370860576629639
      },
      {
        "repetition": 7,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            0.9627412557601929
          ],
          [
            "5",
            0.031424522399902344
          ]
        ],
        "inference_time": 1.7346711158752441
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9627412557601929
          ],
          [
            "0",
            0.1393754631280899
          ]
        ],
        "inference_time": 1.7360289096832275
      },
      {
        "repetition": 9,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9627412557601929
          ],
          [
            "100",
            0.09092985838651657
          ]
        ],
        "inference_time": 1.738060712814331
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 56,
    "sentence": "\u201cI can\u2019t say I add anything to her life but she certainly brightens up mine.\u201d  Brunero begs to differ.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.01584642380475998
          ]
        ],
        "inference_time": 1.7696223258972168
      },
      {
        "repetition": 1,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.24276885390281677
          ]
        ],
        "inference_time": 1.7711098194122314
      },
      {
        "repetition": 2,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "60",
            0.029914991930127144
          ]
        ],
        "inference_time": 1.770655870437622
      },
      {
        "repetition": 3,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.0779988244175911
          ]
        ],
        "inference_time": 1.7666454315185547
      },
      {
        "repetition": 4,
        "generated_text": "  ",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            " ",
            0.01961873285472393
          ]
        ],
        "inference_time": 1.7682371139526367
      },
      {
        "repetition": 5,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.0779988244175911
          ]
        ],
        "inference_time": 1.765216588973999
      },
      {
        "repetition": 6,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.047308675944805145
          ]
        ],
        "inference_time": 1.7693908214569092
      },
      {
        "repetition": 7,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.04537796974182129
          ]
        ],
        "inference_time": 1.7682178020477295
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.060745544731616974
          ]
        ],
        "inference_time": 1.7697958946228027
      },
      {
        "repetition": 9,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "100",
            0.05250244960188866
          ]
        ],
        "inference_time": 1.7669217586517334
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 57,
    "sentence": "But while Leo Woodall is enjoying a career boost for his portrayal as 'pampered Southern toff' Dexter Mayhew, the 2011 film adaptation had the exact opposite effect for actor Jim Sturgess.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.043473221361637115
          ]
        ],
        "inference_time": 1.7719707489013672
      },
      {
        "repetition": 1,
        "generated_text": " 35",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "35",
            0.009160073474049568
          ]
        ],
        "inference_time": 1.772355318069458
      },
      {
        "repetition": 2,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.07472480833530426
          ]
        ],
        "inference_time": 1.7745847702026367
      },
      {
        "repetition": 3,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.043473221361637115
          ]
        ],
        "inference_time": 1.7712454795837402
      },
      {
        "repetition": 4,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.07472480833530426
          ]
        ],
        "inference_time": 1.7725098133087158
      },
      {
        "repetition": 5,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.07790414988994598
          ]
        ],
        "inference_time": 1.7726249694824219
      },
      {
        "repetition": 6,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.14254321157932281
          ]
        ],
        "inference_time": 1.7710893154144287
      },
      {
        "repetition": 7,
        "generated_text": " 87",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "87",
            0.013537711463868618
          ]
        ],
        "inference_time": 1.7719368934631348
      },
      {
        "repetition": 8,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "60",
            0.047745998948812485
          ]
        ],
        "inference_time": 1.773555040359497
      },
      {
        "repetition": 9,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.07790414988994598
          ]
        ],
        "inference_time": 1.7728090286254883
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 58,
    "sentence": "I scribbled down what I saw and what I felt and the song kind of wrote itself.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.15163978934288025
          ]
        ],
        "inference_time": 1.7688000202178955
      },
      {
        "repetition": 1,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.058158617466688156
          ]
        ],
        "inference_time": 1.7692227363586426
      },
      {
        "repetition": 2,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "95",
            0.032454561442136765
          ]
        ],
        "inference_time": 1.7681491374969482
      },
      {
        "repetition": 3,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.009643643163144588
          ]
        ],
        "inference_time": 1.7665331363677979
      },
      {
        "repetition": 4,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.027187518775463104
          ]
        ],
        "inference_time": 1.767547607421875
      },
      {
        "repetition": 5,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.11566220968961716
          ]
        ],
        "inference_time": 1.7675049304962158
      },
      {
        "repetition": 6,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.10531163960695267
          ]
        ],
        "inference_time": 1.7672455310821533
      },
      {
        "repetition": 7,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.15163978934288025
          ]
        ],
        "inference_time": 1.7683682441711426
      },
      {
        "repetition": 8,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.058158617466688156
          ]
        ],
        "inference_time": 1.769418478012085
      },
      {
        "repetition": 9,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.10531163960695267
          ]
        ],
        "inference_time": 1.7691214084625244
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 59,
    "sentence": "In the first image, the Emmy-nominated actress embraced Blanco, who has a passion for cooking, while he was preparing a platter of meatballs.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.17787407338619232
          ]
        ],
        "inference_time": 1.7674615383148193
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.25612330436706543
          ]
        ],
        "inference_time": 1.7705156803131104
      },
      {
        "repetition": 2,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.1045667827129364
          ]
        ],
        "inference_time": 1.7689027786254883
      },
      {
        "repetition": 3,
        "generated_text": " 1",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "1",
            0.025359639897942543
          ]
        ],
        "inference_time": 1.7684683799743652
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.25612330436706543
          ]
        ],
        "inference_time": 1.7688236236572266
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.25612330436706543
          ]
        ],
        "inference_time": 1.768049716949463
      },
      {
        "repetition": 6,
        "generated_text": " 12",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "12",
            0.01975010707974434
          ]
        ],
        "inference_time": 1.77113676071167
      },
      {
        "repetition": 7,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.09132357686758041
          ]
        ],
        "inference_time": 1.768507480621338
      },
      {
        "repetition": 8,
        "generated_text": " 4",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "4",
            0.024072639644145966
          ]
        ],
        "inference_time": 1.7716097831726074
      },
      {
        "repetition": 9,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.1045667827129364
          ]
        ],
        "inference_time": 1.7696678638458252
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 60,
    "sentence": "It follows their range of Unmanned Surface Vehicles (USVs) which have been hugely successful in Black Sea attacks.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 45",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "45",
            0.008914103731513023
          ]
        ],
        "inference_time": 1.7676804065704346
      },
      {
        "repetition": 1,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.19460418820381165
          ]
        ],
        "inference_time": 1.7706995010375977
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.13799501955509186
          ]
        ],
        "inference_time": 1.7654902935028076
      },
      {
        "repetition": 3,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.0529254674911499
          ]
        ],
        "inference_time": 1.7689719200134277
      },
      {
        "repetition": 4,
        "generated_text": " 4",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "4",
            0.029843520373106003
          ]
        ],
        "inference_time": 1.766972541809082
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.13799501955509186
          ]
        ],
        "inference_time": 1.769697904586792
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.13799501955509186
          ]
        ],
        "inference_time": 1.7711687088012695
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.13799501955509186
          ]
        ],
        "inference_time": 1.7697720527648926
      },
      {
        "repetition": 8,
        "generated_text": " 8",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "8",
            0.021383821964263916
          ]
        ],
        "inference_time": 1.7688093185424805
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.13799501955509186
          ]
        ],
        "inference_time": 1.7703673839569092
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 61,
    "sentence": "But one person who knows exactly what's that like after getting the winning number on a scratchcard has told how they were left bitterly \"disappointed.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            0.9623900055885315
          ],
          [
            "60",
            0.06504326313734055
          ]
        ],
        "inference_time": 1.7730257511138916
      },
      {
        "repetition": 1,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9623900055885315
          ],
          [
            "50",
            0.14966292679309845
          ]
        ],
        "inference_time": 1.7715668678283691
      },
      {
        "repetition": 2,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            0.9623900055885315
          ],
          [
            "85",
            0.022951552644371986
          ]
        ],
        "inference_time": 1.7704682350158691
      },
      {
        "repetition": 3,
        "generated_text": " 8",
        "token_probs": [
          [
            " ",
            0.9623900055885315
          ],
          [
            "8",
            0.012941892258822918
          ]
        ],
        "inference_time": 1.771411657333374
      },
      {
        "repetition": 4,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9623900055885315
          ],
          [
            "80",
            0.12537416815757751
          ]
        ],
        "inference_time": 1.7711334228515625
      },
      {
        "repetition": 5,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9623900055885315
          ],
          [
            "75",
            0.08010879158973694
          ]
        ],
        "inference_time": 1.7725186347961426
      },
      {
        "repetition": 6,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9623900055885315
          ],
          [
            "20",
            0.07370366901159286
          ]
        ],
        "inference_time": 1.7662341594696045
      },
      {
        "repetition": 7,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            0.9623900055885315
          ],
          [
            "60",
            0.06504326313734055
          ]
        ],
        "inference_time": 1.7715208530426025
      },
      {
        "repetition": 8,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            0.9623900055885315
          ],
          [
            "85",
            0.022951552644371986
          ]
        ],
        "inference_time": 1.7688977718353271
      },
      {
        "repetition": 9,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9623900055885315
          ],
          [
            "75",
            0.08010879158973694
          ]
        ],
        "inference_time": 1.7672977447509766
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 62,
    "sentence": "Selena looked chic in a brown turtleneck, with her hair brushed back into a ponytail, while her other half rocked a white tee, and gold chains.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.990190863609314
          ],
          [
            "90",
            0.05544028803706169
          ]
        ],
        "inference_time": 1.7698063850402832
      },
      {
        "repetition": 1,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            0.990190863609314
          ],
          [
            "85",
            0.018377728760242462
          ]
        ],
        "inference_time": 1.7700464725494385
      },
      {
        "repetition": 2,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.990190863609314
          ],
          [
            "100",
            0.02967504784464836
          ]
        ],
        "inference_time": 1.7681617736816406
      },
      {
        "repetition": 3,
        "generated_text": " 12",
        "token_probs": [
          [
            " ",
            0.990190863609314
          ],
          [
            "12",
            0.010149145498871803
          ]
        ],
        "inference_time": 1.7694759368896484
      },
      {
        "repetition": 4,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.990190863609314
          ],
          [
            "100",
            0.02967504784464836
          ]
        ],
        "inference_time": 1.767702579498291
      },
      {
        "repetition": 5,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            0.990190863609314
          ],
          [
            "70",
            0.02846398390829563
          ]
        ],
        "inference_time": 1.7675480842590332
      },
      {
        "repetition": 6,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.990190863609314
          ],
          [
            "50",
            0.14606569707393646
          ]
        ],
        "inference_time": 1.7691633701324463
      },
      {
        "repetition": 7,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.990190863609314
          ],
          [
            "20",
            0.09045835584402084
          ]
        ],
        "inference_time": 1.770050287246704
      },
      {
        "repetition": 8,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.990190863609314
          ],
          [
            "20",
            0.09045835584402084
          ]
        ],
        "inference_time": 1.7719085216522217
      },
      {
        "repetition": 9,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            0.990190863609314
          ],
          [
            "60",
            0.04141484573483467
          ]
        ],
        "inference_time": 1.7733514308929443
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 63,
    "sentence": "The refreshing beer-and-fizzy-pop combination bubbled away as a quietly constant \u2013 if not cult \u2013 pub choice for over half my lifetime, then seemed to fizzle out over the past 15 years.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9345125555992126
          ],
          [
            "100",
            0.017093174159526825
          ]
        ],
        "inference_time": 1.773514747619629
      },
      {
        "repetition": 1,
        "generated_text": " 3",
        "token_probs": [
          [
            " ",
            0.9345125555992126
          ],
          [
            "3",
            0.010206801816821098
          ]
        ],
        "inference_time": 1.7711257934570312
      },
      {
        "repetition": 2,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            0.9345125555992126
          ],
          [
            "10",
            0.02461269311606884
          ]
        ],
        "inference_time": 1.7690045833587646
      },
      {
        "repetition": 3,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9345125555992126
          ],
          [
            "20",
            0.07986560463905334
          ]
        ],
        "inference_time": 1.7705132961273193
      },
      {
        "repetition": 4,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9345125555992126
          ],
          [
            "50",
            0.09633630514144897
          ]
        ],
        "inference_time": 1.7727000713348389
      },
      {
        "repetition": 5,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            0.9345125555992126
          ],
          [
            "30",
            0.046464063227176666
          ]
        ],
        "inference_time": 1.7701103687286377
      },
      {
        "repetition": 6,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9345125555992126
          ],
          [
            "50",
            0.09633630514144897
          ]
        ],
        "inference_time": 1.7718136310577393
      },
      {
        "repetition": 7,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9345125555992126
          ],
          [
            "90",
            0.04364895075559616
          ]
        ],
        "inference_time": 1.7729644775390625
      },
      {
        "repetition": 8,
        "generated_text": " 67",
        "token_probs": [
          [
            " ",
            0.9345125555992126
          ],
          [
            "67",
            0.014620567671954632
          ]
        ],
        "inference_time": 1.7700679302215576
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9345125555992126
          ],
          [
            "0",
            0.07502678781747818
          ]
        ],
        "inference_time": 1.7723217010498047
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 64,
    "sentence": "Kyiv continues to target Russia\u2019s Black Sea Fleet with great effectDr Bastian Giegerich, IISS security analyst  And Vlad's Black Sea fleet was \"put on the defensive by several events\", which included the sea drone attack in December that \"badly damaged a landing ship off Novorossiysk\".",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9288713932037354
          ],
          [
            "0",
            0.11933338642120361
          ]
        ],
        "inference_time": 1.7765014171600342
      },
      {
        "repetition": 1,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            0.9288713932037354
          ],
          [
            "30",
            0.05520690977573395
          ]
        ],
        "inference_time": 1.7743959426879883
      },
      {
        "repetition": 2,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            0.9288713932037354
          ],
          [
            "40",
            0.03754991292953491
          ]
        ],
        "inference_time": 1.7750341892242432
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9288713932037354
          ],
          [
            "0",
            0.11933338642120361
          ]
        ],
        "inference_time": 1.7758963108062744
      },
      {
        "repetition": 4,
        "generated_text": " 35",
        "token_probs": [
          [
            " ",
            0.9288713932037354
          ],
          [
            "35",
            0.018110739067196846
          ]
        ],
        "inference_time": 1.775517463684082
      },
      {
        "repetition": 5,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.9288713932037354
          ],
          [
            "25",
            0.0477154441177845
          ]
        ],
        "inference_time": 1.7743713855743408
      },
      {
        "repetition": 6,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            0.9288713932037354
          ],
          [
            "10",
            0.07237935811281204
          ]
        ],
        "inference_time": 1.773552417755127
      },
      {
        "repetition": 7,
        "generated_text": " 4",
        "token_probs": [
          [
            " ",
            0.9288713932037354
          ],
          [
            "4",
            0.027472104877233505
          ]
        ],
        "inference_time": 1.775162935256958
      },
      {
        "repetition": 8,
        "generated_text": " 45",
        "token_probs": [
          [
            " ",
            0.9288713932037354
          ],
          [
            "45",
            0.01425234042108059
          ]
        ],
        "inference_time": 1.7765564918518066
      },
      {
        "repetition": 9,
        "generated_text": " 35",
        "token_probs": [
          [
            " ",
            0.9288713932037354
          ],
          [
            "35",
            0.018110739067196846
          ]
        ],
        "inference_time": 1.7718007564544678
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 65,
    "sentence": "\u201cIt\u2019s such a bonus \u2013 sometimes I cook for her, sometimes she cooks for me, we play cards, we watch TV and we chat,\u201d Hamilton says.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            0.9598456025123596
          ],
          [
            "95",
            0.014407435432076454
          ]
        ],
        "inference_time": 1.7700586318969727
      },
      {
        "repetition": 1,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9598456025123596
          ],
          [
            "50",
            0.10983666777610779
          ]
        ],
        "inference_time": 1.769728183746338
      },
      {
        "repetition": 2,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9598456025123596
          ],
          [
            "50",
            0.10983666777610779
          ]
        ],
        "inference_time": 1.7690744400024414
      },
      {
        "repetition": 3,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            0.9598456025123596
          ],
          [
            "70",
            0.04125726968050003
          ]
        ],
        "inference_time": 1.7710423469543457
      },
      {
        "repetition": 4,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9598456025123596
          ],
          [
            "20",
            0.13387565314769745
          ]
        ],
        "inference_time": 1.771782636642456
      },
      {
        "repetition": 5,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            0.9598456025123596
          ],
          [
            "30",
            0.04484272748231888
          ]
        ],
        "inference_time": 1.771765947341919
      },
      {
        "repetition": 6,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            0.9598456025123596
          ],
          [
            "60",
            0.05242645740509033
          ]
        ],
        "inference_time": 1.7695653438568115
      },
      {
        "repetition": 7,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9598456025123596
          ],
          [
            "90",
            0.03213119879364967
          ]
        ],
        "inference_time": 1.7700695991516113
      },
      {
        "repetition": 8,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.9598456025123596
          ],
          [
            "25",
            0.04578673467040062
          ]
        ],
        "inference_time": 1.773294448852539
      },
      {
        "repetition": 9,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            0.9598456025123596
          ],
          [
            "70",
            0.04125726968050003
          ]
        ],
        "inference_time": 1.7708654403686523
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 66,
    "sentence": "She was fairly close to Wangari, and recalls with sadness how she had promised to send her money the following week so she could move to a new flat.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 6",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "6",
            0.009866766631603241
          ]
        ],
        "inference_time": 1.7726492881774902
      },
      {
        "repetition": 1,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.04111016169190407
          ]
        ],
        "inference_time": 1.7711949348449707
      },
      {
        "repetition": 2,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.19409316778182983
          ]
        ],
        "inference_time": 1.7728750705718994
      },
      {
        "repetition": 3,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.09558398276567459
          ]
        ],
        "inference_time": 1.7714896202087402
      },
      {
        "repetition": 4,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "60",
            0.020887944847345352
          ]
        ],
        "inference_time": 1.7716107368469238
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.09861814230680466
          ]
        ],
        "inference_time": 1.7745275497436523
      },
      {
        "repetition": 6,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.19409316778182983
          ]
        ],
        "inference_time": 1.7708489894866943
      },
      {
        "repetition": 7,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.06993073970079422
          ]
        ],
        "inference_time": 1.772536277770996
      },
      {
        "repetition": 8,
        "generated_text": " 23",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "23",
            0.016959670931100845
          ]
        ],
        "inference_time": 1.7699334621429443
      },
      {
        "repetition": 9,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.05389772355556488
          ]
        ],
        "inference_time": 1.771618127822876
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 67,
    "sentence": "And it could even be used to gather intelligence on Russian operations.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.10724937915802002
          ]
        ],
        "inference_time": 1.7704336643218994
      },
      {
        "repetition": 1,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.1749919056892395
          ]
        ],
        "inference_time": 1.7711904048919678
      },
      {
        "repetition": 2,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.03864137828350067
          ]
        ],
        "inference_time": 1.771827220916748
      },
      {
        "repetition": 3,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.0976516604423523
          ]
        ],
        "inference_time": 1.7689530849456787
      },
      {
        "repetition": 4,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.0976516604423523
          ]
        ],
        "inference_time": 1.7691316604614258
      },
      {
        "repetition": 5,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.07448320835828781
          ]
        ],
        "inference_time": 1.7692596912384033
      },
      {
        "repetition": 6,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.1749919056892395
          ]
        ],
        "inference_time": 1.7700026035308838
      },
      {
        "repetition": 7,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.1749919056892395
          ]
        ],
        "inference_time": 1.7696254253387451
      },
      {
        "repetition": 8,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.016619449481368065
          ]
        ],
        "inference_time": 1.7704389095306396
      },
      {
        "repetition": 9,
        "generated_text": " 45",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "45",
            0.011070940643548965
          ]
        ],
        "inference_time": 1.77101731300354
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 68,
    "sentence": "\"I'm not really a gambler - it was a $10k (\u00a37.9k) a week for life scratch card and I scratched it off.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            0.9885509610176086
          ],
          [
            "5",
            0.08132456988096237
          ]
        ],
        "inference_time": 1.7679898738861084
      },
      {
        "repetition": 1,
        "generated_text": " 12",
        "token_probs": [
          [
            " ",
            0.9885509610176086
          ],
          [
            "12",
            0.01458069123327732
          ]
        ],
        "inference_time": 1.7691147327423096
      },
      {
        "repetition": 2,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            0.9885509610176086
          ],
          [
            "85",
            0.012087817303836346
          ]
        ],
        "inference_time": 1.7728936672210693
      },
      {
        "repetition": 3,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            0.9885509610176086
          ],
          [
            "5",
            0.08132456988096237
          ]
        ],
        "inference_time": 1.7727670669555664
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9885509610176086
          ],
          [
            "0",
            0.21877223253250122
          ]
        ],
        "inference_time": 1.768322467803955
      },
      {
        "repetition": 5,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            0.9885509610176086
          ],
          [
            "5",
            0.08132456988096237
          ]
        ],
        "inference_time": 1.7697701454162598
      },
      {
        "repetition": 6,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            0.9885509610176086
          ],
          [
            "5",
            0.08132456988096237
          ]
        ],
        "inference_time": 1.7700791358947754
      },
      {
        "repetition": 7,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            0.9885509610176086
          ],
          [
            "30",
            0.04307880625128746
          ]
        ],
        "inference_time": 1.768967866897583
      },
      {
        "repetition": 8,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            0.9885509610176086
          ],
          [
            "2",
            0.024291202425956726
          ]
        ],
        "inference_time": 1.7728698253631592
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9885509610176086
          ],
          [
            "0",
            0.21877223253250122
          ]
        ],
        "inference_time": 1.7709076404571533
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 69,
    "sentence": "When it was an Emma and Dex day I felt good about it.'",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " \n50",
        "token_probs": [
          [
            " \n",
            0.007785593159496784
          ],
          [
            "50",
            0.07618444412946701
          ]
        ],
        "inference_time": 1.7683217525482178
      },
      {
        "repetition": 1,
        "generated_text": " <put",
        "token_probs": [
          [
            " <",
            0.006522067356854677
          ],
          [
            "put",
            0.04257611185312271
          ]
        ],
        "inference_time": 1.7700896263122559
      },
      {
        "repetition": 2,
        "generated_text": " ( Your",
        "token_probs": [
          [
            " (",
            0.01564563438296318
          ],
          [
            " Your",
            0.015528363175690174
          ]
        ],
        "inference_time": 1.768599271774292
      },
      {
        "repetition": 3,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.867674708366394
          ],
          [
            "100",
            0.1625208854675293
          ]
        ],
        "inference_time": 1.7699341773986816
      },
      {
        "repetition": 4,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.867674708366394
          ],
          [
            "20",
            0.017308946698904037
          ]
        ],
        "inference_time": 1.766045331954956
      },
      {
        "repetition": 5,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            0.867674708366394
          ],
          [
            "95",
            0.0610467866063118
          ]
        ],
        "inference_time": 1.768730878829956
      },
      {
        "repetition": 6,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.867674708366394
          ],
          [
            "75",
            0.08344106376171112
          ]
        ],
        "inference_time": 1.7702560424804688
      },
      {
        "repetition": 7,
        "generated_text": " Unknown/",
        "token_probs": [
          [
            " Unknown",
            0.006321404594928026
          ],
          [
            "/",
            0.012416395358741283
          ]
        ],
        "inference_time": 1.7649867534637451
      },
      {
        "repetition": 8,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.867674708366394
          ],
          [
            "100",
            0.1625208854675293
          ]
        ],
        "inference_time": 1.7667791843414307
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.867674708366394
          ],
          [
            "0",
            0.05387359485030174
          ]
        ],
        "inference_time": 1.7678189277648926
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 70,
    "sentence": "RULE 10: BE HAPPY  She then advised: \u201cLike the song don\u2019t worry be happy and create a life of meaningful memories.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9901401400566101
          ],
          [
            "75",
            0.05939210206270218
          ]
        ],
        "inference_time": 1.767174482345581
      },
      {
        "repetition": 1,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9901401400566101
          ],
          [
            "100",
            0.13524369895458221
          ]
        ],
        "inference_time": 1.7714219093322754
      },
      {
        "repetition": 2,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9901401400566101
          ],
          [
            "50",
            0.1454736888408661
          ]
        ],
        "inference_time": 1.7679939270019531
      },
      {
        "repetition": 3,
        "generated_text": " 96",
        "token_probs": [
          [
            " ",
            0.9901401400566101
          ],
          [
            "96",
            0.008966866880655289
          ]
        ],
        "inference_time": 1.7699036598205566
      },
      {
        "repetition": 4,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            0.9901401400566101
          ],
          [
            "85",
            0.02374792844057083
          ]
        ],
        "inference_time": 1.769752025604248
      },
      {
        "repetition": 5,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9901401400566101
          ],
          [
            "80",
            0.1395367830991745
          ]
        ],
        "inference_time": 1.7709174156188965
      },
      {
        "repetition": 6,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9901401400566101
          ],
          [
            "100",
            0.13524369895458221
          ]
        ],
        "inference_time": 1.7706665992736816
      },
      {
        "repetition": 7,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            0.9901401400566101
          ],
          [
            "40",
            0.025811711326241493
          ]
        ],
        "inference_time": 1.7698960304260254
      },
      {
        "repetition": 8,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            0.9901401400566101
          ],
          [
            "95",
            0.043001942336559296
          ]
        ],
        "inference_time": 1.7713356018066406
      },
      {
        "repetition": 9,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9901401400566101
          ],
          [
            "80",
            0.1395367830991745
          ]
        ],
        "inference_time": 1.7708954811096191
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 71,
    "sentence": "But perhaps most impressively, Ukrainian forces managed to blow up Russia's flagship vessel - the Moskva - in April 2022.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.17236053943634033
          ]
        ],
        "inference_time": 1.7724928855895996
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3536608815193176
          ]
        ],
        "inference_time": 1.7693085670471191
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3536608815193176
          ]
        ],
        "inference_time": 1.7682456970214844
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3536608815193176
          ]
        ],
        "inference_time": 1.7713091373443604
      },
      {
        "repetition": 4,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.1222219318151474
          ]
        ],
        "inference_time": 1.7693719863891602
      },
      {
        "repetition": 5,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.1222219318151474
          ]
        ],
        "inference_time": 1.7694458961486816
      },
      {
        "repetition": 6,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.17236053943634033
          ]
        ],
        "inference_time": 1.771082878112793
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3536608815193176
          ]
        ],
        "inference_time": 1.769838571548462
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3536608815193176
          ]
        ],
        "inference_time": 1.771759033203125
      },
      {
        "repetition": 9,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.17236053943634033
          ]
        ],
        "inference_time": 1.7726280689239502
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 72,
    "sentence": "But Michelle evidently didn't hold the blunder against him; the couple have been married since 2015 after meeting in late 2012.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.16429394483566284
          ]
        ],
        "inference_time": 1.772759199142456
      },
      {
        "repetition": 1,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.050631508231163025
          ]
        ],
        "inference_time": 1.772148609161377
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.16429394483566284
          ]
        ],
        "inference_time": 1.7701811790466309
      },
      {
        "repetition": 3,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.02545912191271782
          ]
        ],
        "inference_time": 1.7728614807128906
      },
      {
        "repetition": 4,
        "generated_text": " 67",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "67",
            0.008983658626675606
          ]
        ],
        "inference_time": 1.7685863971710205
      },
      {
        "repetition": 5,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11650184541940689
          ]
        ],
        "inference_time": 1.7684407234191895
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.16429394483566284
          ]
        ],
        "inference_time": 1.7721946239471436
      },
      {
        "repetition": 7,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.015441738069057465
          ]
        ],
        "inference_time": 1.7717151641845703
      },
      {
        "repetition": 8,
        "generated_text": " 4",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "4",
            0.013003246858716011
          ]
        ],
        "inference_time": 1.7700495719909668
      },
      {
        "repetition": 9,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.07521925121545792
          ]
        ],
        "inference_time": 1.7695510387420654
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 73,
    "sentence": "Vigils, dubbed \u201cDark Valentine\u201d, were held across Kenya this week after a month in which more than a dozen women have been killed, allegedly by their partners.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.1596977859735489
          ]
        ],
        "inference_time": 1.7752799987792969
      },
      {
        "repetition": 1,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.1596977859735489
          ]
        ],
        "inference_time": 1.7727901935577393
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.22056670486927032
          ]
        ],
        "inference_time": 1.7716898918151855
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.22056670486927032
          ]
        ],
        "inference_time": 1.7737388610839844
      },
      {
        "repetition": 4,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.10418833792209625
          ]
        ],
        "inference_time": 1.7703888416290283
      },
      {
        "repetition": 5,
        "generated_text": " 12",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "12",
            0.014100356958806515
          ]
        ],
        "inference_time": 1.7720372676849365
      },
      {
        "repetition": 6,
        "generated_text": " 4",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "4",
            0.026342937722802162
          ]
        ],
        "inference_time": 1.7722976207733154
      },
      {
        "repetition": 7,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.10418833792209625
          ]
        ],
        "inference_time": 1.7721693515777588
      },
      {
        "repetition": 8,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.1596977859735489
          ]
        ],
        "inference_time": 1.7741060256958008
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.22056670486927032
          ]
        ],
        "inference_time": 1.77122163772583
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 74,
    "sentence": "The radio presenter revealed the Fool Me Once star rumbled his porky pies the next day and fumed: 'Mark, you're a liar!'",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9158970713615417
          ],
          [
            "100",
            0.1111394613981247
          ]
        ],
        "inference_time": 1.7695245742797852
      },
      {
        "repetition": 1,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9158970713615417
          ],
          [
            "20",
            0.04262546822428703
          ]
        ],
        "inference_time": 1.7716150283813477
      },
      {
        "repetition": 2,
        "generated_text": " 92",
        "token_probs": [
          [
            " ",
            0.9158970713615417
          ],
          [
            "92",
            0.0237865149974823
          ]
        ],
        "inference_time": 1.7719497680664062
      },
      {
        "repetition": 3,
        "generated_text": " 83",
        "token_probs": [
          [
            " ",
            0.9158970713615417
          ],
          [
            "83",
            0.008135211654007435
          ]
        ],
        "inference_time": 1.7727892398834229
      },
      {
        "repetition": 4,
        "generated_text": " 88",
        "token_probs": [
          [
            " ",
            0.9158970713615417
          ],
          [
            "88",
            0.012212399393320084
          ]
        ],
        "inference_time": 1.7719852924346924
      },
      {
        "repetition": 5,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9158970713615417
          ],
          [
            "75",
            0.044904399663209915
          ]
        ],
        "inference_time": 1.76957368850708
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9158970713615417
          ],
          [
            "0",
            0.06533551216125488
          ]
        ],
        "inference_time": 1.770009994506836
      },
      {
        "repetition": 7,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9158970713615417
          ],
          [
            "90",
            0.07481002062559128
          ]
        ],
        "inference_time": 1.7700855731964111
      },
      {
        "repetition": 8,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9158970713615417
          ],
          [
            "100",
            0.1111394613981247
          ]
        ],
        "inference_time": 1.771254539489746
      },
      {
        "repetition": 9,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.9158970713615417
          ],
          [
            "25",
            0.03645949065685272
          ]
        ],
        "inference_time": 1.7728815078735352
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 75,
    "sentence": "The snap comes after Selena surprised fans on Monday with a very racy photo of Benny grabbing her cleavage  Gomez has been linked with Blanco, a musical artist, producer, and songwriter, since last year  In the first image from the post, the Emmy-nominated actress embraced Blanco, who has a passion for cooking, while he was preparing a platter of meatballs  Blanco was posed behind Gomez as they relaxed in the kitchen area of a home alongside friends including The Bear actor Matty Matheson  On Sunday, the couple was seen kissing one another while posed against a velvet red couch in a shot Gomez posted to Instagram  Gomez and Blanco have frequently shared their light-hearted and romantic moments via Instagram in the early days of their relationship.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.05288325995206833
          ]
        ],
        "inference_time": 1.856201410293579
      },
      {
        "repetition": 1,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.05179288983345032
          ]
        ],
        "inference_time": 1.8558886051177979
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.17160063982009888
          ]
        ],
        "inference_time": 1.855726957321167
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.17160063982009888
          ]
        ],
        "inference_time": 1.853123426437378
      },
      {
        "repetition": 4,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.14831478893756866
          ]
        ],
        "inference_time": 1.8544504642486572
      },
      {
        "repetition": 5,
        "generated_text": " 12",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "12",
            0.02204502373933792
          ]
        ],
        "inference_time": 1.8568177223205566
      },
      {
        "repetition": 6,
        "generated_text": " 14",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "14",
            0.010092947632074356
          ]
        ],
        "inference_time": 1.8533446788787842
      },
      {
        "repetition": 7,
        "generated_text": " 7",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "7",
            0.008814692497253418
          ]
        ],
        "inference_time": 1.8569104671478271
      },
      {
        "repetition": 8,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.020494773983955383
          ]
        ],
        "inference_time": 1.8530795574188232
      },
      {
        "repetition": 9,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.14831478893756866
          ]
        ],
        "inference_time": 1.8567166328430176
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 76,
    "sentence": "November 17, 2023  Sir, your article \u2018BBC crisis over \u00a31.7bn pension bill for stars\u2019 (4/11/2023) is incorrect and significantly inflates the BBC\u2019s obligation to fund its defined benefit pension scheme shortfall and employer contribution rate.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "95",
            0.08729198575019836
          ]
        ],
        "inference_time": 1.7738611698150635
      },
      {
        "repetition": 1,
        "generated_text": " 99",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "99",
            0.06520861387252808
          ]
        ],
        "inference_time": 1.7753446102142334
      },
      {
        "repetition": 2,
        "generated_text": " 98",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "98",
            0.05577588453888893
          ]
        ],
        "inference_time": 1.7757184505462646
      },
      {
        "repetition": 3,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.021391818299889565
          ]
        ],
        "inference_time": 1.7785463333129883
      },
      {
        "repetition": 4,
        "generated_text": " 93",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "93",
            0.014399228617548943
          ]
        ],
        "inference_time": 1.7760815620422363
      },
      {
        "repetition": 5,
        "generated_text": " 97",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "97",
            0.027755238115787506
          ]
        ],
        "inference_time": 1.7727267742156982
      },
      {
        "repetition": 6,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "100",
            0.16308288276195526
          ]
        ],
        "inference_time": 1.775559425354004
      },
      {
        "repetition": 7,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.03211292251944542
          ]
        ],
        "inference_time": 1.7776834964752197
      },
      {
        "repetition": 8,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "95",
            0.08729198575019836
          ]
        ],
        "inference_time": 1.7785768508911133
      },
      {
        "repetition": 9,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.06520861387252808
          ]
        ],
        "inference_time": 1.7748303413391113
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 77,
    "sentence": "The crime currently falls under homicide provisions, which rights groups say do not account for the unequal power relations between men and women that drive and characterise the killings.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9548416137695312
          ],
          [
            "80",
            0.0915260910987854
          ]
        ],
        "inference_time": 1.7722141742706299
      },
      {
        "repetition": 1,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9548416137695312
          ],
          [
            "50",
            0.09443143010139465
          ]
        ],
        "inference_time": 1.771742582321167
      },
      {
        "repetition": 2,
        "generated_text": " {Your",
        "token_probs": [
          [
            " {",
            0.01286169420927763
          ],
          [
            "Your",
            0.11856696754693985
          ]
        ],
        "inference_time": 1.7702887058258057
      },
      {
        "repetition": 3,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9548416137695312
          ],
          [
            "20",
            0.13316966593265533
          ]
        ],
        "inference_time": 1.7759730815887451
      },
      {
        "repetition": 4,
        "generated_text": " 26",
        "token_probs": [
          [
            " ",
            0.9548416137695312
          ],
          [
            "26",
            0.013463160023093224
          ]
        ],
        "inference_time": 1.7735300064086914
      },
      {
        "repetition": 5,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9548416137695312
          ],
          [
            "80",
            0.0915260910987854
          ]
        ],
        "inference_time": 1.7719180583953857
      },
      {
        "repetition": 6,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9548416137695312
          ],
          [
            "80",
            0.0915260910987854
          ]
        ],
        "inference_time": 1.7747681140899658
      },
      {
        "repetition": 7,
        "generated_text": " 26",
        "token_probs": [
          [
            " ",
            0.9548416137695312
          ],
          [
            "26",
            0.013463160023093224
          ]
        ],
        "inference_time": 1.7736577987670898
      },
      {
        "repetition": 8,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9548416137695312
          ],
          [
            "20",
            0.13316966593265533
          ]
        ],
        "inference_time": 1.774409294128418
      },
      {
        "repetition": 9,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9548416137695312
          ],
          [
            "20",
            0.13316966593265533
          ]
        ],
        "inference_time": 1.7752764225006104
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 78,
    "sentence": "Fr\u00fch Natur Radler  2.5%; The Real Ale Store, \u00a31.85 for 500ml; Hop Burns & Black, \u00a32.30  If grapefruit is not your bag, seek out this lemony-fresh delight from Fr\u00fch.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4162748157978058
          ]
        ],
        "inference_time": 1.7748260498046875
      },
      {
        "repetition": 1,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.12564100325107574
          ]
        ],
        "inference_time": 1.775238275527954
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4162748157978058
          ]
        ],
        "inference_time": 1.7772340774536133
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4162748157978058
          ]
        ],
        "inference_time": 1.776336431503296
      },
      {
        "repetition": 4,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.07233770936727524
          ]
        ],
        "inference_time": 1.7761156558990479
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4162748157978058
          ]
        ],
        "inference_time": 1.7753424644470215
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4162748157978058
          ]
        ],
        "inference_time": 1.774735927581787
      },
      {
        "repetition": 7,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.12564100325107574
          ]
        ],
        "inference_time": 1.7731919288635254
      },
      {
        "repetition": 8,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.10972890257835388
          ]
        ],
        "inference_time": 1.7757909297943115
      },
      {
        "repetition": 9,
        "generated_text": " 1",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "1",
            0.023484619334340096
          ]
        ],
        "inference_time": 1.7758805751800537
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 79,
    "sentence": "Following on from this, Jim went on to star in the 2012 adaptation of David Mitchell's Cloud Atlas, which also divided audiences.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.21679292619228363
          ]
        ],
        "inference_time": 1.7718610763549805
      },
      {
        "repetition": 1,
        "generated_text": " 23",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "23",
            0.015541697852313519
          ]
        ],
        "inference_time": 1.770113468170166
      },
      {
        "repetition": 2,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.08401763439178467
          ]
        ],
        "inference_time": 1.7704393863677979
      },
      {
        "repetition": 3,
        "generated_text": " 22",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "22",
            0.012884519062936306
          ]
        ],
        "inference_time": 1.770171880722046
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.21679292619228363
          ]
        ],
        "inference_time": 1.770768642425537
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.21679292619228363
          ]
        ],
        "inference_time": 1.774174451828003
      },
      {
        "repetition": 6,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.02873481996357441
          ]
        ],
        "inference_time": 1.7704975605010986
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.21679292619228363
          ]
        ],
        "inference_time": 1.7719383239746094
      },
      {
        "repetition": 8,
        "generated_text": " 15",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "15",
            0.033946193754673004
          ]
        ],
        "inference_time": 1.7715404033660889
      },
      {
        "repetition": 9,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.13425979018211365
          ]
        ],
        "inference_time": 1.7709150314331055
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 80,
    "sentence": "Limit your spending and you have limited your income too.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.07369787991046906
          ]
        ],
        "inference_time": 1.7358307838439941
      },
      {
        "repetition": 1,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.1083526462316513
          ]
        ],
        "inference_time": 1.7388627529144287
      },
      {
        "repetition": 2,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.052806854248046875
          ]
        ],
        "inference_time": 1.7380993366241455
      },
      {
        "repetition": 3,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.04199179261922836
          ]
        ],
        "inference_time": 1.7408673763275146
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3038824796676636
          ]
        ],
        "inference_time": 1.7403151988983154
      },
      {
        "repetition": 5,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.1083526462316513
          ]
        ],
        "inference_time": 1.7414720058441162
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3038824796676636
          ]
        ],
        "inference_time": 1.740217924118042
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3038824796676636
          ]
        ],
        "inference_time": 1.740354061126709
      },
      {
        "repetition": 8,
        "generated_text": " 26",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "26",
            0.007146631367504597
          ]
        ],
        "inference_time": 1.7398180961608887
      },
      {
        "repetition": 9,
        "generated_text": " 13",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "13",
            0.007297078613191843
          ]
        ],
        "inference_time": 1.7393207550048828
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 81,
    "sentence": "Unlike some of the other lemon offerings out there, this isn\u2019t soapy at all and has a very natural lemon flavouring.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.1461573839187622
          ]
        ],
        "inference_time": 1.7722387313842773
      },
      {
        "repetition": 1,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.11032537370920181
          ]
        ],
        "inference_time": 1.7728807926177979
      },
      {
        "repetition": 2,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "70",
            0.06761636584997177
          ]
        ],
        "inference_time": 1.7724206447601318
      },
      {
        "repetition": 3,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "60",
            0.07582544535398483
          ]
        ],
        "inference_time": 1.773580551147461
      },
      {
        "repetition": 4,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.14314384758472443
          ]
        ],
        "inference_time": 1.7746946811676025
      },
      {
        "repetition": 5,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.14314384758472443
          ]
        ],
        "inference_time": 1.7751126289367676
      },
      {
        "repetition": 6,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.11032537370920181
          ]
        ],
        "inference_time": 1.775306224822998
      },
      {
        "repetition": 7,
        "generated_text": " 82",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "82",
            0.012771088629961014
          ]
        ],
        "inference_time": 1.7729284763336182
      },
      {
        "repetition": 8,
        "generated_text": " 73",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "73",
            0.01053259801119566
          ]
        ],
        "inference_time": 1.7740330696105957
      },
      {
        "repetition": 9,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.030318772420287132
          ]
        ],
        "inference_time": 1.7736070156097412
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 82,
    "sentence": "Blanco was past rumored to be in a romance with Elsie Hewitt, a 27-year-old model-actress from London (who has since been linked with Jason Sudeikis, 48).",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.35747137665748596
          ]
        ],
        "inference_time": 1.7747414112091064
      },
      {
        "repetition": 1,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.07493007183074951
          ]
        ],
        "inference_time": 1.7746105194091797
      },
      {
        "repetition": 2,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.07493007183074951
          ]
        ],
        "inference_time": 1.7752737998962402
      },
      {
        "repetition": 3,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.11849719285964966
          ]
        ],
        "inference_time": 1.7743370532989502
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.35747137665748596
          ]
        ],
        "inference_time": 1.774322748184204
      },
      {
        "repetition": 5,
        "generated_text": " 15",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "15",
            0.02458096295595169
          ]
        ],
        "inference_time": 1.7754178047180176
      },
      {
        "repetition": 6,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.05656019225716591
          ]
        ],
        "inference_time": 1.7757320404052734
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.35747137665748596
          ]
        ],
        "inference_time": 1.7746191024780273
      },
      {
        "repetition": 8,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.07493007183074951
          ]
        ],
        "inference_time": 1.7739825248718262
      },
      {
        "repetition": 9,
        "generated_text": " 6",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "6",
            0.013434222899377346
          ]
        ],
        "inference_time": 1.775062084197998
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 83,
    "sentence": "The Schedule of Contributions agreed with the Scheme Trustee as part of the 2022 actuarial valuation states that the employer contribution rate for the defined benefit pension scheme is currently set to 30% of members\u2019 pensionable salaries.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.8107445240020752
          ]
        ],
        "inference_time": 1.7759132385253906
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.8107445240020752
          ]
        ],
        "inference_time": 1.7765634059906006
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.8107445240020752
          ]
        ],
        "inference_time": 1.7747037410736084
      },
      {
        "repetition": 3,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.03525248169898987
          ]
        ],
        "inference_time": 1.7732658386230469
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.8107445240020752
          ]
        ],
        "inference_time": 1.776860237121582
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.8107445240020752
          ]
        ],
        "inference_time": 1.7734272480010986
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.8107445240020752
          ]
        ],
        "inference_time": 1.774259090423584
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.8107445240020752
          ]
        ],
        "inference_time": 1.7727527618408203
      },
      {
        "repetition": 8,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.8107445240020752
          ]
        ],
        "inference_time": 1.7735767364501953
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.8107445240020752
          ]
        ],
        "inference_time": 1.7726483345031738
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 84,
    "sentence": "So I wanted more.'",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            0.9044440388679504
          ],
          [
            "5",
            0.014123445376753807
          ]
        ],
        "inference_time": 1.733841896057129
      },
      {
        "repetition": 1,
        "generated_text": " 89",
        "token_probs": [
          [
            " ",
            0.9044440388679504
          ],
          [
            "89",
            0.008792308159172535
          ]
        ],
        "inference_time": 1.733987808227539
      },
      {
        "repetition": 2,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9044440388679504
          ],
          [
            "90",
            0.04753077030181885
          ]
        ],
        "inference_time": 1.7388217449188232
      },
      {
        "repetition": 3,
        "generated_text": " 88",
        "token_probs": [
          [
            " ",
            0.9044440388679504
          ],
          [
            "88",
            0.010172736831009388
          ]
        ],
        "inference_time": 1.7381565570831299
      },
      {
        "repetition": 4,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            0.9044440388679504
          ],
          [
            "40",
            0.011289548128843307
          ]
        ],
        "inference_time": 1.739093542098999
      },
      {
        "repetition": 5,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9044440388679504
          ],
          [
            "100",
            0.19803845882415771
          ]
        ],
        "inference_time": 1.739109754562378
      },
      {
        "repetition": 6,
        "generated_text": " \n\"\n",
        "token_probs": [
          [
            " \n",
            0.010695470497012138
          ],
          [
            "\"\n",
            0.015298986807465553
          ]
        ],
        "inference_time": 1.7388200759887695
      },
      {
        "repetition": 7,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9044440388679504
          ],
          [
            "100",
            0.19803845882415771
          ]
        ],
        "inference_time": 1.7366242408752441
      },
      {
        "repetition": 8,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9044440388679504
          ],
          [
            "80",
            0.05112605541944504
          ]
        ],
        "inference_time": 1.7356147766113281
      },
      {
        "repetition": 9,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9044440388679504
          ],
          [
            "50",
            0.09066861867904663
          ]
        ],
        "inference_time": 1.7353715896606445
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 85,
    "sentence": "Nearly half of Republicans and right-leaning independents said the US was providing too much aid to Ukraine, according to a survey by the Pew Research Center conducted late last year.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3132181763648987
          ]
        ],
        "inference_time": 1.7708678245544434
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3132181763648987
          ]
        ],
        "inference_time": 1.7716388702392578
      },
      {
        "repetition": 2,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3132181763648987
          ]
        ],
        "inference_time": 1.77199125289917
      },
      {
        "repetition": 3,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.030058637261390686
          ]
        ],
        "inference_time": 1.771078109741211
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3132181763648987
          ]
        ],
        "inference_time": 1.772162675857544
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.3132181763648987
          ]
        ],
        "inference_time": 1.7729992866516113
      },
      {
        "repetition": 6,
        "generated_text": " 1",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "1",
            0.020658979192376137
          ]
        ],
        "inference_time": 1.7737705707550049
      },
      {
        "repetition": 7,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.18033497035503387
          ]
        ],
        "inference_time": 1.771878957748413
      },
      {
        "repetition": 8,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.11765222996473312
          ]
        ],
        "inference_time": 1.7731330394744873
      },
      {
        "repetition": 9,
        "generated_text": " 3",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "3",
            0.013619232922792435
          ]
        ],
        "inference_time": 1.7715702056884766
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 86,
    "sentence": "Meanwhile, some arch-conservatives suggested it was time for McConnell to step down.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "60",
            0.060897789895534515
          ]
        ],
        "inference_time": 1.7683384418487549
      },
      {
        "repetition": 1,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.07045892626047134
          ]
        ],
        "inference_time": 1.7710258960723877
      },
      {
        "repetition": 2,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.048425666987895966
          ]
        ],
        "inference_time": 1.7683794498443604
      },
      {
        "repetition": 3,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.07345675677061081
          ]
        ],
        "inference_time": 1.771052360534668
      },
      {
        "repetition": 4,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "85",
            0.02082761935889721
          ]
        ],
        "inference_time": 1.7709746360778809
      },
      {
        "repetition": 5,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.07045892626047134
          ]
        ],
        "inference_time": 1.7693660259246826
      },
      {
        "repetition": 6,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.10251712799072266
          ]
        ],
        "inference_time": 1.7697908878326416
      },
      {
        "repetition": 7,
        "generated_text": " 60",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "60",
            0.060897789895534515
          ]
        ],
        "inference_time": 1.769282341003418
      },
      {
        "repetition": 8,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.07045892626047134
          ]
        ],
        "inference_time": 1.7698323726654053
      },
      {
        "repetition": 9,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "85",
            0.02082761935889721
          ]
        ],
        "inference_time": 1.7701823711395264
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 87,
    "sentence": "\u201cI maintain a healthy weight that preserves my facial structure and collagen.\u201d",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.964838981628418
          ],
          [
            "100",
            0.057809554040431976
          ]
        ],
        "inference_time": 1.7685739994049072
      },
      {
        "repetition": 1,
        "generated_text": " \"88",
        "token_probs": [
          [
            " \"",
            0.012596501968801022
          ],
          [
            "88",
            0.010601994581520557
          ]
        ],
        "inference_time": 1.7694599628448486
      },
      {
        "repetition": 2,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            0.964838981628418
          ],
          [
            "70",
            0.03617629408836365
          ]
        ],
        "inference_time": 1.7690269947052002
      },
      {
        "repetition": 3,
        "generated_text": " 91",
        "token_probs": [
          [
            " ",
            0.964838981628418
          ],
          [
            "91",
            0.009004991501569748
          ]
        ],
        "inference_time": 1.7643330097198486
      },
      {
        "repetition": 4,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.964838981628418
          ],
          [
            "90",
            0.05545029416680336
          ]
        ],
        "inference_time": 1.769906997680664
      },
      {
        "repetition": 5,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.964838981628418
          ],
          [
            "90",
            0.05545029416680336
          ]
        ],
        "inference_time": 1.7691268920898438
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.964838981628418
          ],
          [
            "0",
            0.0726984441280365
          ]
        ],
        "inference_time": 1.7696382999420166
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.964838981628418
          ],
          [
            "0",
            0.0726984441280365
          ]
        ],
        "inference_time": 1.7667453289031982
      },
      {
        "repetition": 8,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.964838981628418
          ],
          [
            "75",
            0.06829386949539185
          ]
        ],
        "inference_time": 1.7674336433410645
      },
      {
        "repetition": 9,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.964838981628418
          ],
          [
            "50",
            0.11259755492210388
          ]
        ],
        "inference_time": 1.7649030685424805
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 88,
    "sentence": "Later in a campaign speech, Trump rattled American allies in Europe when he claimed that he would encourage Russia to attack Nato allies who did not pay enough to maintain the security alliance.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "40",
            0.03497040271759033
          ]
        ],
        "inference_time": 1.770416021347046
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.25572049617767334
          ]
        ],
        "inference_time": 1.7689623832702637
      },
      {
        "repetition": 2,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.18904821574687958
          ]
        ],
        "inference_time": 1.7715110778808594
      },
      {
        "repetition": 3,
        "generated_text": " 4",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "4",
            0.009812608361244202
          ]
        ],
        "inference_time": 1.7714579105377197
      },
      {
        "repetition": 4,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.05948666110634804
          ]
        ],
        "inference_time": 1.771059274673462
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.25572049617767334
          ]
        ],
        "inference_time": 1.7712843418121338
      },
      {
        "repetition": 6,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.18904821574687958
          ]
        ],
        "inference_time": 1.767338514328003
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.25572049617767334
          ]
        ],
        "inference_time": 1.7701411247253418
      },
      {
        "repetition": 8,
        "generated_text": " 12",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "12",
            0.008481057360768318
          ]
        ],
        "inference_time": 1.7678070068359375
      },
      {
        "repetition": 9,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.11113571375608444
          ]
        ],
        "inference_time": 1.770115852355957
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 89,
    "sentence": "Mark made the cheeky confession on-air while hosting his Heart FM radio programme on Monday, admitting he got 'clocked' by Michelle when she found the restaurant takeaway bag in the bin.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.08885306864976883
          ]
        ],
        "inference_time": 1.769111156463623
      },
      {
        "repetition": 1,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.17670542001724243
          ]
        ],
        "inference_time": 1.7680726051330566
      },
      {
        "repetition": 2,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.17670542001724243
          ]
        ],
        "inference_time": 1.769223690032959
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.14347361028194427
          ]
        ],
        "inference_time": 1.7725555896759033
      },
      {
        "repetition": 4,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.0398411825299263
          ]
        ],
        "inference_time": 1.772078514099121
      },
      {
        "repetition": 5,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.17670542001724243
          ]
        ],
        "inference_time": 1.7713685035705566
      },
      {
        "repetition": 6,
        "generated_text": " 17",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "17",
            0.009562193416059017
          ]
        ],
        "inference_time": 1.7701420783996582
      },
      {
        "repetition": 7,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.04609636589884758
          ]
        ],
        "inference_time": 1.7709944248199463
      },
      {
        "repetition": 8,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.08885306864976883
          ]
        ],
        "inference_time": 1.7705168724060059
      },
      {
        "repetition": 9,
        "generated_text": " 23",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "23",
            0.01678217202425003
          ]
        ],
        "inference_time": 1.7712597846984863
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 90,
    "sentence": "\u201cIt has my facial expressions \u2013 my eyes, lips, hair, arms, legs, chest and butt, all dimples and textures fully integrated.\u201d  Fabulous will pay for your exclusive stories.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "100",
            0.14988043904304504
          ]
        ],
        "inference_time": 1.767655611038208
      },
      {
        "repetition": 1,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "100",
            0.14988043904304504
          ]
        ],
        "inference_time": 1.7722892761230469
      },
      {
        "repetition": 2,
        "generated_text": " 91",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "91",
            0.007270288188010454
          ]
        ],
        "inference_time": 1.7706000804901123
      },
      {
        "repetition": 3,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "70",
            0.029513206332921982
          ]
        ],
        "inference_time": 1.7708113193511963
      },
      {
        "repetition": 4,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.0586940236389637
          ]
        ],
        "inference_time": 1.767819881439209
      },
      {
        "repetition": 5,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.04384544864296913
          ]
        ],
        "inference_time": 1.7692978382110596
      },
      {
        "repetition": 6,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.036729782819747925
          ]
        ],
        "inference_time": 1.7689683437347412
      },
      {
        "repetition": 7,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.020711125805974007
          ]
        ],
        "inference_time": 1.7690203189849854
      },
      {
        "repetition": 8,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "85",
            0.020711125805974007
          ]
        ],
        "inference_time": 1.769310474395752
      },
      {
        "repetition": 9,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "85",
            0.020711125805974007
          ]
        ],
        "inference_time": 1.7694475650787354
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 91,
    "sentence": "Since the 2022 valuation, funding has improved.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.4181390106678009
          ]
        ],
        "inference_time": 1.7331855297088623
      },
      {
        "repetition": 1,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.10907808691263199
          ]
        ],
        "inference_time": 1.7349324226379395
      },
      {
        "repetition": 2,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.06086942180991173
          ]
        ],
        "inference_time": 1.7349274158477783
      },
      {
        "repetition": 3,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.15382476150989532
          ]
        ],
        "inference_time": 1.7347300052642822
      },
      {
        "repetition": 4,
        "generated_text": " 2",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "2",
            0.018758499994874
          ]
        ],
        "inference_time": 1.7341718673706055
      },
      {
        "repetition": 5,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.15382476150989532
          ]
        ],
        "inference_time": 1.7365999221801758
      },
      {
        "repetition": 6,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.10907808691263199
          ]
        ],
        "inference_time": 1.7356455326080322
      },
      {
        "repetition": 7,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.15382476150989532
          ]
        ],
        "inference_time": 1.7350506782531738
      },
      {
        "repetition": 8,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.15382476150989532
          ]
        ],
        "inference_time": 1.7335081100463867
      },
      {
        "repetition": 9,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.15382476150989532
          ]
        ],
        "inference_time": 1.737030029296875
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 92,
    "sentence": "He said: 'At a very young age, the local theatre in my town went to local schools to cast a load of kids to be in a professional production of Wind In The Willows.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.039385195821523666
          ]
        ],
        "inference_time": 1.7685437202453613
      },
      {
        "repetition": 1,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.20852458477020264
          ]
        ],
        "inference_time": 1.772287130355835
      },
      {
        "repetition": 2,
        "generated_text": " 10",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "10",
            0.08337845653295517
          ]
        ],
        "inference_time": 1.7723114490509033
      },
      {
        "repetition": 3,
        "generated_text": " 5",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "5",
            0.11636408418416977
          ]
        ],
        "inference_time": 1.7722151279449463
      },
      {
        "repetition": 4,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.12258527427911758
          ]
        ],
        "inference_time": 1.7713103294372559
      },
      {
        "repetition": 5,
        "generated_text": " 3",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "3",
            0.022675996646285057
          ]
        ],
        "inference_time": 1.7720680236816406
      },
      {
        "repetition": 6,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.20852458477020264
          ]
        ],
        "inference_time": 1.7731223106384277
      },
      {
        "repetition": 7,
        "generated_text": " 8",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "8",
            0.023888329043984413
          ]
        ],
        "inference_time": 1.7684030532836914
      },
      {
        "repetition": 8,
        "generated_text": " 7",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "7",
            0.012137585319578648
          ]
        ],
        "inference_time": 1.7696342468261719
      },
      {
        "repetition": 9,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.039385195821523666
          ]
        ],
        "inference_time": 1.7711832523345947
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 93,
    "sentence": "RULE 9: LOVE  According to Gina, you should love yourself, love your life, love others.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.12156340479850769
          ]
        ],
        "inference_time": 1.769408941268921
      },
      {
        "repetition": 1,
        "generated_text": " 88",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "88",
            0.00903836265206337
          ]
        ],
        "inference_time": 1.7701101303100586
      },
      {
        "repetition": 2,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "100",
            0.19224469363689423
          ]
        ],
        "inference_time": 1.768751621246338
      },
      {
        "repetition": 3,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "80",
            0.12156340479850769
          ]
        ],
        "inference_time": 1.7684485912322998
      },
      {
        "repetition": 4,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "90",
            0.09666670113801956
          ]
        ],
        "inference_time": 1.7676990032196045
      },
      {
        "repetition": 5,
        "generated_text": " 97",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "97",
            0.008898235857486725
          ]
        ],
        "inference_time": 1.7679543495178223
      },
      {
        "repetition": 6,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "70",
            0.04379865154623985
          ]
        ],
        "inference_time": 1.7679417133331299
      },
      {
        "repetition": 7,
        "generated_text": " 99",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "99",
            0.016798153519630432
          ]
        ],
        "inference_time": 1.767427682876587
      },
      {
        "repetition": 8,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.016798153519630432
          ]
        ],
        "inference_time": 1.7700045108795166
      },
      {
        "repetition": 9,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "0",
            0.03825162351131439
          ]
        ],
        "inference_time": 1.7684705257415771
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 94,
    "sentence": "Anne Hathaway is not it.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9684506058692932
          ],
          [
            "80",
            0.05314347520470619
          ]
        ],
        "inference_time": 1.734006643295288
      },
      {
        "repetition": 1,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9684506058692932
          ],
          [
            "75",
            0.05657093599438667
          ]
        ],
        "inference_time": 1.735023021697998
      },
      {
        "repetition": 2,
        "generated_text": " 67",
        "token_probs": [
          [
            " ",
            0.9684506058692932
          ],
          [
            "67",
            0.01808115467429161
          ]
        ],
        "inference_time": 1.732875108718872
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9684506058692932
          ],
          [
            "0",
            0.0797777995467186
          ]
        ],
        "inference_time": 1.7346558570861816
      },
      {
        "repetition": 4,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9684506058692932
          ],
          [
            "0",
            0.0797777995467186
          ]
        ],
        "inference_time": 1.7343833446502686
      },
      {
        "repetition": 5,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9684506058692932
          ],
          [
            "100",
            0.1521821767091751
          ]
        ],
        "inference_time": 1.7367489337921143
      },
      {
        "repetition": 6,
        "generated_text": " 92",
        "token_probs": [
          [
            " ",
            0.9684506058692932
          ],
          [
            "92",
            0.017433809116482735
          ]
        ],
        "inference_time": 1.7335388660430908
      },
      {
        "repetition": 7,
        "generated_text": " 97",
        "token_probs": [
          [
            " ",
            0.9684506058692932
          ],
          [
            "97",
            0.013091371394693851
          ]
        ],
        "inference_time": 1.7361626625061035
      },
      {
        "repetition": 8,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9684506058692932
          ],
          [
            "90",
            0.05657093599438667
          ]
        ],
        "inference_time": 1.7355518341064453
      },
      {
        "repetition": 9,
        "generated_text": " 87",
        "token_probs": [
          [
            " ",
            0.9684506058692932
          ],
          [
            "87",
            0.017524858936667442
          ]
        ],
        "inference_time": 1.7352540493011475
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 95,
    "sentence": "As she watches her granddaughters play, Wairimu wonders if things could have played out differently.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 92",
        "token_probs": [
          [
            " ",
            0.9805318713188171
          ],
          [
            "92",
            0.01084135752171278
          ]
        ],
        "inference_time": 1.7666094303131104
      },
      {
        "repetition": 1,
        "generated_text": " 40",
        "token_probs": [
          [
            " ",
            0.9805318713188171
          ],
          [
            "40",
            0.050129931420087814
          ]
        ],
        "inference_time": 1.7684826850891113
      },
      {
        "repetition": 2,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9805318713188171
          ],
          [
            "80",
            0.1165555864572525
          ]
        ],
        "inference_time": 1.7686238288879395
      },
      {
        "repetition": 3,
        "generated_text": " 78",
        "token_probs": [
          [
            " ",
            0.9805318713188171
          ],
          [
            "78",
            0.013704760000109673
          ]
        ],
        "inference_time": 1.7698321342468262
      },
      {
        "repetition": 4,
        "generated_text": " 95",
        "token_probs": [
          [
            " ",
            0.9805318713188171
          ],
          [
            "95",
            0.014741405844688416
          ]
        ],
        "inference_time": 1.7707526683807373
      },
      {
        "repetition": 5,
        "generated_text": " 67",
        "token_probs": [
          [
            " ",
            0.9805318713188171
          ],
          [
            "67",
            0.01844177208840847
          ]
        ],
        "inference_time": 1.7704048156738281
      },
      {
        "repetition": 6,
        "generated_text": " 76",
        "token_probs": [
          [
            " ",
            0.9805318713188171
          ],
          [
            "76",
            0.01084135752171278
          ]
        ],
        "inference_time": 1.7729003429412842
      },
      {
        "repetition": 7,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9805318713188171
          ],
          [
            "20",
            0.07683822512626648
          ]
        ],
        "inference_time": 1.7697558403015137
      },
      {
        "repetition": 8,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            0.9805318713188171
          ],
          [
            "30",
            0.0592215359210968
          ]
        ],
        "inference_time": 1.7701747417449951
      },
      {
        "repetition": 9,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            0.9805318713188171
          ],
          [
            "30",
            0.0592215359210968
          ]
        ],
        "inference_time": 1.7702691555023193
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 96,
    "sentence": "RULE 5: ATTITUDE IS EVERYTHING  Gina stressed the importance of \"thinking yourself young\" as she suggested: \"You are what you think.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9384856224060059
          ],
          [
            "0",
            0.20287318527698517
          ]
        ],
        "inference_time": 1.771376609802246
      },
      {
        "repetition": 1,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9384856224060059
          ],
          [
            "90",
            0.027743402868509293
          ]
        ],
        "inference_time": 1.7740566730499268
      },
      {
        "repetition": 2,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9384856224060059
          ],
          [
            "20",
            0.09990783035755157
          ]
        ],
        "inference_time": 1.7712841033935547
      },
      {
        "repetition": 3,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9384856224060059
          ],
          [
            "0",
            0.20287318527698517
          ]
        ],
        "inference_time": 1.7740797996520996
      },
      {
        "repetition": 4,
        "generated_text": " 100",
        "token_probs": [
          [
            " ",
            0.9384856224060059
          ],
          [
            "100",
            0.03675403445959091
          ]
        ],
        "inference_time": 1.7761821746826172
      },
      {
        "repetition": 5,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9384856224060059
          ],
          [
            "0",
            0.20287318527698517
          ]
        ],
        "inference_time": 1.7700614929199219
      },
      {
        "repetition": 6,
        "generated_text": "  ",
        "token_probs": [
          [
            " ",
            0.9384856224060059
          ],
          [
            " ",
            0.02552514523267746
          ]
        ],
        "inference_time": 1.7732667922973633
      },
      {
        "repetition": 7,
        "generated_text": " 0",
        "token_probs": [
          [
            " ",
            0.9384856224060059
          ],
          [
            "0",
            0.20287318527698517
          ]
        ],
        "inference_time": 1.7689073085784912
      },
      {
        "repetition": 8,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9384856224060059
          ],
          [
            "90",
            0.027743402868509293
          ]
        ],
        "inference_time": 1.7685692310333252
      },
      {
        "repetition": 9,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9384856224060059
          ],
          [
            "20",
            0.09990783035755157
          ]
        ],
        "inference_time": 1.76863431930542
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 97,
    "sentence": "However, Variety wasn't so gushing - and said the drama 'should have stayed in quarantine'.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9696318507194519
          ],
          [
            "50",
            0.22817794978618622
          ]
        ],
        "inference_time": 1.7715835571289062
      },
      {
        "repetition": 1,
        "generated_text": " (put",
        "token_probs": [
          [
            " (",
            0.00991038791835308
          ],
          [
            "put",
            0.030581315979361534
          ]
        ],
        "inference_time": 1.7717258930206299
      },
      {
        "repetition": 2,
        "generated_text": " 86",
        "token_probs": [
          [
            " ",
            0.9696318507194519
          ],
          [
            "86",
            0.011068284511566162
          ]
        ],
        "inference_time": 1.7680788040161133
      },
      {
        "repetition": 3,
        "generated_text": " 76",
        "token_probs": [
          [
            " ",
            0.9696318507194519
          ],
          [
            "76",
            0.012412049807608128
          ]
        ],
        "inference_time": 1.767033576965332
      },
      {
        "repetition": 4,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9696318507194519
          ],
          [
            "50",
            0.22817794978618622
          ]
        ],
        "inference_time": 1.771285057067871
      },
      {
        "repetition": 5,
        "generated_text": " 70",
        "token_probs": [
          [
            " ",
            0.9696318507194519
          ],
          [
            "70",
            0.040066588670015335
          ]
        ],
        "inference_time": 1.7676122188568115
      },
      {
        "repetition": 6,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9696318507194519
          ],
          [
            "90",
            0.062056347727775574
          ]
        ],
        "inference_time": 1.7673285007476807
      },
      {
        "repetition": 7,
        "generated_text": " 78",
        "token_probs": [
          [
            " ",
            0.9696318507194519
          ],
          [
            "78",
            0.010672025382518768
          ]
        ],
        "inference_time": 1.764824390411377
      },
      {
        "repetition": 8,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9696318507194519
          ],
          [
            "50",
            0.22817794978618622
          ]
        ],
        "inference_time": 1.7676832675933838
      },
      {
        "repetition": 9,
        "generated_text": " 90",
        "token_probs": [
          [
            " ",
            0.9696318507194519
          ],
          [
            "90",
            0.062056347727775574
          ]
        ],
        "inference_time": 1.7668814659118652
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 98,
    "sentence": "The Ohio senator JD Vance, another Trump loyalist, claimed the effort to replenish Ukraine\u2019s war chest was a \u201cplot\u201d by the Republican establishment to \u201cstop the election of Donald Trump\u201d.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9319154620170593
          ],
          [
            "80",
            0.11918050050735474
          ]
        ],
        "inference_time": 1.7704243659973145
      },
      {
        "repetition": 1,
        "generated_text": " 67",
        "token_probs": [
          [
            " ",
            0.9319154620170593
          ],
          [
            "67",
            0.012825971469283104
          ]
        ],
        "inference_time": 1.7720508575439453
      },
      {
        "repetition": 2,
        "generated_text": " 85",
        "token_probs": [
          [
            " ",
            0.9319154620170593
          ],
          [
            "85",
            0.03711317852139473
          ]
        ],
        "inference_time": 1.772773265838623
      },
      {
        "repetition": 3,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9319154620170593
          ],
          [
            "20",
            0.08629072457551956
          ]
        ],
        "inference_time": 1.7704594135284424
      },
      {
        "repetition": 4,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            0.9319154620170593
          ],
          [
            "20",
            0.08629072457551956
          ]
        ],
        "inference_time": 1.7698745727539062
      },
      {
        "repetition": 5,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            0.9319154620170593
          ],
          [
            "25",
            0.035971324890851974
          ]
        ],
        "inference_time": 1.773784875869751
      },
      {
        "repetition": 6,
        "generated_text": "? ",
        "token_probs": [
          [
            "?",
            0.018551969900727272
          ],
          [
            " ",
            0.09718648344278336
          ]
        ],
        "inference_time": 1.7726185321807861
      },
      {
        "repetition": 7,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            0.9319154620170593
          ],
          [
            "50",
            0.11195971816778183
          ]
        ],
        "inference_time": 1.7732563018798828
      },
      {
        "repetition": 8,
        "generated_text": " 80",
        "token_probs": [
          [
            " ",
            0.9319154620170593
          ],
          [
            "80",
            0.11918050050735474
          ]
        ],
        "inference_time": 1.7747573852539062
      },
      {
        "repetition": 9,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            0.9319154620170593
          ],
          [
            "75",
            0.03559855744242668
          ]
        ],
        "inference_time": 1.7728400230407715
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 99,
    "sentence": "It\u2019s made me realise how much we take older people for granted.\u201d  Both Brunero and Hamilton can see how mutually beneficial a multigenerational community such as Ayrton House could be.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": " 75",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "75",
            0.028440862894058228
          ]
        ],
        "inference_time": 1.7715253829956055
      },
      {
        "repetition": 1,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.1067771390080452
          ]
        ],
        "inference_time": 1.7732863426208496
      },
      {
        "repetition": 2,
        "generated_text": " 25",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "25",
            0.07976436614990234
          ]
        ],
        "inference_time": 1.773686170578003
      },
      {
        "repetition": 3,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.1067771390080452
          ]
        ],
        "inference_time": 1.7738029956817627
      },
      {
        "repetition": 4,
        "generated_text": " 67",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "67",
            0.014300962910056114
          ]
        ],
        "inference_time": 1.7732007503509521
      },
      {
        "repetition": 5,
        "generated_text": " 50",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "50",
            0.11974049359560013
          ]
        ],
        "inference_time": 1.7722766399383545
      },
      {
        "repetition": 6,
        "generated_text": " 30",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "30",
            0.1067771390080452
          ]
        ],
        "inference_time": 1.7719380855560303
      },
      {
        "repetition": 7,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.2058183252811432
          ]
        ],
        "inference_time": 1.771742820739746
      },
      {
        "repetition": 8,
        "generated_text": " 20",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "20",
            0.2058183252811432
          ]
        ],
        "inference_time": 1.7706811428070068
      },
      {
        "repetition": 9,
        "generated_text": " 26",
        "token_probs": [
          [
            " ",
            1.0
          ],
          [
            "26",
            0.04181452840566635
          ]
        ],
        "inference_time": 1.7751381397247314
      }
    ],
    "predicted_label": 0
  }
]