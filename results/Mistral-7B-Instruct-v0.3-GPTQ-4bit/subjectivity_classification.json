[
  {
    "sample_idx": 0,
    "sentence": "Blanco established himself earlier in his career working for Dr. Luke's Kasz Money Productions.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.5514435768127441
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3047547340393066
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3092353343963623
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3030364513397217
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3059628009796143
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.311838150024414
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3056552410125732
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.30464768409729
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.309021234512329
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3056988716125488
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 1,
    "sentence": "RULE 13: ARTIFICIAL INTELLIGENCE  Not only this, but Gina also created an AI model of herself to achieve immortality.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9499176740646362
          ],
          [
            "1",
            0.23612146079540253
          ]
        ],
        "inference_time": 1.30755615234375
      },
      {
        "repetition": 1,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9499176740646362
          ],
          [
            "3",
            0.1763869673013687
          ]
        ],
        "inference_time": 1.3101475238800049
      },
      {
        "repetition": 2,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9499176740646362
          ],
          [
            "3",
            0.1763869673013687
          ]
        ],
        "inference_time": 1.3089509010314941
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9499176740646362
          ],
          [
            "0",
            0.0742989107966423
          ]
        ],
        "inference_time": 1.310239315032959
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9499176740646362
          ],
          [
            "0",
            0.0742989107966423
          ]
        ],
        "inference_time": 1.31022310256958
      },
      {
        "repetition": 5,
        "generated_text": "\n7",
        "token_probs": [
          [
            "\n",
            0.05008228123188019
          ],
          [
            "7",
            0.0460406094789505
          ]
        ],
        "inference_time": 1.3109705448150635
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9499176740646362
          ],
          [
            "0",
            0.0742989107966423
          ]
        ],
        "inference_time": 1.3097655773162842
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9499176740646362
          ],
          [
            "0",
            0.0742989107966423
          ]
        ],
        "inference_time": 1.3114047050476074
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9499176740646362
          ],
          [
            "2",
            0.24109241366386414
          ]
        ],
        "inference_time": 1.3115618228912354
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9499176740646362
          ],
          [
            "2",
            0.24109241366386414
          ]
        ],
        "inference_time": 1.3101308345794678
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 2,
    "sentence": "The valuation is required by law and the figure is assessed independently by a pension specialist and has been reviewed by the National Audit Office.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.309842824935913
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3101046085357666
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.309157133102417
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3091216087341309
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3109104633331299
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3081822395324707
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3103854656219482
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3102092742919922
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3114192485809326
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.311042070388794
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 3,
    "sentence": "A sip can really hit the spot after a long bike ride or a walk.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.6888833045959473
          ],
          [
            "2",
            0.23764066398143768
          ]
        ],
        "inference_time": 1.3087098598480225
      },
      {
        "repetition": 1,
        "generated_text": "\n---",
        "token_probs": [
          [
            "\n",
            0.18253591656684875
          ],
          [
            "---",
            0.1680206060409546
          ]
        ],
        "inference_time": 1.308457851409912
      },
      {
        "repetition": 2,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.6888833045959473
          ],
          [
            "3",
            0.2503456771373749
          ]
        ],
        "inference_time": 1.3081231117248535
      },
      {
        "repetition": 3,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.6888833045959473
          ],
          [
            "4",
            0.1685124635696411
          ]
        ],
        "inference_time": 1.3100194931030273
      },
      {
        "repetition": 4,
        "generated_text": "\n________",
        "token_probs": [
          [
            "\n",
            0.18253591656684875
          ],
          [
            "________",
            0.02333906479179859
          ]
        ],
        "inference_time": 1.3088428974151611
      },
      {
        "repetition": 5,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.6888833045959473
          ],
          [
            "2",
            0.23764066398143768
          ]
        ],
        "inference_time": 1.3090806007385254
      },
      {
        "repetition": 6,
        "generated_text": "_________",
        "token_probs": [
          [
            "_",
            0.05202570557594299
          ],
          [
            "________",
            0.17569293081760406
          ]
        ],
        "inference_time": 1.3090648651123047
      },
      {
        "repetition": 7,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.6888833045959473
          ],
          [
            "3",
            0.2503456771373749
          ]
        ],
        "inference_time": 1.3096957206726074
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.6888833045959473
          ],
          [
            "5",
            0.17205990850925446
          ]
        ],
        "inference_time": 1.3097901344299316
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.6888833045959473
          ],
          [
            "5",
            0.17205990850925446
          ]
        ],
        "inference_time": 1.3075439929962158
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 4,
    "sentence": "Lobster!\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "(Based",
        "token_probs": [
          [
            "(",
            0.01647106744349003
          ],
          [
            "Based",
            0.05017293989658356
          ]
        ],
        "inference_time": 1.3075897693634033
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7772576212882996
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.307969093322754
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7772576212882996
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3067781925201416
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7772576212882996
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.307649850845337
      },
      {
        "repetition": 4,
        "generated_text": "\n3",
        "token_probs": [
          [
            "\n",
            0.14303134381771088
          ],
          [
            "3",
            0.011216544546186924
          ]
        ],
        "inference_time": 1.3070554733276367
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7772576212882996
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3061602115631104
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7772576212882996
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.307293176651001
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7772576212882996
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3074464797973633
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7772576212882996
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3088023662567139
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7772576212882996
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3074369430541992
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 5,
    "sentence": "But this is precisely the reason why Labour must reject the austerian urges that, inevitably, spring from the credit card analogy.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.9219217896461487
          ],
          [
            "6",
            0.1763380914926529
          ]
        ],
        "inference_time": 1.3107707500457764
      },
      {
        "repetition": 1,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.9219217896461487
          ],
          [
            "7",
            0.2968527376651764
          ]
        ],
        "inference_time": 1.311610460281372
      },
      {
        "repetition": 2,
        "generated_text": "\n7",
        "token_probs": [
          [
            "\n",
            0.07807815819978714
          ],
          [
            "7",
            0.2673088312149048
          ]
        ],
        "inference_time": 1.3086216449737549
      },
      {
        "repetition": 3,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            0.9219217896461487
          ],
          [
            "9",
            0.1359090805053711
          ]
        ],
        "inference_time": 1.3105432987213135
      },
      {
        "repetition": 4,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.9219217896461487
          ],
          [
            "6",
            0.1763380914926529
          ]
        ],
        "inference_time": 1.3111107349395752
      },
      {
        "repetition": 5,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.9219217896461487
          ],
          [
            "8",
            0.3260289430618286
          ]
        ],
        "inference_time": 1.3098700046539307
      },
      {
        "repetition": 6,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.9219217896461487
          ],
          [
            "8",
            0.3260289430618286
          ]
        ],
        "inference_time": 1.3090920448303223
      },
      {
        "repetition": 7,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            0.9219217896461487
          ],
          [
            "9",
            0.1359090805053711
          ]
        ],
        "inference_time": 1.3101887702941895
      },
      {
        "repetition": 8,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.9219217896461487
          ],
          [
            "7",
            0.2968527376651764
          ]
        ],
        "inference_time": 1.310877799987793
      },
      {
        "repetition": 9,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.9219217896461487
          ],
          [
            "8",
            0.3260289430618286
          ]
        ],
        "inference_time": 1.3120086193084717
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 6,
    "sentence": "Googled how to cook a good lobster and I read how hard it is to get it good because it can turn very tough, rubbery.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8469627499580383
          ],
          [
            "1",
            0.23839572072029114
          ]
        ],
        "inference_time": 1.3103163242340088
      },
      {
        "repetition": 1,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8469627499580383
          ],
          [
            "3",
            0.19155633449554443
          ]
        ],
        "inference_time": 1.3106369972229004
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8469627499580383
          ],
          [
            "5",
            0.18566277623176575
          ]
        ],
        "inference_time": 1.3100101947784424
      },
      {
        "repetition": 3,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8469627499580383
          ],
          [
            "3",
            0.19155633449554443
          ]
        ],
        "inference_time": 1.3101997375488281
      },
      {
        "repetition": 4,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8469627499580383
          ],
          [
            "1",
            0.23839572072029114
          ]
        ],
        "inference_time": 1.3109683990478516
      },
      {
        "repetition": 5,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8469627499580383
          ],
          [
            "1",
            0.23839572072029114
          ]
        ],
        "inference_time": 1.3119432926177979
      },
      {
        "repetition": 6,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8469627499580383
          ],
          [
            "2",
            0.2485385686159134
          ]
        ],
        "inference_time": 1.3108832836151123
      },
      {
        "repetition": 7,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8469627499580383
          ],
          [
            "3",
            0.19155633449554443
          ]
        ],
        "inference_time": 1.3116564750671387
      },
      {
        "repetition": 8,
        "generated_text": "\n...",
        "token_probs": [
          [
            "\n",
            0.11582422256469727
          ],
          [
            "...",
            0.02563437819480896
          ]
        ],
        "inference_time": 1.3116319179534912
      },
      {
        "repetition": 9,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.8469627499580383
          ],
          [
            "4",
            0.08153357356786728
          ]
        ],
        "inference_time": 1.3122684955596924
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 7,
    "sentence": "Apartments cost from \u00a3392 per week to rent, which makes it more expensive than an average room in first-year halls (a single room without bathroom typically costs \u00a3250 per week) but more affordable than a lot of the postgraduate accommodation on offer.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.27508726716041565
          ]
        ],
        "inference_time": 1.3393347263336182
      },
      {
        "repetition": 1,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.11348507553339005
          ]
        ],
        "inference_time": 1.3419506549835205
      },
      {
        "repetition": 2,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.27508726716041565
          ]
        ],
        "inference_time": 1.3408236503601074
      },
      {
        "repetition": 3,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.41727912425994873
          ]
        ],
        "inference_time": 1.3399951457977295
      },
      {
        "repetition": 4,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.27508726716041565
          ]
        ],
        "inference_time": 1.3381774425506592
      },
      {
        "repetition": 5,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.41727912425994873
          ]
        ],
        "inference_time": 1.336272954940796
      },
      {
        "repetition": 6,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.41727912425994873
          ]
        ],
        "inference_time": 1.3402788639068604
      },
      {
        "repetition": 7,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.41727912425994873
          ]
        ],
        "inference_time": 1.3355424404144287
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.11348507553339005
          ]
        ],
        "inference_time": 1.3379416465759277
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.27508726716041565
          ]
        ],
        "inference_time": 1.3385488986968994
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 8,
    "sentence": "We apologise to TikTok for not approaching it for comment prior to publication.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8057808876037598
          ],
          [
            "0",
            0.5469655990600586
          ]
        ],
        "inference_time": 1.3076562881469727
      },
      {
        "repetition": 1,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8057808876037598
          ],
          [
            "2",
            0.06532572954893112
          ]
        ],
        "inference_time": 1.3096652030944824
      },
      {
        "repetition": 2,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8057808876037598
          ],
          [
            "1",
            0.2119751274585724
          ]
        ],
        "inference_time": 1.309736728668213
      },
      {
        "repetition": 3,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8057808876037598
          ],
          [
            "5",
            0.1757335662841797
          ]
        ],
        "inference_time": 1.3091440200805664
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8057808876037598
          ],
          [
            "0",
            0.5469655990600586
          ]
        ],
        "inference_time": 1.309983491897583
      },
      {
        "repetition": 5,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8057808876037598
          ],
          [
            "1",
            0.2119751274585724
          ]
        ],
        "inference_time": 1.309915542602539
      },
      {
        "repetition": 6,
        "generated_text": "\n1",
        "token_probs": [
          [
            "\n",
            0.15061528980731964
          ],
          [
            "1",
            0.07010510563850403
          ]
        ],
        "inference_time": 1.3085331916809082
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8057808876037598
          ],
          [
            "0",
            0.5469655990600586
          ]
        ],
        "inference_time": 1.310755729675293
      },
      {
        "repetition": 8,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8057808876037598
          ],
          [
            "1",
            0.2119751274585724
          ]
        ],
        "inference_time": 1.3092319965362549
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8057808876037598
          ],
          [
            "5",
            0.1757335662841797
          ]
        ],
        "inference_time": 1.3082897663116455
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 9,
    "sentence": "Crumbling parliament patched up with a few fig leaves  Parliament gained some new residents yesterday, and there are already questions as to their expenses.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8229336738586426
          ],
          [
            "5",
            0.14955173432826996
          ]
        ],
        "inference_time": 1.3117084503173828
      },
      {
        "repetition": 1,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8229336738586426
          ],
          [
            "3",
            0.19003845751285553
          ]
        ],
        "inference_time": 1.3097188472747803
      },
      {
        "repetition": 2,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8229336738586426
          ],
          [
            "2",
            0.319916307926178
          ]
        ],
        "inference_time": 1.3109533786773682
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8229336738586426
          ],
          [
            "2",
            0.319916307926178
          ]
        ],
        "inference_time": 1.3116481304168701
      },
      {
        "repetition": 4,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8229336738586426
          ],
          [
            "5",
            0.14955173432826996
          ]
        ],
        "inference_time": 1.3122467994689941
      },
      {
        "repetition": 5,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8229336738586426
          ],
          [
            "5",
            0.14955173432826996
          ]
        ],
        "inference_time": 1.3121123313903809
      },
      {
        "repetition": 6,
        "generated_text": "\n2",
        "token_probs": [
          [
            "\n",
            0.14831428229808807
          ],
          [
            "2",
            0.16274824738502502
          ]
        ],
        "inference_time": 1.3117742538452148
      },
      {
        "repetition": 7,
        "generated_text": "\n-",
        "token_probs": [
          [
            "\n",
            0.14831428229808807
          ],
          [
            "-",
            0.009374920278787613
          ]
        ],
        "inference_time": 1.3111834526062012
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8229336738586426
          ],
          [
            "2",
            0.319916307926178
          ]
        ],
        "inference_time": 1.312044382095337
      },
      {
        "repetition": 9,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8229336738586426
          ],
          [
            "3",
            0.19003845751285553
          ]
        ],
        "inference_time": 1.3103361129760742
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 10,
    "sentence": "In 2019, he bagged a role in the ensemble movie Berlin, I Love You - which was labelled a 'empty, boring flop' by The Observer.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8752193450927734
          ],
          [
            "2",
            0.3032560646533966
          ]
        ],
        "inference_time": 1.311633825302124
      },
      {
        "repetition": 1,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8752193450927734
          ],
          [
            "2",
            0.3032560646533966
          ]
        ],
        "inference_time": 1.3154017925262451
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8752193450927734
          ],
          [
            "5",
            0.1623212844133377
          ]
        ],
        "inference_time": 1.3122313022613525
      },
      {
        "repetition": 3,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8752193450927734
          ],
          [
            "5",
            0.1623212844133377
          ]
        ],
        "inference_time": 1.3108251094818115
      },
      {
        "repetition": 4,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8752193450927734
          ],
          [
            "3",
            0.18014167249202728
          ]
        ],
        "inference_time": 1.3133795261383057
      },
      {
        "repetition": 5,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8752193450927734
          ],
          [
            "1",
            0.2970033884048462
          ]
        ],
        "inference_time": 1.3120553493499756
      },
      {
        "repetition": 6,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8752193450927734
          ],
          [
            "2",
            0.3032560646533966
          ]
        ],
        "inference_time": 1.3123762607574463
      },
      {
        "repetition": 7,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8752193450927734
          ],
          [
            "3",
            0.18014167249202728
          ]
        ],
        "inference_time": 1.3113842010498047
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8752193450927734
          ],
          [
            "2",
            0.3032560646533966
          ]
        ],
        "inference_time": 1.311492919921875
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8752193450927734
          ],
          [
            "5",
            0.1623212844133377
          ]
        ],
        "inference_time": 1.3125638961791992
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 11,
    "sentence": "By the way, she is honestly the best cook.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9161096215248108
          ],
          [
            "5",
            0.20424675941467285
          ]
        ],
        "inference_time": 1.3083696365356445
      },
      {
        "repetition": 1,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9161096215248108
          ],
          [
            "5",
            0.20424675941467285
          ]
        ],
        "inference_time": 1.3098704814910889
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9161096215248108
          ],
          [
            "5",
            0.20424675941467285
          ]
        ],
        "inference_time": 1.3080835342407227
      },
      {
        "repetition": 3,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.9161096215248108
          ],
          [
            "6",
            0.19187207520008087
          ]
        ],
        "inference_time": 1.3085639476776123
      },
      {
        "repetition": 4,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.9161096215248108
          ],
          [
            "6",
            0.19187207520008087
          ]
        ],
        "inference_time": 1.3086662292480469
      },
      {
        "repetition": 5,
        "generated_text": "\n--",
        "token_probs": [
          [
            "\n",
            0.0838903859257698
          ],
          [
            "--",
            0.01093616709113121
          ]
        ],
        "inference_time": 1.3094143867492676
      },
      {
        "repetition": 6,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.9161096215248108
          ],
          [
            "6",
            0.19187207520008087
          ]
        ],
        "inference_time": 1.3082776069641113
      },
      {
        "repetition": 7,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.9161096215248108
          ],
          [
            "4",
            0.11882630735635757
          ]
        ],
        "inference_time": 1.307560682296753
      },
      {
        "repetition": 8,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.9161096215248108
          ],
          [
            "4",
            0.11882630735635757
          ]
        ],
        "inference_time": 1.3098664283752441
      },
      {
        "repetition": 9,
        "generated_text": "\n4",
        "token_probs": [
          [
            "\n",
            0.0838903859257698
          ],
          [
            "4",
            0.05109785124659538
          ]
        ],
        "inference_time": 1.3073968887329102
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 12,
    "sentence": "Families are doubling down on calls for perpetrators to be brought to justice, and say changes on the handling of femicide cases are necessary.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9343951344490051
          ],
          [
            "2",
            0.36125174164772034
          ]
        ],
        "inference_time": 1.3138213157653809
      },
      {
        "repetition": 1,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9343951344490051
          ],
          [
            "3",
            0.23324166238307953
          ]
        ],
        "inference_time": 1.3121871948242188
      },
      {
        "repetition": 2,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9343951344490051
          ],
          [
            "3",
            0.23324166238307953
          ]
        ],
        "inference_time": 1.3119349479675293
      },
      {
        "repetition": 3,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9343951344490051
          ],
          [
            "1",
            0.20799043774604797
          ]
        ],
        "inference_time": 1.3134803771972656
      },
      {
        "repetition": 4,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9343951344490051
          ],
          [
            "1",
            0.20799043774604797
          ]
        ],
        "inference_time": 1.311657190322876
      },
      {
        "repetition": 5,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9343951344490051
          ],
          [
            "1",
            0.20799043774604797
          ]
        ],
        "inference_time": 1.3109028339385986
      },
      {
        "repetition": 6,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9343951344490051
          ],
          [
            "3",
            0.23324166238307953
          ]
        ],
        "inference_time": 1.312941312789917
      },
      {
        "repetition": 7,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9343951344490051
          ],
          [
            "2",
            0.36125174164772034
          ]
        ],
        "inference_time": 1.3132109642028809
      },
      {
        "repetition": 8,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9343951344490051
          ],
          [
            "3",
            0.23324166238307953
          ]
        ],
        "inference_time": 1.3098969459533691
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9343951344490051
          ],
          [
            "2",
            0.36125174164772034
          ]
        ],
        "inference_time": 1.3116450309753418
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 13,
    "sentence": "Anything we can actually do, we can afford.\u201d Britain\u2019s conundrum, today, is that the next government, whose job will be to fix the Tories\u2019 mess, is led by politicians who share neither Keynes\u2019s aims nor his innovative approach to public finance.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.27429506182670593
          ]
        ],
        "inference_time": 1.3389217853546143
      },
      {
        "repetition": 1,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.3140714466571808
          ]
        ],
        "inference_time": 1.3407466411590576
      },
      {
        "repetition": 2,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.21585793793201447
          ]
        ],
        "inference_time": 1.3386452198028564
      },
      {
        "repetition": 3,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.21585793793201447
          ]
        ],
        "inference_time": 1.3384320735931396
      },
      {
        "repetition": 4,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.3140714466571808
          ]
        ],
        "inference_time": 1.339388370513916
      },
      {
        "repetition": 5,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.27429506182670593
          ]
        ],
        "inference_time": 1.338787317276001
      },
      {
        "repetition": 6,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.1019640639424324
          ]
        ],
        "inference_time": 1.337296962738037
      },
      {
        "repetition": 7,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.21585793793201447
          ]
        ],
        "inference_time": 1.3415155410766602
      },
      {
        "repetition": 8,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.27429506182670593
          ]
        ],
        "inference_time": 1.3373191356658936
      },
      {
        "repetition": 9,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.3140714466571808
          ]
        ],
        "inference_time": 1.3386473655700684
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 14,
    "sentence": "\u201cI just believe in being the best version of myself that I can possibly be, it makes me feel good.\u201d  Read more real life stories  Not only does Gina swear by hydration - but she also has 13 other rules she sticks to like glue.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.3503681719303131
          ]
        ],
        "inference_time": 1.339597463607788
      },
      {
        "repetition": 1,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.1554749310016632
          ]
        ],
        "inference_time": 1.3382365703582764
      },
      {
        "repetition": 2,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.3503681719303131
          ]
        ],
        "inference_time": 1.3400969505310059
      },
      {
        "repetition": 3,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.3503681719303131
          ]
        ],
        "inference_time": 1.3382480144500732
      },
      {
        "repetition": 4,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.1554749310016632
          ]
        ],
        "inference_time": 1.3402228355407715
      },
      {
        "repetition": 5,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.1554749310016632
          ]
        ],
        "inference_time": 1.3376262187957764
      },
      {
        "repetition": 6,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.3503681719303131
          ]
        ],
        "inference_time": 1.3383541107177734
      },
      {
        "repetition": 7,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.3503681719303131
          ]
        ],
        "inference_time": 1.3388032913208008
      },
      {
        "repetition": 8,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1554749310016632
          ]
        ],
        "inference_time": 1.3386545181274414
      },
      {
        "repetition": 9,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1554749310016632
          ]
        ],
        "inference_time": 1.3379325866699219
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 15,
    "sentence": "\u201cRussia\u2019s dominance in the Black Sea is now challenged.\u201d  The Boxing Day blast saw Vlad's valuable landing ship - docked in Crimea - turned into a raging fireball.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.896251380443573
          ],
          [
            "4",
            0.13034924864768982
          ]
        ],
        "inference_time": 1.312333345413208
      },
      {
        "repetition": 1,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.896251380443573
          ],
          [
            "1",
            0.19772621989250183
          ]
        ],
        "inference_time": 1.3111929893493652
      },
      {
        "repetition": 2,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.896251380443573
          ],
          [
            "1",
            0.19772621989250183
          ]
        ],
        "inference_time": 1.311985969543457
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.896251380443573
          ],
          [
            "2",
            0.2538854777812958
          ]
        ],
        "inference_time": 1.3144159317016602
      },
      {
        "repetition": 4,
        "generated_text": "\n2",
        "token_probs": [
          [
            "\n",
            0.1037486270070076
          ],
          [
            "2",
            0.14312505722045898
          ]
        ],
        "inference_time": 1.313197135925293
      },
      {
        "repetition": 5,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.896251380443573
          ],
          [
            "2",
            0.2538854777812958
          ]
        ],
        "inference_time": 1.3115301132202148
      },
      {
        "repetition": 6,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.896251380443573
          ],
          [
            "2",
            0.2538854777812958
          ]
        ],
        "inference_time": 1.311476230621338
      },
      {
        "repetition": 7,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.896251380443573
          ],
          [
            "5",
            0.15398932993412018
          ]
        ],
        "inference_time": 1.3116395473480225
      },
      {
        "repetition": 8,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.896251380443573
          ],
          [
            "3",
            0.2217315137386322
          ]
        ],
        "inference_time": 1.312185287475586
      },
      {
        "repetition": 9,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.896251380443573
          ],
          [
            "4",
            0.13034924864768982
          ]
        ],
        "inference_time": 1.3107903003692627
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 16,
    "sentence": "Sea drones & anti-ship missiles  The February 1 attack came after Ukraine unveiled its new underwater robot drone, a stealth Autonomous Underwater Vehicle (AUV).",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.8236469626426697
          ]
        ],
        "inference_time": 1.3114275932312012
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.8236469626426697
          ]
        ],
        "inference_time": 1.312065839767456
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.8236469626426697
          ]
        ],
        "inference_time": 1.3131458759307861
      },
      {
        "repetition": 3,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.10362992435693741
          ]
        ],
        "inference_time": 1.3114962577819824
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.8236469626426697
          ]
        ],
        "inference_time": 1.3118464946746826
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.8236469626426697
          ]
        ],
        "inference_time": 1.3131046295166016
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.8236469626426697
          ]
        ],
        "inference_time": 1.3121683597564697
      },
      {
        "repetition": 7,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.10362992435693741
          ]
        ],
        "inference_time": 1.3124024868011475
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.8236469626426697
          ]
        ],
        "inference_time": 1.3113365173339844
      },
      {
        "repetition": 9,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.10362992435693741
          ]
        ],
        "inference_time": 1.31233549118042
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 17,
    "sentence": "\u201cThey\u2019re people who appreciate the onsite facilities such as the restaurant and gym and see living around older people as a lifestyle benefit rather than a hindrance,\u201d she explains.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9042003154754639
          ],
          [
            "3",
            0.16787351667881012
          ]
        ],
        "inference_time": 1.31070876121521
      },
      {
        "repetition": 1,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9042003154754639
          ],
          [
            "2",
            0.3303966224193573
          ]
        ],
        "inference_time": 1.312269687652588
      },
      {
        "repetition": 2,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9042003154754639
          ],
          [
            "2",
            0.3303966224193573
          ]
        ],
        "inference_time": 1.3130059242248535
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9042003154754639
          ],
          [
            "2",
            0.3303966224193573
          ]
        ],
        "inference_time": 1.3113923072814941
      },
      {
        "repetition": 4,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9042003154754639
          ],
          [
            "1",
            0.33385634422302246
          ]
        ],
        "inference_time": 1.3109126091003418
      },
      {
        "repetition": 5,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9042003154754639
          ],
          [
            "3",
            0.16787351667881012
          ]
        ],
        "inference_time": 1.3119120597839355
      },
      {
        "repetition": 6,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9042003154754639
          ],
          [
            "1",
            0.33385634422302246
          ]
        ],
        "inference_time": 1.3097608089447021
      },
      {
        "repetition": 7,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9042003154754639
          ],
          [
            "2",
            0.3303966224193573
          ]
        ],
        "inference_time": 1.310046911239624
      },
      {
        "repetition": 8,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9042003154754639
          ],
          [
            "3",
            0.16787351667881012
          ]
        ],
        "inference_time": 1.3122258186340332
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9042003154754639
          ],
          [
            "5",
            0.16787351667881012
          ]
        ],
        "inference_time": 1.3116388320922852
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 18,
    "sentence": "But none of this means that the ditched \u00a328bn policy was optimal or, indeed, that an incoming chancellor can safely commit the Treasury to borrow and spend unlimited amounts.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9064324498176575
          ],
          [
            "2",
            0.3039027750492096
          ]
        ],
        "inference_time": 1.3112435340881348
      },
      {
        "repetition": 1,
        "generated_text": "\n3",
        "token_probs": [
          [
            "\n",
            0.09356753528118134
          ],
          [
            "3",
            0.12434335052967072
          ]
        ],
        "inference_time": 1.3126285076141357
      },
      {
        "repetition": 2,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9064324498176575
          ],
          [
            "2",
            0.3039027750492096
          ]
        ],
        "inference_time": 1.3119165897369385
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9064324498176575
          ],
          [
            "2",
            0.3039027750492096
          ]
        ],
        "inference_time": 1.311800479888916
      },
      {
        "repetition": 4,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9064324498176575
          ],
          [
            "3",
            0.2796041667461395
          ]
        ],
        "inference_time": 1.3125760555267334
      },
      {
        "repetition": 5,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9064324498176575
          ],
          [
            "2",
            0.3039027750492096
          ]
        ],
        "inference_time": 1.31300687789917
      },
      {
        "repetition": 6,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.9064324498176575
          ],
          [
            "4",
            0.14966131746768951
          ]
        ],
        "inference_time": 1.3109400272369385
      },
      {
        "repetition": 7,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9064324498176575
          ],
          [
            "1",
            0.14657554030418396
          ]
        ],
        "inference_time": 1.3126816749572754
      },
      {
        "repetition": 8,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.9064324498176575
          ],
          [
            "4",
            0.14966131746768951
          ]
        ],
        "inference_time": 1.3122031688690186
      },
      {
        "repetition": 9,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9064324498176575
          ],
          [
            "1",
            0.14657554030418396
          ]
        ],
        "inference_time": 1.3117163181304932
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 19,
    "sentence": "The record, which topped out at 41 on the Billboard 200, included contributions from Bieber, Halsey, Calvin Harris, Omar Apollo and Gracie Abrams.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.33793306350708
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3372900485992432
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3366620540618896
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3374881744384766
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3365862369537354
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3399114608764648
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3378188610076904
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3352649211883545
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.338317632675171
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3365068435668945
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 20,
    "sentence": "The journalist Mike Smith was struck yesterday when he noticed",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7010223865509033
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.308115005493164
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7010223865509033
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.308703899383545
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7010223865509033
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3079252243041992
      },
      {
        "repetition": 3,
        "generated_text": "\n\n",
        "token_probs": [
          [
            "\n",
            0.2160385400056839
          ],
          [
            "\n",
            0.23445236682891846
          ]
        ],
        "inference_time": 1.3084900379180908
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7010223865509033
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3077495098114014
      },
      {
        "repetition": 5,
        "generated_text": "_____",
        "token_probs": [
          [
            "_",
            0.04389089345932007
          ],
          [
            "____",
            0.4255144000053406
          ]
        ],
        "inference_time": 1.3097472190856934
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7010223865509033
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3086280822753906
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7010223865509033
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.307091474533081
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.7010223865509033
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.307488203048706
      },
      {
        "repetition": 9,
        "generated_text": "_____",
        "token_probs": [
          [
            "_",
            0.04389089345932007
          ],
          [
            "____",
            0.4255144000053406
          ]
        ],
        "inference_time": 1.3076565265655518
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 21,
    "sentence": "Two years later, he stepped into a leading man role once again when he appeared in The Other Me - about a architect who has an eye disease which enables him to see people's real motives.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8452624678611755
          ],
          [
            "0",
            0.8981727361679077
          ]
        ],
        "inference_time": 1.3101439476013184
      },
      {
        "repetition": 1,
        "generated_text": "\n0",
        "token_probs": [
          [
            "\n",
            0.15473750233650208
          ],
          [
            "0",
            0.6106389760971069
          ]
        ],
        "inference_time": 1.3131003379821777
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8452624678611755
          ],
          [
            "0",
            0.8981727361679077
          ]
        ],
        "inference_time": 1.3127362728118896
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8452624678611755
          ],
          [
            "0",
            0.8981727361679077
          ]
        ],
        "inference_time": 1.311103105545044
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8452624678611755
          ],
          [
            "0",
            0.8981727361679077
          ]
        ],
        "inference_time": 1.3113181591033936
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8452624678611755
          ],
          [
            "0",
            0.8981727361679077
          ]
        ],
        "inference_time": 1.3098890781402588
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8452624678611755
          ],
          [
            "0",
            0.8981727361679077
          ]
        ],
        "inference_time": 1.3117780685424805
      },
      {
        "repetition": 7,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8452624678611755
          ],
          [
            "1",
            0.10182731598615646
          ]
        ],
        "inference_time": 1.3106389045715332
      },
      {
        "repetition": 8,
        "generated_text": "\n0",
        "token_probs": [
          [
            "\n",
            0.15473750233650208
          ],
          [
            "0",
            0.6106389760971069
          ]
        ],
        "inference_time": 1.309227705001831
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8452624678611755
          ],
          [
            "0",
            0.8981727361679077
          ]
        ],
        "inference_time": 1.3110363483428955
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 22,
    "sentence": "At the time, Time magazine dubbed the film 'disjoined' - saying that 'characters that Nicholls brought so cunningly to life in the book feel rushed through a timeline, tied to an agenda'.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.1486833542585373
          ]
        ],
        "inference_time": 1.338141679763794
      },
      {
        "repetition": 1,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "3",
            0.242597296833992
          ]
        ],
        "inference_time": 1.3373558521270752
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.19091321527957916
          ]
        ],
        "inference_time": 1.3378186225891113
      },
      {
        "repetition": 3,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.19091321527957916
          ]
        ],
        "inference_time": 1.3378310203552246
      },
      {
        "repetition": 4,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.2375953197479248
          ]
        ],
        "inference_time": 1.3376436233520508
      },
      {
        "repetition": 5,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.2375953197479248
          ]
        ],
        "inference_time": 1.3366343975067139
      },
      {
        "repetition": 6,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.19091321527957916
          ]
        ],
        "inference_time": 1.3363499641418457
      },
      {
        "repetition": 7,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.2375953197479248
          ]
        ],
        "inference_time": 1.3369531631469727
      },
      {
        "repetition": 8,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.2375953197479248
          ]
        ],
        "inference_time": 1.336909294128418
      },
      {
        "repetition": 9,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.2375953197479248
          ]
        ],
        "inference_time": 1.340768575668335
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 23,
    "sentence": "\u201cWe were in shock,\u201d says Wangari\u2019s father.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.6983873248100281
          ],
          [
            "3",
            0.14785659313201904
          ]
        ],
        "inference_time": 1.3111791610717773
      },
      {
        "repetition": 1,
        "generated_text": "\n---",
        "token_probs": [
          [
            "\n",
            0.20430374145507812
          ],
          [
            "---",
            0.1551545411348343
          ]
        ],
        "inference_time": 1.3086788654327393
      },
      {
        "repetition": 2,
        "generated_text": "<Y",
        "token_probs": [
          [
            "<",
            0.00847665499895811
          ],
          [
            "Y",
            0.033898066729307175
          ]
        ],
        "inference_time": 1.3086824417114258
      },
      {
        "repetition": 3,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.6983873248100281
          ],
          [
            "6",
            0.1048460379242897
          ]
        ],
        "inference_time": 1.309788703918457
      },
      {
        "repetition": 4,
        "generated_text": "\n2",
        "token_probs": [
          [
            "\n",
            0.20430374145507812
          ],
          [
            "2",
            0.02626875415444374
          ]
        ],
        "inference_time": 1.3091020584106445
      },
      {
        "repetition": 5,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.6983873248100281
          ],
          [
            "5",
            0.19792909920215607
          ]
        ],
        "inference_time": 1.3104827404022217
      },
      {
        "repetition": 6,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.6983873248100281
          ],
          [
            "8",
            0.09849372506141663
          ]
        ],
        "inference_time": 1.3075478076934814
      },
      {
        "repetition": 7,
        "generated_text": "\n---",
        "token_probs": [
          [
            "\n",
            0.20430374145507812
          ],
          [
            "---",
            0.1551545411348343
          ]
        ],
        "inference_time": 1.3104393482208252
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.6983873248100281
          ],
          [
            "5",
            0.19792909920215607
          ]
        ],
        "inference_time": 1.3071727752685547
      },
      {
        "repetition": 9,
        "generated_text": "\nAn",
        "token_probs": [
          [
            "\n",
            0.20430374145507812
          ],
          [
            "An",
            0.032691989094018936
          ]
        ],
        "inference_time": 1.307492733001709
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 24,
    "sentence": "House Democrats and the remaining pro-Ukraine House Republicans are casting about behind the scenes for a solution.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9301205277442932
          ],
          [
            "0",
            0.6549825668334961
          ]
        ],
        "inference_time": 1.3091087341308594
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9301205277442932
          ],
          [
            "0",
            0.6549825668334961
          ]
        ],
        "inference_time": 1.3099257946014404
      },
      {
        "repetition": 2,
        "generated_text": "\n0",
        "token_probs": [
          [
            "\n",
            0.06987948715686798
          ],
          [
            "0",
            0.2617493271827698
          ]
        ],
        "inference_time": 1.3085436820983887
      },
      {
        "repetition": 3,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9301205277442932
          ],
          [
            "1",
            0.2263559252023697
          ]
        ],
        "inference_time": 1.3111767768859863
      },
      {
        "repetition": 4,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9301205277442932
          ],
          [
            "1",
            0.2263559252023697
          ]
        ],
        "inference_time": 1.3083157539367676
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9301205277442932
          ],
          [
            "0",
            0.6549825668334961
          ]
        ],
        "inference_time": 1.3096680641174316
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9301205277442932
          ],
          [
            "0",
            0.6549825668334961
          ]
        ],
        "inference_time": 1.3095159530639648
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9301205277442932
          ],
          [
            "0",
            0.6549825668334961
          ]
        ],
        "inference_time": 1.3102166652679443
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9301205277442932
          ],
          [
            "0",
            0.6549825668334961
          ]
        ],
        "inference_time": 1.310713529586792
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9301205277442932
          ],
          [
            "0",
            0.6549825668334961
          ]
        ],
        "inference_time": 1.3070666790008545
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 25,
    "sentence": "Austerity, and the credit card analogy that provides its thin veneer of logic, is not just bad for workers and people in desperate need of state support during tough times; it also depresses investment.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.22120901942253113
          ]
        ],
        "inference_time": 1.3110573291778564
      },
      {
        "repetition": 1,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.0830913856625557
          ]
        ],
        "inference_time": 1.312040090560913
      },
      {
        "repetition": 2,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.0830913856625557
          ]
        ],
        "inference_time": 1.312868356704712
      },
      {
        "repetition": 3,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2586195468902588
          ]
        ],
        "inference_time": 1.3124115467071533
      },
      {
        "repetition": 4,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.22120901942253113
          ]
        ],
        "inference_time": 1.3109402656555176
      },
      {
        "repetition": 5,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.22120901942253113
          ]
        ],
        "inference_time": 1.312326192855835
      },
      {
        "repetition": 6,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.22120901942253113
          ]
        ],
        "inference_time": 1.3129000663757324
      },
      {
        "repetition": 7,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.13277965784072876
          ]
        ],
        "inference_time": 1.3108265399932861
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.13277965784072876
          ]
        ],
        "inference_time": 1.3132102489471436
      },
      {
        "repetition": 9,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.22120901942253113
          ]
        ],
        "inference_time": 1.3120381832122803
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 26,
    "sentence": "In a pre-dawn vote on Tuesday, Graham joined the majority of Senate Republicans in opposing a foreign aid package that would rush wartime assistance to Ukraine as it approaches the second anniversary of Russia\u2019s full invasion.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7046776413917542
          ]
        ],
        "inference_time": 1.3090183734893799
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7046776413917542
          ]
        ],
        "inference_time": 1.310307264328003
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7046776413917542
          ]
        ],
        "inference_time": 1.3095471858978271
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7046776413917542
          ]
        ],
        "inference_time": 1.3108513355255127
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7046776413917542
          ]
        ],
        "inference_time": 1.3108441829681396
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7046776413917542
          ]
        ],
        "inference_time": 1.3118517398834229
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7046776413917542
          ]
        ],
        "inference_time": 1.3103828430175781
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7046776413917542
          ]
        ],
        "inference_time": 1.3117241859436035
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7046776413917542
          ]
        ],
        "inference_time": 1.3090429306030273
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7046776413917542
          ]
        ],
        "inference_time": 1.3118953704833984
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 27,
    "sentence": "The Observer's Philip French dubbed it 'thin, superficial and sentimental' and said the casting of Anne Hathway was 'disastrous'.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.3182401955127716
          ]
        ],
        "inference_time": 1.313244104385376
      },
      {
        "repetition": 1,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.46303674578666687
          ]
        ],
        "inference_time": 1.3127508163452148
      },
      {
        "repetition": 2,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.3182401955127716
          ]
        ],
        "inference_time": 1.3129513263702393
      },
      {
        "repetition": 3,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.3182401955127716
          ]
        ],
        "inference_time": 1.312577486038208
      },
      {
        "repetition": 4,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.21872307360172272
          ]
        ],
        "inference_time": 1.311570405960083
      },
      {
        "repetition": 5,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.46303674578666687
          ]
        ],
        "inference_time": 1.3127422332763672
      },
      {
        "repetition": 6,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.46303674578666687
          ]
        ],
        "inference_time": 1.3144731521606445
      },
      {
        "repetition": 7,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.46303674578666687
          ]
        ],
        "inference_time": 1.3113288879394531
      },
      {
        "repetition": 8,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.3182401955127716
          ]
        ],
        "inference_time": 1.3112142086029053
      },
      {
        "repetition": 9,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.21872307360172272
          ]
        ],
        "inference_time": 1.3132531642913818
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 28,
    "sentence": "A third commented: \"$20 for $6k - not bad!\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8731857538223267
          ],
          [
            "2",
            0.23872914910316467
          ]
        ],
        "inference_time": 1.3079173564910889
      },
      {
        "repetition": 1,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8731857538223267
          ],
          [
            "5",
            0.19586263597011566
          ]
        ],
        "inference_time": 1.3088264465332031
      },
      {
        "repetition": 2,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8731857538223267
          ],
          [
            "1",
            0.15095724165439606
          ]
        ],
        "inference_time": 1.3121397495269775
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8731857538223267
          ],
          [
            "2",
            0.23872914910316467
          ]
        ],
        "inference_time": 1.3088088035583496
      },
      {
        "repetition": 4,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8731857538223267
          ],
          [
            "3",
            0.20633408427238464
          ]
        ],
        "inference_time": 1.311805248260498
      },
      {
        "repetition": 5,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8731857538223267
          ],
          [
            "2",
            0.23872914910316467
          ]
        ],
        "inference_time": 1.310034990310669
      },
      {
        "repetition": 6,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.8731857538223267
          ],
          [
            "4",
            0.11159917712211609
          ]
        ],
        "inference_time": 1.309631586074829
      },
      {
        "repetition": 7,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8731857538223267
          ],
          [
            "5",
            0.19586263597011566
          ]
        ],
        "inference_time": 1.3125576972961426
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8731857538223267
          ],
          [
            "2",
            0.23872914910316467
          ]
        ],
        "inference_time": 1.3108882904052734
      },
      {
        "repetition": 9,
        "generated_text": "\n7",
        "token_probs": [
          [
            "\n",
            0.10003111511468887
          ],
          [
            "7",
            0.05158572271466255
          ]
        ],
        "inference_time": 1.310239553451538
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 29,
    "sentence": "The plan incorporates cash payments supplemented by contingent contributions.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8991213440895081
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3105411529541016
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8991213440895081
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3098993301391602
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8991213440895081
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3106262683868408
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8991213440895081
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3105831146240234
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8991213440895081
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3115043640136719
      },
      {
        "repetition": 5,
        "generated_text": "\n5",
        "token_probs": [
          [
            "\n",
            0.10087861120700836
          ],
          [
            "5",
            0.08832340687513351
          ]
        ],
        "inference_time": 1.3119170665740967
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8991213440895081
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3103675842285156
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8991213440895081
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.312323808670044
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8991213440895081
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3122584819793701
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8991213440895081
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3113811016082764
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 30,
    "sentence": "It is true that the Tories will leave scorched earth behind for the next government, with a budget dripping in red ink and a pitiful level of investment in the technologies and services the UK needs to escape a long-term slump.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.18135905265808105
          ]
        ],
        "inference_time": 1.339385747909546
      },
      {
        "repetition": 1,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.18135905265808105
          ]
        ],
        "inference_time": 1.3394253253936768
      },
      {
        "repetition": 2,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.16004881262779236
          ]
        ],
        "inference_time": 1.340904712677002
      },
      {
        "repetition": 3,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.17761987447738647
          ]
        ],
        "inference_time": 1.3376123905181885
      },
      {
        "repetition": 4,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "3",
            0.17395763099193573
          ]
        ],
        "inference_time": 1.3404302597045898
      },
      {
        "repetition": 5,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.11588077247142792
          ]
        ],
        "inference_time": 1.3397667407989502
      },
      {
        "repetition": 6,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.11588077247142792
          ]
        ],
        "inference_time": 1.3398981094360352
      },
      {
        "repetition": 7,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.18135905265808105
          ]
        ],
        "inference_time": 1.3397767543792725
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.17761987447738647
          ]
        ],
        "inference_time": 1.3396186828613281
      },
      {
        "repetition": 9,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "3",
            0.17395763099193573
          ]
        ],
        "inference_time": 1.3382368087768555
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 31,
    "sentence": "A WOMAN who has been dubbed \u2018the world\u2019s hottest gran\u2019 has revealed how she stays looking eternally young at the age of 53.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9334307909011841
          ],
          [
            "0",
            0.12535400688648224
          ]
        ],
        "inference_time": 1.312830924987793
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9334307909011841
          ],
          [
            "0",
            0.12535400688648224
          ]
        ],
        "inference_time": 1.312265157699585
      },
      {
        "repetition": 2,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9334307909011841
          ],
          [
            "2",
            0.20031514763832092
          ]
        ],
        "inference_time": 1.3105688095092773
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9334307909011841
          ],
          [
            "2",
            0.20031514763832092
          ]
        ],
        "inference_time": 1.3116941452026367
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9334307909011841
          ],
          [
            "0",
            0.12535400688648224
          ]
        ],
        "inference_time": 1.3118648529052734
      },
      {
        "repetition": 5,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9334307909011841
          ],
          [
            "3",
            0.07142457365989685
          ]
        ],
        "inference_time": 1.3108186721801758
      },
      {
        "repetition": 6,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9334307909011841
          ],
          [
            "2",
            0.20031514763832092
          ]
        ],
        "inference_time": 1.313319206237793
      },
      {
        "repetition": 7,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9334307909011841
          ],
          [
            "3",
            0.07142457365989685
          ]
        ],
        "inference_time": 1.3118159770965576
      },
      {
        "repetition": 8,
        "generated_text": "\n5",
        "token_probs": [
          [
            "\n",
            0.06656918674707413
          ],
          [
            "5",
            0.11278679966926575
          ]
        ],
        "inference_time": 1.3120250701904297
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9334307909011841
          ],
          [
            "5",
            0.20453208684921265
          ]
        ],
        "inference_time": 1.3129096031188965
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 32,
    "sentence": "Couldn't say everything I wanted to in the video.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.8341978788375854
          ],
          [
            "8",
            0.1924491673707962
          ]
        ],
        "inference_time": 1.310429573059082
      },
      {
        "repetition": 1,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.8341978788375854
          ],
          [
            "7",
            0.19045500457286835
          ]
        ],
        "inference_time": 1.3101518154144287
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8341978788375854
          ],
          [
            "5",
            0.15144900977611542
          ]
        ],
        "inference_time": 1.3111019134521484
      },
      {
        "repetition": 3,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.8341978788375854
          ],
          [
            "4",
            0.10851798951625824
          ]
        ],
        "inference_time": 1.3094561100006104
      },
      {
        "repetition": 4,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.8341978788375854
          ],
          [
            "7",
            0.19045500457286835
          ]
        ],
        "inference_time": 1.3114709854125977
      },
      {
        "repetition": 5,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8341978788375854
          ],
          [
            "3",
            0.08810964971780777
          ]
        ],
        "inference_time": 1.3119385242462158
      },
      {
        "repetition": 6,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.8341978788375854
          ],
          [
            "8",
            0.1924491673707962
          ]
        ],
        "inference_time": 1.3075311183929443
      },
      {
        "repetition": 7,
        "generated_text": "__6",
        "token_probs": [
          [
            "__",
            0.011004949919879436
          ],
          [
            "6",
            0.16301590204238892
          ]
        ],
        "inference_time": 1.3108179569244385
      },
      {
        "repetition": 8,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.8341978788375854
          ],
          [
            "4",
            0.10851798951625824
          ]
        ],
        "inference_time": 1.3091034889221191
      },
      {
        "repetition": 9,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.8341978788375854
          ],
          [
            "7",
            0.19045500457286835
          ]
        ],
        "inference_time": 1.3100171089172363
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 33,
    "sentence": "From the Senate floor, Senator Mitch McConnell, the top Republican, delivered increasingly urgent pleas for his conference to rise to the occasion and support America\u2019s allies, even after his plan to tie border security to foreign aid collapsed, torpedoed by Trump\u2019s opposition.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9393223524093628
          ],
          [
            "3",
            0.2595541477203369
          ]
        ],
        "inference_time": 1.3414840698242188
      },
      {
        "repetition": 1,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.9393223524093628
          ],
          [
            "4",
            0.21970798075199127
          ]
        ],
        "inference_time": 1.3401501178741455
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9393223524093628
          ],
          [
            "5",
            0.16584427654743195
          ]
        ],
        "inference_time": 1.3394412994384766
      },
      {
        "repetition": 3,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.9393223524093628
          ],
          [
            "4",
            0.21970798075199127
          ]
        ],
        "inference_time": 1.341651201248169
      },
      {
        "repetition": 4,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.9393223524093628
          ],
          [
            "4",
            0.21970798075199127
          ]
        ],
        "inference_time": 1.3384637832641602
      },
      {
        "repetition": 5,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9393223524093628
          ],
          [
            "5",
            0.16584427654743195
          ]
        ],
        "inference_time": 1.3416130542755127
      },
      {
        "repetition": 6,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.9393223524093628
          ],
          [
            "4",
            0.21970798075199127
          ]
        ],
        "inference_time": 1.3386976718902588
      },
      {
        "repetition": 7,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.9393223524093628
          ],
          [
            "4",
            0.21970798075199127
          ]
        ],
        "inference_time": 1.3377904891967773
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9393223524093628
          ],
          [
            "5",
            0.16584427654743195
          ]
        ],
        "inference_time": 1.3413279056549072
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9393223524093628
          ],
          [
            "5",
            0.16584427654743195
          ]
        ],
        "inference_time": 1.339566946029663
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 34,
    "sentence": "The Hollywood Reporter was particularly gushing of Jim Sturgess' performance - saying the actor had 'staked his claim as the new Hugh Grant only without the fussy mannerisms'.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.09224319458007812
          ]
        ],
        "inference_time": 1.3130743503570557
      },
      {
        "repetition": 1,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2669145166873932
          ]
        ],
        "inference_time": 1.3134586811065674
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.15208330750465393
          ]
        ],
        "inference_time": 1.3132822513580322
      },
      {
        "repetition": 3,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.15208330750465393
          ]
        ],
        "inference_time": 1.313215970993042
      },
      {
        "repetition": 4,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2669145166873932
          ]
        ],
        "inference_time": 1.3108723163604736
      },
      {
        "repetition": 5,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.19325518608093262
          ]
        ],
        "inference_time": 1.3138983249664307
      },
      {
        "repetition": 6,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.24814456701278687
          ]
        ],
        "inference_time": 1.3123395442962646
      },
      {
        "repetition": 7,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2669145166873932
          ]
        ],
        "inference_time": 1.3105802536010742
      },
      {
        "repetition": 8,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.24814456701278687
          ]
        ],
        "inference_time": 1.310713291168213
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.15208330750465393
          ]
        ],
        "inference_time": 1.311838150024414
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 35,
    "sentence": "The Neptune \"super missile\", revealed in August last year, was reportedly snatched from behind enemy lines during a raid on Putin's prized \u00a3200million air defence system.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "0",
            0.40753763914108276
          ]
        ],
        "inference_time": 1.312842607498169
      },
      {
        "repetition": 1,
        "generated_text": "\n3",
        "token_probs": [
          [
            "\n",
            0.1595662385225296
          ],
          [
            "3",
            0.10944150388240814
          ]
        ],
        "inference_time": 1.312929630279541
      },
      {
        "repetition": 2,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "1",
            0.33089444041252136
          ]
        ],
        "inference_time": 1.3132765293121338
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "2",
            0.10197383910417557
          ]
        ],
        "inference_time": 1.3116455078125
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "0",
            0.40753763914108276
          ]
        ],
        "inference_time": 1.3114993572235107
      },
      {
        "repetition": 5,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "2",
            0.10197383910417557
          ]
        ],
        "inference_time": 1.3124778270721436
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "0",
            0.40753763914108276
          ]
        ],
        "inference_time": 1.3119287490844727
      },
      {
        "repetition": 7,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "2",
            0.10197383910417557
          ]
        ],
        "inference_time": 1.3138208389282227
      },
      {
        "repetition": 8,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "1",
            0.33089444041252136
          ]
        ],
        "inference_time": 1.3133275508880615
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "0",
            0.40753763914108276
          ]
        ],
        "inference_time": 1.311558485031128
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 36,
    "sentence": "- Actor was on track to become a Hollywood star when he appeared in One Day  - Read More: How Taylor Swift's savvy marketing executive mother Andrea turned her daughter into a superstar  David Nicholls' romantic novel One Day became an overnight fan favourite when it was first released in 2009 and is now being rediscovered by a new audience thanks to Netflix's adaptation.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.6125674843788147
          ]
        ],
        "inference_time": 1.3436148166656494
      },
      {
        "repetition": 1,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.1424977332353592
          ]
        ],
        "inference_time": 1.3444342613220215
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.6125674843788147
          ]
        ],
        "inference_time": 1.342440128326416
      },
      {
        "repetition": 3,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.2449348121881485
          ]
        ],
        "inference_time": 1.3432872295379639
      },
      {
        "repetition": 4,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.2449348121881485
          ]
        ],
        "inference_time": 1.3435547351837158
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.6125674843788147
          ]
        ],
        "inference_time": 1.342604398727417
      },
      {
        "repetition": 6,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.2449348121881485
          ]
        ],
        "inference_time": 1.3426263332366943
      },
      {
        "repetition": 7,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.1424977332353592
          ]
        ],
        "inference_time": 1.3434453010559082
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.1424977332353592
          ]
        ],
        "inference_time": 1.3417599201202393
      },
      {
        "repetition": 9,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.2449348121881485
          ]
        ],
        "inference_time": 1.3426883220672607
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 37,
    "sentence": "\"$6k is a lot of money,\" wrote one.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "9",
            0.08907242864370346
          ]
        ],
        "inference_time": 1.3084867000579834
      },
      {
        "repetition": 1,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "5",
            0.13940268754959106
          ]
        ],
        "inference_time": 1.3073506355285645
      },
      {
        "repetition": 2,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "8",
            0.22745442390441895
          ]
        ],
        "inference_time": 1.308746576309204
      },
      {
        "repetition": 3,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "4",
            0.07083000987768173
          ]
        ],
        "inference_time": 1.3069586753845215
      },
      {
        "repetition": 4,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "8",
            0.22745442390441895
          ]
        ],
        "inference_time": 1.3087403774261475
      },
      {
        "repetition": 5,
        "generated_text": "\n5",
        "token_probs": [
          [
            "\n",
            0.09009299427270889
          ],
          [
            "5",
            0.1569938212633133
          ]
        ],
        "inference_time": 1.3086280822753906
      },
      {
        "repetition": 6,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "6",
            0.21817182004451752
          ]
        ],
        "inference_time": 1.3091764450073242
      },
      {
        "repetition": 7,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "7",
            0.25506868958473206
          ]
        ],
        "inference_time": 1.3074641227722168
      },
      {
        "repetition": 8,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "6",
            0.21817182004451752
          ]
        ],
        "inference_time": 1.307889461517334
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "5",
            0.13940268754959106
          ]
        ],
        "inference_time": 1.3082761764526367
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 38,
    "sentence": "He told The Independent in 2021: 'If someone does a bad one, I can\u2019t watch the film.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.7301626801490784
          ],
          [
            "2",
            0.2124805450439453
          ]
        ],
        "inference_time": 1.3101723194122314
      },
      {
        "repetition": 1,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.7301626801490784
          ],
          [
            "4",
            0.06616710126399994
          ]
        ],
        "inference_time": 1.310359239578247
      },
      {
        "repetition": 2,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.7301626801490784
          ],
          [
            "2",
            0.2124805450439453
          ]
        ],
        "inference_time": 1.310081958770752
      },
      {
        "repetition": 3,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.7301626801490784
          ],
          [
            "3",
            0.1491098701953888
          ]
        ],
        "inference_time": 1.3108937740325928
      },
      {
        "repetition": 4,
        "generated_text": "_\n",
        "token_probs": [
          [
            "_",
            0.03578906133770943
          ],
          [
            "\n",
            0.11320190876722336
          ]
        ],
        "inference_time": 1.3073666095733643
      },
      {
        "repetition": 5,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.7301626801490784
          ],
          [
            "1",
            0.24841491878032684
          ]
        ],
        "inference_time": 1.310089349746704
      },
      {
        "repetition": 6,
        "generated_text": "\n6",
        "token_probs": [
          [
            "\n",
            0.17893406748771667
          ],
          [
            "6",
            0.01930548995733261
          ]
        ],
        "inference_time": 1.3119091987609863
      },
      {
        "repetition": 7,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.7301626801490784
          ],
          [
            "2",
            0.2124805450439453
          ]
        ],
        "inference_time": 1.308562994003296
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.7301626801490784
          ],
          [
            "2",
            0.2124805450439453
          ]
        ],
        "inference_time": 1.3107402324676514
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.7301626801490784
          ],
          [
            "2",
            0.2124805450439453
          ]
        ],
        "inference_time": 1.3098571300506592
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 39,
    "sentence": "Gina Stewart has previously hit the headlines for her youthful appearance and most recently, immortalising herself as an AI model.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9000713229179382
          ],
          [
            "5",
            0.2208319753408432
          ]
        ],
        "inference_time": 1.3085541725158691
      },
      {
        "repetition": 1,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9000713229179382
          ],
          [
            "1",
            0.3603176772594452
          ]
        ],
        "inference_time": 1.311443567276001
      },
      {
        "repetition": 2,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9000713229179382
          ],
          [
            "2",
            0.12323204427957535
          ]
        ],
        "inference_time": 1.3126513957977295
      },
      {
        "repetition": 3,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9000713229179382
          ],
          [
            "1",
            0.3603176772594452
          ]
        ],
        "inference_time": 1.3077654838562012
      },
      {
        "repetition": 4,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9000713229179382
          ],
          [
            "5",
            0.2208319753408432
          ]
        ],
        "inference_time": 1.3107197284698486
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9000713229179382
          ],
          [
            "0",
            0.29561832547187805
          ]
        ],
        "inference_time": 1.310697078704834
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9000713229179382
          ],
          [
            "0",
            0.29561832547187805
          ]
        ],
        "inference_time": 1.3101427555084229
      },
      {
        "repetition": 7,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9000713229179382
          ],
          [
            "2",
            0.12323204427957535
          ]
        ],
        "inference_time": 1.307448387145996
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9000713229179382
          ],
          [
            "2",
            0.12323204427957535
          ]
        ],
        "inference_time": 1.3101181983947754
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9000713229179382
          ],
          [
            "0",
            0.29561832547187805
          ]
        ],
        "inference_time": 1.3083453178405762
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 40,
    "sentence": "Anne is a very warm actress.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "\n4",
        "token_probs": [
          [
            "\n",
            0.20585821568965912
          ],
          [
            "4",
            0.12324090301990509
          ]
        ],
        "inference_time": 1.3057990074157715
      },
      {
        "repetition": 1,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.7037011384963989
          ],
          [
            "2",
            0.20789475739002228
          ]
        ],
        "inference_time": 1.30759596824646
      },
      {
        "repetition": 2,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.7037011384963989
          ],
          [
            "3",
            0.2641761004924774
          ]
        ],
        "inference_time": 1.3072173595428467
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.7037011384963989
          ],
          [
            "2",
            0.20789475739002228
          ]
        ],
        "inference_time": 1.308483362197876
      },
      {
        "repetition": 4,
        "generated_text": "\n4",
        "token_probs": [
          [
            "\n",
            0.20585821568965912
          ],
          [
            "4",
            0.12324090301990509
          ]
        ],
        "inference_time": 1.3076696395874023
      },
      {
        "repetition": 5,
        "generated_text": "\nAn",
        "token_probs": [
          [
            "\n",
            0.20585821568965912
          ],
          [
            "An",
            0.031160181388258934
          ]
        ],
        "inference_time": 1.3076484203338623
      },
      {
        "repetition": 6,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.7037011384963989
          ],
          [
            "5",
            0.18732888996601105
          ]
        ],
        "inference_time": 1.3083367347717285
      },
      {
        "repetition": 7,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.7037011384963989
          ],
          [
            "4",
            0.18732888996601105
          ]
        ],
        "inference_time": 1.306431770324707
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.7037011384963989
          ],
          [
            "2",
            0.20789475739002228
          ]
        ],
        "inference_time": 1.3073673248291016
      },
      {
        "repetition": 9,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.7037011384963989
          ],
          [
            "4",
            0.18732888996601105
          ]
        ],
        "inference_time": 1.307800054550171
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 41,
    "sentence": "And I was good at it.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.7744511961936951
          ],
          [
            "2",
            0.09183800220489502
          ]
        ],
        "inference_time": 1.3058724403381348
      },
      {
        "repetition": 1,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.7744511961936951
          ],
          [
            "2",
            0.09183800220489502
          ]
        ],
        "inference_time": 1.3088853359222412
      },
      {
        "repetition": 2,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.7744511961936951
          ],
          [
            "7",
            0.1422414779663086
          ]
        ],
        "inference_time": 1.3069837093353271
      },
      {
        "repetition": 3,
        "generated_text": "<Your",
        "token_probs": [
          [
            "<",
            0.009698261506855488
          ],
          [
            "Your",
            0.33700984716415405
          ]
        ],
        "inference_time": 1.3069686889648438
      },
      {
        "repetition": 4,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.7744511961936951
          ],
          [
            "6",
            0.1422414779663086
          ]
        ],
        "inference_time": 1.3081471920013428
      },
      {
        "repetition": 5,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.7744511961936951
          ],
          [
            "7",
            0.1422414779663086
          ]
        ],
        "inference_time": 1.3093698024749756
      },
      {
        "repetition": 6,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.7744511961936951
          ],
          [
            "4",
            0.1179223284125328
          ]
        ],
        "inference_time": 1.3088858127593994
      },
      {
        "repetition": 7,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.7744511961936951
          ],
          [
            "2",
            0.09183800220489502
          ]
        ],
        "inference_time": 1.3076145648956299
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.7744511961936951
          ],
          [
            "5",
            0.19442105293273926
          ]
        ],
        "inference_time": 1.3101656436920166
      },
      {
        "repetition": 9,
        "generated_text": "__7",
        "token_probs": [
          [
            "__",
            0.012781363911926746
          ],
          [
            "7",
            0.08221137523651123
          ]
        ],
        "inference_time": 1.307309627532959
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 42,
    "sentence": "\u201cOn matters like femicide which society takes lightly, you don\u2019t just get justice,\u201d says Kamande.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.909049391746521
          ],
          [
            "7",
            0.20212557911872864
          ]
        ],
        "inference_time": 1.3084526062011719
      },
      {
        "repetition": 1,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.909049391746521
          ],
          [
            "8",
            0.1765267252922058
          ]
        ],
        "inference_time": 1.3099942207336426
      },
      {
        "repetition": 2,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.909049391746521
          ],
          [
            "6",
            0.1959068328142166
          ]
        ],
        "inference_time": 1.3106811046600342
      },
      {
        "repetition": 3,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.909049391746521
          ],
          [
            "8",
            0.1765267252922058
          ]
        ],
        "inference_time": 1.3097589015960693
      },
      {
        "repetition": 4,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.909049391746521
          ],
          [
            "5",
            0.16241247951984406
          ]
        ],
        "inference_time": 1.310798168182373
      },
      {
        "repetition": 5,
        "generated_text": "\n7",
        "token_probs": [
          [
            "\n",
            0.09095059335231781
          ],
          [
            "7",
            0.1878892481327057
          ]
        ],
        "inference_time": 1.311415195465088
      },
      {
        "repetition": 6,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.909049391746521
          ],
          [
            "7",
            0.20212557911872864
          ]
        ],
        "inference_time": 1.3084137439727783
      },
      {
        "repetition": 7,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.909049391746521
          ],
          [
            "6",
            0.1959068328142166
          ]
        ],
        "inference_time": 1.312211513519287
      },
      {
        "repetition": 8,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.909049391746521
          ],
          [
            "6",
            0.1959068328142166
          ]
        ],
        "inference_time": 1.3113248348236084
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.909049391746521
          ],
          [
            "5",
            0.16241247951984406
          ]
        ],
        "inference_time": 1.3101489543914795
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 43,
    "sentence": "hosted by Laura Rangeley and Michael Deakin).",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8466200828552246
          ],
          [
            "0",
            0.9449946880340576
          ]
        ],
        "inference_time": 1.3100759983062744
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8466200828552246
          ],
          [
            "0",
            0.9449946880340576
          ]
        ],
        "inference_time": 1.3099157810211182
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8466200828552246
          ],
          [
            "0",
            0.9449946880340576
          ]
        ],
        "inference_time": 1.3077478408813477
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8466200828552246
          ],
          [
            "0",
            0.9449946880340576
          ]
        ],
        "inference_time": 1.3099637031555176
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8466200828552246
          ],
          [
            "0",
            0.9449946880340576
          ]
        ],
        "inference_time": 1.3087120056152344
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8466200828552246
          ],
          [
            "0",
            0.9449946880340576
          ]
        ],
        "inference_time": 1.3105781078338623
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8466200828552246
          ],
          [
            "0",
            0.9449946880340576
          ]
        ],
        "inference_time": 1.310997486114502
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8466200828552246
          ],
          [
            "0",
            0.9449946880340576
          ]
        ],
        "inference_time": 1.308985710144043
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8466200828552246
          ],
          [
            "0",
            0.9449946880340576
          ]
        ],
        "inference_time": 1.311194896697998
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8466200828552246
          ],
          [
            "0",
            0.9449946880340576
          ]
        ],
        "inference_time": 1.3118555545806885
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 44,
    "sentence": "Following One Day, the actor was dubbed the 'new Hugh Grant'  Pictured: Jim Sturgess - who is now a musician - opposite David Jason in A Touch of Frost in March 2003  Speaking to The Telegraph at the time, Jim - who starred in the Beatles-inspired movie Across the Universe beforehand - admitted that he hadn't read the book when he had his first audition.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.2353815734386444
          ]
        ],
        "inference_time": 1.3438210487365723
      },
      {
        "repetition": 1,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.2353815734386444
          ]
        ],
        "inference_time": 1.3482775688171387
      },
      {
        "repetition": 2,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "3",
            0.11959664523601532
          ]
        ],
        "inference_time": 1.3450994491577148
      },
      {
        "repetition": 3,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.3645661175251007
          ]
        ],
        "inference_time": 1.3447461128234863
      },
      {
        "repetition": 4,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.19111491739749908
          ]
        ],
        "inference_time": 1.3467881679534912
      },
      {
        "repetition": 5,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.2353815734386444
          ]
        ],
        "inference_time": 1.343583345413208
      },
      {
        "repetition": 6,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.2353815734386444
          ]
        ],
        "inference_time": 1.3467023372650146
      },
      {
        "repetition": 7,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.2353815734386444
          ]
        ],
        "inference_time": 1.3445992469787598
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.2353815734386444
          ]
        ],
        "inference_time": 1.34486722946167
      },
      {
        "repetition": 9,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.3645661175251007
          ]
        ],
        "inference_time": 1.3483209609985352
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 45,
    "sentence": "He has collaborated with a bevy of big name artists - including Gomez herself, on tracks such as 2023's Single Soon, and his 2019 song I Can\u2019t Get Enough.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7871412634849548
          ]
        ],
        "inference_time": 1.3379771709442139
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7871412634849548
          ]
        ],
        "inference_time": 1.3396635055541992
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7871412634849548
          ]
        ],
        "inference_time": 1.3378911018371582
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7871412634849548
          ]
        ],
        "inference_time": 1.3375115394592285
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7871412634849548
          ]
        ],
        "inference_time": 1.3403491973876953
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7871412634849548
          ]
        ],
        "inference_time": 1.3398213386535645
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7871412634849548
          ]
        ],
        "inference_time": 1.339270830154419
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7871412634849548
          ]
        ],
        "inference_time": 1.3408160209655762
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7871412634849548
          ]
        ],
        "inference_time": 1.3385615348815918
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7871412634849548
          ]
        ],
        "inference_time": 1.3398618698120117
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 46,
    "sentence": "RULE 4: MOISTURISE  Gina uses organic coconut oil every day on her body, as she admitted \"I have moisturised my entire body every day since I was 19.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8952787518501282
          ],
          [
            "1",
            0.30909648537635803
          ]
        ],
        "inference_time": 1.314328670501709
      },
      {
        "repetition": 1,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8952787518501282
          ],
          [
            "1",
            0.30909648537635803
          ]
        ],
        "inference_time": 1.3141422271728516
      },
      {
        "repetition": 2,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8952787518501282
          ],
          [
            "3",
            0.12619388103485107
          ]
        ],
        "inference_time": 1.3135015964508057
      },
      {
        "repetition": 3,
        "generated_text": "\n\n",
        "token_probs": [
          [
            "\n",
            0.10472125560045242
          ],
          [
            "\n",
            0.21164247393608093
          ]
        ],
        "inference_time": 1.3138623237609863
      },
      {
        "repetition": 4,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8952787518501282
          ],
          [
            "5",
            0.2643842399120331
          ]
        ],
        "inference_time": 1.3144195079803467
      },
      {
        "repetition": 5,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8952787518501282
          ],
          [
            "1",
            0.30909648537635803
          ]
        ],
        "inference_time": 1.3135437965393066
      },
      {
        "repetition": 6,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8952787518501282
          ],
          [
            "3",
            0.12619388103485107
          ]
        ],
        "inference_time": 1.314666986465454
      },
      {
        "repetition": 7,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8952787518501282
          ],
          [
            "1",
            0.30909648537635803
          ]
        ],
        "inference_time": 1.3142585754394531
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8952787518501282
          ],
          [
            "2",
            0.22613981366157532
          ]
        ],
        "inference_time": 1.3147978782653809
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8952787518501282
          ],
          [
            "2",
            0.22613981366157532
          ]
        ],
        "inference_time": 1.3136515617370605
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 47,
    "sentence": "It\u2019s this second group that Barratt is targeting for Ayrton House \u2013 final year medical students and graduate trainees from the surrounding universities, which include Westminster, Middlesex and UCL.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7447161078453064
          ]
        ],
        "inference_time": 1.3101558685302734
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7447161078453064
          ]
        ],
        "inference_time": 1.3104846477508545
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7447161078453064
          ]
        ],
        "inference_time": 1.310983419418335
      },
      {
        "repetition": 3,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.10398566722869873
          ]
        ],
        "inference_time": 1.3126401901245117
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7447161078453064
          ]
        ],
        "inference_time": 1.3122520446777344
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7447161078453064
          ]
        ],
        "inference_time": 1.311168909072876
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7447161078453064
          ]
        ],
        "inference_time": 1.3123393058776855
      },
      {
        "repetition": 7,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.15129825472831726
          ]
        ],
        "inference_time": 1.310901165008545
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7447161078453064
          ]
        ],
        "inference_time": 1.3112733364105225
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.7447161078453064
          ]
        ],
        "inference_time": 1.3127853870391846
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 48,
    "sentence": "This is why the more Osborne slashed public spending in the 2010s, the more money he needed to borrow.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8499711751937866
          ],
          [
            "1",
            0.2911003828048706
          ]
        ],
        "inference_time": 1.311903715133667
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8499711751937866
          ],
          [
            "0",
            0.44619283080101013
          ]
        ],
        "inference_time": 1.3118000030517578
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8499711751937866
          ],
          [
            "0",
            0.44619283080101013
          ]
        ],
        "inference_time": 1.3124961853027344
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8499711751937866
          ],
          [
            "0",
            0.44619283080101013
          ]
        ],
        "inference_time": 1.312727451324463
      },
      {
        "repetition": 4,
        "generated_text": "\n\n",
        "token_probs": [
          [
            "\n",
            0.15002882480621338
          ],
          [
            "\n",
            0.1324954479932785
          ]
        ],
        "inference_time": 1.3125073909759521
      },
      {
        "repetition": 5,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8499711751937866
          ],
          [
            "1",
            0.2911003828048706
          ]
        ],
        "inference_time": 1.3127820491790771
      },
      {
        "repetition": 6,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8499711751937866
          ],
          [
            "1",
            0.2911003828048706
          ]
        ],
        "inference_time": 1.3119816780090332
      },
      {
        "repetition": 7,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8499711751937866
          ],
          [
            "1",
            0.2911003828048706
          ]
        ],
        "inference_time": 1.3113296031951904
      },
      {
        "repetition": 8,
        "generated_text": "\n0",
        "token_probs": [
          [
            "\n",
            0.15002882480621338
          ],
          [
            "0",
            0.07279077917337418
          ]
        ],
        "inference_time": 1.3127386569976807
      },
      {
        "repetition": 9,
        "generated_text": "\n0",
        "token_probs": [
          [
            "\n",
            0.15002882480621338
          ],
          [
            "0",
            0.07279077917337418
          ]
        ],
        "inference_time": 1.312047004699707
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 49,
    "sentence": "When your credit card is \u201cmaxed out\u201d, you do indeed need immediately to tighten your belt.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8976953029632568
          ],
          [
            "1",
            0.28088346123695374
          ]
        ],
        "inference_time": 1.311225414276123
      },
      {
        "repetition": 1,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8976953029632568
          ],
          [
            "3",
            0.17577238380908966
          ]
        ],
        "inference_time": 1.3128948211669922
      },
      {
        "repetition": 2,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8976953029632568
          ],
          [
            "1",
            0.28088346123695374
          ]
        ],
        "inference_time": 1.3107237815856934
      },
      {
        "repetition": 3,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8976953029632568
          ],
          [
            "1",
            0.28088346123695374
          ]
        ],
        "inference_time": 1.3126780986785889
      },
      {
        "repetition": 4,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8976953029632568
          ],
          [
            "1",
            0.28088346123695374
          ]
        ],
        "inference_time": 1.3110928535461426
      },
      {
        "repetition": 5,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8976953029632568
          ],
          [
            "2",
            0.2928342819213867
          ]
        ],
        "inference_time": 1.310537338256836
      },
      {
        "repetition": 6,
        "generated_text": "\n5",
        "token_probs": [
          [
            "\n",
            0.10230470448732376
          ],
          [
            "5",
            0.12725655734539032
          ]
        ],
        "inference_time": 1.3114268779754639
      },
      {
        "repetition": 7,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8976953029632568
          ],
          [
            "2",
            0.2928342819213867
          ]
        ],
        "inference_time": 1.3114333152770996
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8976953029632568
          ],
          [
            "2",
            0.2928342819213867
          ]
        ],
        "inference_time": 1.311898946762085
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8976953029632568
          ],
          [
            "2",
            0.2928342819213867
          ]
        ],
        "inference_time": 1.3126392364501953
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 50,
    "sentence": "This was inaccurate.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "\n8",
        "token_probs": [
          [
            "\n",
            0.09434022009372711
          ],
          [
            "8",
            0.12988939881324768
          ]
        ],
        "inference_time": 1.3087737560272217
      },
      {
        "repetition": 1,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.8950750827789307
          ],
          [
            "7",
            0.20597435534000397
          ]
        ],
        "inference_time": 1.309931755065918
      },
      {
        "repetition": 2,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.8950750827789307
          ],
          [
            "8",
            0.2238742858171463
          ]
        ],
        "inference_time": 1.3117949962615967
      },
      {
        "repetition": 3,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            0.8950750827789307
          ],
          [
            "9",
            0.12108607590198517
          ]
        ],
        "inference_time": 1.3092389106750488
      },
      {
        "repetition": 4,
        "generated_text": "\n7",
        "token_probs": [
          [
            "\n",
            0.09434022009372711
          ],
          [
            "7",
            0.25299006700515747
          ]
        ],
        "inference_time": 1.309659481048584
      },
      {
        "repetition": 5,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.8950750827789307
          ],
          [
            "8",
            0.2238742858171463
          ]
        ],
        "inference_time": 1.3105590343475342
      },
      {
        "repetition": 6,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            0.8950750827789307
          ],
          [
            "9",
            0.12108607590198517
          ]
        ],
        "inference_time": 1.309659719467163
      },
      {
        "repetition": 7,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8950750827789307
          ],
          [
            "3",
            0.06347642838954926
          ]
        ],
        "inference_time": 1.3092613220214844
      },
      {
        "repetition": 8,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8950750827789307
          ],
          [
            "3",
            0.06347642838954926
          ]
        ],
        "inference_time": 1.3099639415740967
      },
      {
        "repetition": 9,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.8950750827789307
          ],
          [
            "8",
            0.2238742858171463
          ]
        ],
        "inference_time": 1.3107287883758545
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 51,
    "sentence": "She now has her 26-year-old granddaughter, Eliza Brunero, lodging with her on Wednesdays each week.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3127784729003906
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3132641315460205
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3133642673492432
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3130953311920166
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3147754669189453
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.311816930770874
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3133699893951416
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3132586479187012
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.311525821685791
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3123705387115479
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 52,
    "sentence": "Wangari is one of 16 Kenyan women who have died allegedly at the hands of their partners since the start of 2024.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.313957929611206
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3137381076812744
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3131299018859863
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3145809173583984
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3123867511749268
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.31337308883667
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.314622163772583
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3139793872833252
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3136262893676758
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3140771389007568
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 53,
    "sentence": "And the Caesar Kunikov's watery demise is just the latest blow to have embarrassed Putin.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.219765767455101
          ]
        ],
        "inference_time": 1.3135557174682617
      },
      {
        "repetition": 1,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.12521876394748688
          ]
        ],
        "inference_time": 1.3128893375396729
      },
      {
        "repetition": 2,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.08084730058908463
          ]
        ],
        "inference_time": 1.3135342597961426
      },
      {
        "repetition": 3,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2706688642501831
          ]
        ],
        "inference_time": 1.3129210472106934
      },
      {
        "repetition": 4,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2706688642501831
          ]
        ],
        "inference_time": 1.3121669292449951
      },
      {
        "repetition": 5,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.219765767455101
          ]
        ],
        "inference_time": 1.3123235702514648
      },
      {
        "repetition": 6,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.219765767455101
          ]
        ],
        "inference_time": 1.3135545253753662
      },
      {
        "repetition": 7,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.08084730058908463
          ]
        ],
        "inference_time": 1.31467604637146
      },
      {
        "repetition": 8,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.22911617159843445
          ]
        ],
        "inference_time": 1.3109219074249268
      },
      {
        "repetition": 9,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2706688642501831
          ]
        ],
        "inference_time": 1.312669038772583
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 54,
    "sentence": "Beks then shared a clip of what happened straight after and continues: \"It was my lunch break and I just dipped out and didn't tell anybody.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8224802017211914
          ],
          [
            "2",
            0.22840319573879242
          ]
        ],
        "inference_time": 1.3151965141296387
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8224802017211914
          ],
          [
            "0",
            0.23079489171504974
          ]
        ],
        "inference_time": 1.3137576580047607
      },
      {
        "repetition": 2,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8224802017211914
          ],
          [
            "2",
            0.22840319573879242
          ]
        ],
        "inference_time": 1.314512014389038
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8224802017211914
          ],
          [
            "2",
            0.22840319573879242
          ]
        ],
        "inference_time": 1.3134899139404297
      },
      {
        "repetition": 4,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8224802017211914
          ],
          [
            "1",
            0.2213759571313858
          ]
        ],
        "inference_time": 1.315295696258545
      },
      {
        "repetition": 5,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8224802017211914
          ],
          [
            "1",
            0.2213759571313858
          ]
        ],
        "inference_time": 1.31500244140625
      },
      {
        "repetition": 6,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8224802017211914
          ],
          [
            "5",
            0.1505727618932724
          ]
        ],
        "inference_time": 1.313826084136963
      },
      {
        "repetition": 7,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8224802017211914
          ],
          [
            "2",
            0.22840319573879242
          ]
        ],
        "inference_time": 1.3134100437164307
      },
      {
        "repetition": 8,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8224802017211914
          ],
          [
            "1",
            0.2213759571313858
          ]
        ],
        "inference_time": 1.3149404525756836
      },
      {
        "repetition": 9,
        "generated_text": "\n____",
        "token_probs": [
          [
            "\n",
            0.1392517387866974
          ],
          [
            "____",
            0.017244765534996986
          ]
        ],
        "inference_time": 1.3135464191436768
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 55,
    "sentence": "I know you was heartbroken lol.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.9486642479896545
          ],
          [
            "7",
            0.06757214665412903
          ]
        ],
        "inference_time": 1.3114302158355713
      },
      {
        "repetition": 1,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9486642479896545
          ],
          [
            "1",
            0.5426854491233826
          ]
        ],
        "inference_time": 1.3115520477294922
      },
      {
        "repetition": 2,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9486642479896545
          ],
          [
            "1",
            0.5426854491233826
          ]
        ],
        "inference_time": 1.3103053569793701
      },
      {
        "repetition": 3,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            0.9486642479896545
          ],
          [
            "9",
            0.2309873402118683
          ]
        ],
        "inference_time": 1.3101961612701416
      },
      {
        "repetition": 4,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.9486642479896545
          ],
          [
            "7",
            0.06757214665412903
          ]
        ],
        "inference_time": 1.309622049331665
      },
      {
        "repetition": 5,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            0.9486642479896545
          ],
          [
            "9",
            0.2309873402118683
          ]
        ],
        "inference_time": 1.3113844394683838
      },
      {
        "repetition": 6,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.9486642479896545
          ],
          [
            "8",
            0.1587551236152649
          ]
        ],
        "inference_time": 1.3101022243499756
      },
      {
        "repetition": 7,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9486642479896545
          ],
          [
            "1",
            0.5426854491233826
          ]
        ],
        "inference_time": 1.3106114864349365
      },
      {
        "repetition": 8,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9486642479896545
          ],
          [
            "1",
            0.5426854491233826
          ]
        ],
        "inference_time": 1.3122761249542236
      },
      {
        "repetition": 9,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            0.9486642479896545
          ],
          [
            "9",
            0.2309873402118683
          ]
        ],
        "inference_time": 1.31184983253479
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 56,
    "sentence": "\u201cI can\u2019t say I add anything to her life but she certainly brightens up mine.\u201d  Brunero begs to differ.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.12771765887737274
          ]
        ],
        "inference_time": 1.3124232292175293
      },
      {
        "repetition": 1,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.23368851840496063
          ]
        ],
        "inference_time": 1.311164140701294
      },
      {
        "repetition": 2,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.2818821370601654
          ]
        ],
        "inference_time": 1.3125779628753662
      },
      {
        "repetition": 3,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.11750596016645432
          ]
        ],
        "inference_time": 1.3119027614593506
      },
      {
        "repetition": 4,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.12771765887737274
          ]
        ],
        "inference_time": 1.3120810985565186
      },
      {
        "repetition": 5,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.2818821370601654
          ]
        ],
        "inference_time": 1.311467170715332
      },
      {
        "repetition": 6,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.23368851840496063
          ]
        ],
        "inference_time": 1.312288522720337
      },
      {
        "repetition": 7,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.23368851840496063
          ]
        ],
        "inference_time": 1.3132660388946533
      },
      {
        "repetition": 8,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.12771765887737274
          ]
        ],
        "inference_time": 1.3129916191101074
      },
      {
        "repetition": 9,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.23368851840496063
          ]
        ],
        "inference_time": 1.3148667812347412
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 57,
    "sentence": "But while Leo Woodall is enjoying a career boost for his portrayal as 'pampered Southern toff' Dexter Mayhew, the 2011 film adaptation had the exact opposite effect for actor Jim Sturgess.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9340751767158508
          ],
          [
            "3",
            0.16770096123218536
          ]
        ],
        "inference_time": 1.3387477397918701
      },
      {
        "repetition": 1,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9340751767158508
          ],
          [
            "5",
            0.19811514019966125
          ]
        ],
        "inference_time": 1.3407256603240967
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9340751767158508
          ],
          [
            "5",
            0.19811514019966125
          ]
        ],
        "inference_time": 1.3427929878234863
      },
      {
        "repetition": 3,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9340751767158508
          ],
          [
            "5",
            0.19811514019966125
          ]
        ],
        "inference_time": 1.3418691158294678
      },
      {
        "repetition": 4,
        "generated_text": "\n\n",
        "token_probs": [
          [
            "\n",
            0.06592481583356857
          ],
          [
            "\n",
            0.179194837808609
          ]
        ],
        "inference_time": 1.3419818878173828
      },
      {
        "repetition": 5,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.9340751767158508
          ],
          [
            "8",
            0.07137983292341232
          ]
        ],
        "inference_time": 1.3418176174163818
      },
      {
        "repetition": 6,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9340751767158508
          ],
          [
            "2",
            0.11406464874744415
          ]
        ],
        "inference_time": 1.3421592712402344
      },
      {
        "repetition": 7,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9340751767158508
          ],
          [
            "2",
            0.11406464874744415
          ]
        ],
        "inference_time": 1.3428997993469238
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9340751767158508
          ],
          [
            "5",
            0.19811514019966125
          ]
        ],
        "inference_time": 1.339264154434204
      },
      {
        "repetition": 9,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9340751767158508
          ],
          [
            "3",
            0.16770096123218536
          ]
        ],
        "inference_time": 1.341609239578247
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 58,
    "sentence": "I scribbled down what I saw and what I felt and the song kind of wrote itself.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "\n__",
        "token_probs": [
          [
            "\n",
            0.12940272688865662
          ],
          [
            "__",
            0.01907196454703808
          ]
        ],
        "inference_time": 1.3122670650482178
      },
      {
        "repetition": 1,
        "generated_text": "\n----",
        "token_probs": [
          [
            "\n",
            0.12940272688865662
          ],
          [
            "----",
            0.022648517042398453
          ]
        ],
        "inference_time": 1.3123972415924072
      },
      {
        "repetition": 2,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.8705973029136658
          ],
          [
            "7",
            0.14652222394943237
          ]
        ],
        "inference_time": 1.3132197856903076
      },
      {
        "repetition": 3,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.8705973029136658
          ],
          [
            "8",
            0.35888826847076416
          ]
        ],
        "inference_time": 1.3114416599273682
      },
      {
        "repetition": 4,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.8705973029136658
          ],
          [
            "8",
            0.35888826847076416
          ]
        ],
        "inference_time": 1.3117990493774414
      },
      {
        "repetition": 5,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.8705973029136658
          ],
          [
            "8",
            0.35888826847076416
          ]
        ],
        "inference_time": 1.312659502029419
      },
      {
        "repetition": 6,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.8705973029136658
          ],
          [
            "8",
            0.35888826847076416
          ]
        ],
        "inference_time": 1.3130018711090088
      },
      {
        "repetition": 7,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.8705973029136658
          ],
          [
            "8",
            0.35888826847076416
          ]
        ],
        "inference_time": 1.3120431900024414
      },
      {
        "repetition": 8,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            0.8705973029136658
          ],
          [
            "9",
            0.3780755400657654
          ]
        ],
        "inference_time": 1.3131048679351807
      },
      {
        "repetition": 9,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            0.8705973029136658
          ],
          [
            "9",
            0.3780755400657654
          ]
        ],
        "inference_time": 1.3127555847167969
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 59,
    "sentence": "In the first image, the Emmy-nominated actress embraced Blanco, who has a passion for cooking, while he was preparing a platter of meatballs.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9284088015556335
          ],
          [
            "0",
            0.7336639165878296
          ]
        ],
        "inference_time": 1.3136706352233887
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9284088015556335
          ],
          [
            "0",
            0.7336639165878296
          ]
        ],
        "inference_time": 1.3141412734985352
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9284088015556335
          ],
          [
            "5",
            0.07494848221540451
          ]
        ],
        "inference_time": 1.314192295074463
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9284088015556335
          ],
          [
            "0",
            0.7336639165878296
          ]
        ],
        "inference_time": 1.3133909702301025
      },
      {
        "repetition": 4,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9284088015556335
          ],
          [
            "1",
            0.19138766825199127
          ]
        ],
        "inference_time": 1.3156471252441406
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9284088015556335
          ],
          [
            "0",
            0.7336639165878296
          ]
        ],
        "inference_time": 1.315788984298706
      },
      {
        "repetition": 6,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9284088015556335
          ],
          [
            "1",
            0.19138766825199127
          ]
        ],
        "inference_time": 1.3120825290679932
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9284088015556335
          ],
          [
            "0",
            0.7336639165878296
          ]
        ],
        "inference_time": 1.3130199909210205
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9284088015556335
          ],
          [
            "0",
            0.7336639165878296
          ]
        ],
        "inference_time": 1.3144047260284424
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9284088015556335
          ],
          [
            "0",
            0.7336639165878296
          ]
        ],
        "inference_time": 1.3120136260986328
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 60,
    "sentence": "It follows their range of Unmanned Surface Vehicles (USVs) which have been hugely successful in Black Sea attacks.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3094680309295654
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.31312894821167
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3125481605529785
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3124139308929443
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3129112720489502
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3134982585906982
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3134150505065918
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.312027931213379
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.312547206878662
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3141849040985107
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 61,
    "sentence": "But one person who knows exactly what's that like after getting the winning number on a scratchcard has told how they were left bitterly \"disappointed.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1763867437839508
          ]
        ],
        "inference_time": 1.313110113143921
      },
      {
        "repetition": 1,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.08596403896808624
          ]
        ],
        "inference_time": 1.313420057296753
      },
      {
        "repetition": 2,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.15087158977985382
          ]
        ],
        "inference_time": 1.3147187232971191
      },
      {
        "repetition": 3,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "3",
            0.13737013936042786
          ]
        ],
        "inference_time": 1.3124415874481201
      },
      {
        "repetition": 4,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "3",
            0.13737013936042786
          ]
        ],
        "inference_time": 1.3138530254364014
      },
      {
        "repetition": 5,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.18776272237300873
          ]
        ],
        "inference_time": 1.311544418334961
      },
      {
        "repetition": 6,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.18776272237300873
          ]
        ],
        "inference_time": 1.312601089477539
      },
      {
        "repetition": 7,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1763867437839508
          ]
        ],
        "inference_time": 1.3131544589996338
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.18776272237300873
          ]
        ],
        "inference_time": 1.3141701221466064
      },
      {
        "repetition": 9,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.14776098728179932
          ]
        ],
        "inference_time": 1.3137168884277344
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 62,
    "sentence": "Selena looked chic in a brown turtleneck, with her hair brushed back into a ponytail, while her other half rocked a white tee, and gold chains.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8393705487251282
          ],
          [
            "2",
            0.29620426893234253
          ]
        ],
        "inference_time": 1.312901258468628
      },
      {
        "repetition": 1,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8393705487251282
          ],
          [
            "1",
            0.2900969982147217
          ]
        ],
        "inference_time": 1.3142106533050537
      },
      {
        "repetition": 2,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8393705487251282
          ],
          [
            "2",
            0.29620426893234253
          ]
        ],
        "inference_time": 1.314396619796753
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8393705487251282
          ],
          [
            "2",
            0.29620426893234253
          ]
        ],
        "inference_time": 1.3151373863220215
      },
      {
        "repetition": 4,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8393705487251282
          ],
          [
            "2",
            0.29620426893234253
          ]
        ],
        "inference_time": 1.3148322105407715
      },
      {
        "repetition": 5,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8393705487251282
          ],
          [
            "2",
            0.29620426893234253
          ]
        ],
        "inference_time": 1.3133556842803955
      },
      {
        "repetition": 6,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8393705487251282
          ],
          [
            "3",
            0.16529227793216705
          ]
        ],
        "inference_time": 1.3151259422302246
      },
      {
        "repetition": 7,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8393705487251282
          ],
          [
            "2",
            0.29620426893234253
          ]
        ],
        "inference_time": 1.3156280517578125
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8393705487251282
          ],
          [
            "2",
            0.29620426893234253
          ]
        ],
        "inference_time": 1.3133254051208496
      },
      {
        "repetition": 9,
        "generated_text": "\nAn",
        "token_probs": [
          [
            "\n",
            0.14434932172298431
          ],
          [
            "An",
            0.021474573761224747
          ]
        ],
        "inference_time": 1.3154339790344238
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 63,
    "sentence": "The refreshing beer-and-fizzy-pop combination bubbled away as a quietly constant \u2013 if not cult \u2013 pub choice for over half my lifetime, then seemed to fizzle out over the past 15 years.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.0922635868191719
          ]
        ],
        "inference_time": 1.3372654914855957
      },
      {
        "repetition": 1,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.2057645618915558
          ]
        ],
        "inference_time": 1.3405895233154297
      },
      {
        "repetition": 2,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.1553192287683487
          ]
        ],
        "inference_time": 1.3404650688171387
      },
      {
        "repetition": 3,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.22364625334739685
          ]
        ],
        "inference_time": 1.3372933864593506
      },
      {
        "repetition": 4,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.2057645618915558
          ]
        ],
        "inference_time": 1.340982437133789
      },
      {
        "repetition": 5,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.0922635868191719
          ]
        ],
        "inference_time": 1.3396642208099365
      },
      {
        "repetition": 6,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.1553192287683487
          ]
        ],
        "inference_time": 1.340167760848999
      },
      {
        "repetition": 7,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.1553192287683487
          ]
        ],
        "inference_time": 1.342700481414795
      },
      {
        "repetition": 8,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.0922635868191719
          ]
        ],
        "inference_time": 1.340634822845459
      },
      {
        "repetition": 9,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.0922635868191719
          ]
        ],
        "inference_time": 1.3404169082641602
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 64,
    "sentence": "Kyiv continues to target Russia\u2019s Black Sea Fleet with great effectDr Bastian Giegerich, IISS security analyst  And Vlad's Black Sea fleet was \"put on the defensive by several events\", which included the sea drone attack in December that \"badly damaged a landing ship off Novorossiysk\".",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.3238909840583801
          ]
        ],
        "inference_time": 1.343773365020752
      },
      {
        "repetition": 1,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.06377790868282318
          ]
        ],
        "inference_time": 1.342979907989502
      },
      {
        "repetition": 2,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "3",
            0.23450806736946106
          ]
        ],
        "inference_time": 1.345409870147705
      },
      {
        "repetition": 3,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "3",
            0.23450806736946106
          ]
        ],
        "inference_time": 1.342726230621338
      },
      {
        "repetition": 4,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.3238909840583801
          ]
        ],
        "inference_time": 1.3415696620941162
      },
      {
        "repetition": 5,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.3238909840583801
          ]
        ],
        "inference_time": 1.3419673442840576
      },
      {
        "repetition": 6,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.2548879384994507
          ]
        ],
        "inference_time": 1.3423597812652588
      },
      {
        "repetition": 7,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.2548879384994507
          ]
        ],
        "inference_time": 1.3441669940948486
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.3238909840583801
          ]
        ],
        "inference_time": 1.3433887958526611
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.3238909840583801
          ]
        ],
        "inference_time": 1.3435914516448975
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 65,
    "sentence": "\u201cIt\u2019s such a bonus \u2013 sometimes I cook for her, sometimes she cooks for me, we play cards, we watch TV and we chat,\u201d Hamilton says.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "3",
            0.22942578792572021
          ]
        ],
        "inference_time": 1.3141827583312988
      },
      {
        "repetition": 1,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "4",
            0.11902453750371933
          ]
        ],
        "inference_time": 1.3133234977722168
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "5",
            0.17317967116832733
          ]
        ],
        "inference_time": 1.3128061294555664
      },
      {
        "repetition": 3,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "3",
            0.22942578792572021
          ]
        ],
        "inference_time": 1.312730073928833
      },
      {
        "repetition": 4,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "2",
            0.30079007148742676
          ]
        ],
        "inference_time": 1.3120484352111816
      },
      {
        "repetition": 5,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "2",
            0.30079007148742676
          ]
        ],
        "inference_time": 1.3123884201049805
      },
      {
        "repetition": 6,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "6",
            0.039868224412202835
          ]
        ],
        "inference_time": 1.3125660419464111
      },
      {
        "repetition": 7,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "3",
            0.22942578792572021
          ]
        ],
        "inference_time": 1.313807725906372
      },
      {
        "repetition": 8,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "1",
            0.13771173357963562
          ]
        ],
        "inference_time": 1.31235933303833
      },
      {
        "repetition": 9,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9099069833755493
          ],
          [
            "3",
            0.22942578792572021
          ]
        ],
        "inference_time": 1.313291072845459
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 66,
    "sentence": "She was fairly close to Wangari, and recalls with sadness how she had promised to send her money the following week so she could move to a new flat.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9248687624931335
          ],
          [
            "1",
            0.3918253183364868
          ]
        ],
        "inference_time": 1.3120908737182617
      },
      {
        "repetition": 1,
        "generated_text": "\n2",
        "token_probs": [
          [
            "\n",
            0.07513120025396347
          ],
          [
            "2",
            0.15548491477966309
          ]
        ],
        "inference_time": 1.3145403861999512
      },
      {
        "repetition": 2,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9248687624931335
          ],
          [
            "2",
            0.27784574031829834
          ]
        ],
        "inference_time": 1.3125190734863281
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9248687624931335
          ],
          [
            "2",
            0.27784574031829834
          ]
        ],
        "inference_time": 1.3127238750457764
      },
      {
        "repetition": 4,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9248687624931335
          ],
          [
            "2",
            0.27784574031829834
          ]
        ],
        "inference_time": 1.3137626647949219
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9248687624931335
          ],
          [
            "0",
            0.06599415093660355
          ]
        ],
        "inference_time": 1.3139634132385254
      },
      {
        "repetition": 6,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9248687624931335
          ],
          [
            "5",
            0.15996932983398438
          ]
        ],
        "inference_time": 1.3119544982910156
      },
      {
        "repetition": 7,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9248687624931335
          ],
          [
            "1",
            0.3918253183364868
          ]
        ],
        "inference_time": 1.3133480548858643
      },
      {
        "repetition": 8,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9248687624931335
          ],
          [
            "3",
            0.1043655052781105
          ]
        ],
        "inference_time": 1.3136041164398193
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9248687624931335
          ],
          [
            "2",
            0.27784574031829834
          ]
        ],
        "inference_time": 1.3147602081298828
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 67,
    "sentence": "And it could even be used to gather intelligence on Russian operations.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.6850283741950989
          ],
          [
            "2",
            0.2211291342973709
          ]
        ],
        "inference_time": 1.309877872467041
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.6850283741950989
          ],
          [
            "0",
            0.25852614641189575
          ]
        ],
        "inference_time": 1.3104422092437744
      },
      {
        "repetition": 2,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.6850283741950989
          ],
          [
            "3",
            0.11119071394205093
          ]
        ],
        "inference_time": 1.3127660751342773
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.6850283741950989
          ],
          [
            "2",
            0.2211291342973709
          ]
        ],
        "inference_time": 1.3084704875946045
      },
      {
        "repetition": 4,
        "generated_text": "\n\n",
        "token_probs": [
          [
            "\n",
            0.23185847699642181
          ],
          [
            "\n",
            0.15045389533042908
          ]
        ],
        "inference_time": 1.31003737449646
      },
      {
        "repetition": 5,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.6850283741950989
          ],
          [
            "5",
            0.11003845930099487
          ]
        ],
        "inference_time": 1.311875581741333
      },
      {
        "repetition": 6,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.6850283741950989
          ],
          [
            "3",
            0.11119071394205093
          ]
        ],
        "inference_time": 1.3113422393798828
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.6850283741950989
          ],
          [
            "0",
            0.25852614641189575
          ]
        ],
        "inference_time": 1.3104441165924072
      },
      {
        "repetition": 8,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.6850283741950989
          ],
          [
            "1",
            0.29911550879478455
          ]
        ],
        "inference_time": 1.3118305206298828
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.6850283741950989
          ],
          [
            "2",
            0.2211291342973709
          ]
        ],
        "inference_time": 1.3098506927490234
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 68,
    "sentence": "\"I'm not really a gambler - it was a $10k (\u00a37.9k) a week for life scratch card and I scratched it off.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.14998722076416016
          ]
        ],
        "inference_time": 1.3148303031921387
      },
      {
        "repetition": 1,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.17904427647590637
          ]
        ],
        "inference_time": 1.3149166107177734
      },
      {
        "repetition": 2,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.09991302341222763
          ]
        ],
        "inference_time": 1.31227707862854
      },
      {
        "repetition": 3,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.10201634466648102
          ]
        ],
        "inference_time": 1.3145089149475098
      },
      {
        "repetition": 4,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.12051812559366226
          ]
        ],
        "inference_time": 1.313758134841919
      },
      {
        "repetition": 5,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.12051812559366226
          ]
        ],
        "inference_time": 1.3122084140777588
      },
      {
        "repetition": 6,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.10201634466648102
          ]
        ],
        "inference_time": 1.3140506744384766
      },
      {
        "repetition": 7,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.17904427647590637
          ]
        ],
        "inference_time": 1.3129706382751465
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.17904427647590637
          ]
        ],
        "inference_time": 1.316408634185791
      },
      {
        "repetition": 9,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "3",
            0.15474833548069
          ]
        ],
        "inference_time": 1.3137447834014893
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 69,
    "sentence": "When it was an Emma and Dex day I felt good about it.'",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.814506471157074
          ],
          [
            "5",
            0.16812410950660706
          ]
        ],
        "inference_time": 1.3107562065124512
      },
      {
        "repetition": 1,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.814506471157074
          ],
          [
            "5",
            0.16812410950660706
          ]
        ],
        "inference_time": 1.3133695125579834
      },
      {
        "repetition": 2,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.814506471157074
          ],
          [
            "8",
            0.19050955772399902
          ]
        ],
        "inference_time": 1.31113600730896
      },
      {
        "repetition": 3,
        "generated_text": "\n7",
        "token_probs": [
          [
            "\n",
            0.14451964199543
          ],
          [
            "7",
            0.2049398422241211
          ]
        ],
        "inference_time": 1.3106200695037842
      },
      {
        "repetition": 4,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.814506471157074
          ],
          [
            "7",
            0.21587562561035156
          ]
        ],
        "inference_time": 1.311957597732544
      },
      {
        "repetition": 5,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.814506471157074
          ],
          [
            "7",
            0.21587562561035156
          ]
        ],
        "inference_time": 1.3124358654022217
      },
      {
        "repetition": 6,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.814506471157074
          ],
          [
            "8",
            0.19050955772399902
          ]
        ],
        "inference_time": 1.3117048740386963
      },
      {
        "repetition": 7,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.814506471157074
          ],
          [
            "5",
            0.16812410950660706
          ]
        ],
        "inference_time": 1.3124024868011475
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.814506471157074
          ],
          [
            "5",
            0.16812410950660706
          ]
        ],
        "inference_time": 1.3103206157684326
      },
      {
        "repetition": 9,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.814506471157074
          ],
          [
            "6",
            0.19861522316932678
          ]
        ],
        "inference_time": 1.3121168613433838
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 70,
    "sentence": "RULE 10: BE HAPPY  She then advised: \u201cLike the song don\u2019t worry be happy and create a life of meaningful memories.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.12627729773521423
          ]
        ],
        "inference_time": 1.3113489151000977
      },
      {
        "repetition": 1,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.08499958366155624
          ]
        ],
        "inference_time": 1.3135361671447754
      },
      {
        "repetition": 2,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.11986861377954483
          ]
        ],
        "inference_time": 1.313823938369751
      },
      {
        "repetition": 3,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.20390339195728302
          ]
        ],
        "inference_time": 1.313598394393921
      },
      {
        "repetition": 4,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.20390339195728302
          ]
        ],
        "inference_time": 1.3134593963623047
      },
      {
        "repetition": 5,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1621432602405548
          ]
        ],
        "inference_time": 1.31394362449646
      },
      {
        "repetition": 6,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.12627729773521423
          ]
        ],
        "inference_time": 1.3124523162841797
      },
      {
        "repetition": 7,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.12627729773521423
          ]
        ],
        "inference_time": 1.3139228820800781
      },
      {
        "repetition": 8,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.23591704666614532
          ]
        ],
        "inference_time": 1.3134286403656006
      },
      {
        "repetition": 9,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.11986861377954483
          ]
        ],
        "inference_time": 1.3146941661834717
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 71,
    "sentence": "But perhaps most impressively, Ukrainian forces managed to blow up Russia's flagship vessel - the Moskva - in April 2022.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9107572436332703
          ],
          [
            "5",
            0.17120809853076935
          ]
        ],
        "inference_time": 1.3121418952941895
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9107572436332703
          ],
          [
            "0",
            0.4022391140460968
          ]
        ],
        "inference_time": 1.3148491382598877
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9107572436332703
          ],
          [
            "5",
            0.17120809853076935
          ]
        ],
        "inference_time": 1.3141698837280273
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9107572436332703
          ],
          [
            "0",
            0.4022391140460968
          ]
        ],
        "inference_time": 1.312154769897461
      },
      {
        "repetition": 4,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9107572436332703
          ],
          [
            "1",
            0.3300122320652008
          ]
        ],
        "inference_time": 1.3140888214111328
      },
      {
        "repetition": 5,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9107572436332703
          ],
          [
            "1",
            0.3300122320652008
          ]
        ],
        "inference_time": 1.3139781951904297
      },
      {
        "repetition": 6,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9107572436332703
          ],
          [
            "2",
            0.09654060006141663
          ]
        ],
        "inference_time": 1.3137180805206299
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9107572436332703
          ],
          [
            "0",
            0.4022391140460968
          ]
        ],
        "inference_time": 1.3144760131835938
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9107572436332703
          ],
          [
            "5",
            0.17120809853076935
          ]
        ],
        "inference_time": 1.3136487007141113
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9107572436332703
          ],
          [
            "0",
            0.4022391140460968
          ]
        ],
        "inference_time": 1.3134281635284424
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 72,
    "sentence": "But Michelle evidently didn't hold the blunder against him; the couple have been married since 2015 after meeting in late 2012.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.38948941230773926
          ]
        ],
        "inference_time": 1.3131048679351807
      },
      {
        "repetition": 1,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.228969007730484
          ]
        ],
        "inference_time": 1.313347578048706
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.228969007730484
          ]
        ],
        "inference_time": 1.313255786895752
      },
      {
        "repetition": 3,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.38948941230773926
          ]
        ],
        "inference_time": 1.313462257385254
      },
      {
        "repetition": 4,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.38948941230773926
          ]
        ],
        "inference_time": 1.3144090175628662
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.24121065437793732
          ]
        ],
        "inference_time": 1.3152315616607666
      },
      {
        "repetition": 6,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.140330970287323
          ]
        ],
        "inference_time": 1.3138835430145264
      },
      {
        "repetition": 7,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.228969007730484
          ]
        ],
        "inference_time": 1.3127074241638184
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.228969007730484
          ]
        ],
        "inference_time": 1.3142855167388916
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.140330970287323
          ]
        ],
        "inference_time": 1.3137710094451904
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 73,
    "sentence": "Vigils, dubbed \u201cDark Valentine\u201d, were held across Kenya this week after a month in which more than a dozen women have been killed, allegedly by their partners.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.928061842918396
          ],
          [
            "2",
            0.30872267484664917
          ]
        ],
        "inference_time": 1.3135743141174316
      },
      {
        "repetition": 1,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.928061842918396
          ],
          [
            "5",
            0.16016322374343872
          ]
        ],
        "inference_time": 1.3148491382598877
      },
      {
        "repetition": 2,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.928061842918396
          ],
          [
            "1",
            0.3185226023197174
          ]
        ],
        "inference_time": 1.3128626346588135
      },
      {
        "repetition": 3,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.928061842918396
          ],
          [
            "5",
            0.16016322374343872
          ]
        ],
        "inference_time": 1.3130791187286377
      },
      {
        "repetition": 4,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.928061842918396
          ],
          [
            "2",
            0.30872267484664917
          ]
        ],
        "inference_time": 1.314460039138794
      },
      {
        "repetition": 5,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.928061842918396
          ],
          [
            "1",
            0.3185226023197174
          ]
        ],
        "inference_time": 1.3119683265686035
      },
      {
        "repetition": 6,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.928061842918396
          ],
          [
            "1",
            0.3185226023197174
          ]
        ],
        "inference_time": 1.3131067752838135
      },
      {
        "repetition": 7,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.928061842918396
          ],
          [
            "5",
            0.16016322374343872
          ]
        ],
        "inference_time": 1.3156790733337402
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.928061842918396
          ],
          [
            "2",
            0.30872267484664917
          ]
        ],
        "inference_time": 1.3134653568267822
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.928061842918396
          ],
          [
            "2",
            0.30872267484664917
          ]
        ],
        "inference_time": 1.3154714107513428
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 74,
    "sentence": "The radio presenter revealed the Fool Me Once star rumbled his porky pies the next day and fumed: 'Mark, you're a liar!'",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.935660719871521
          ],
          [
            "7",
            0.2664335370063782
          ]
        ],
        "inference_time": 1.3153376579284668
      },
      {
        "repetition": 1,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.935660719871521
          ],
          [
            "8",
            0.23269039392471313
          ]
        ],
        "inference_time": 1.314718246459961
      },
      {
        "repetition": 2,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.935660719871521
          ],
          [
            "6",
            0.21186703443527222
          ]
        ],
        "inference_time": 1.3139986991882324
      },
      {
        "repetition": 3,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.935660719871521
          ],
          [
            "7",
            0.2664335370063782
          ]
        ],
        "inference_time": 1.3156604766845703
      },
      {
        "repetition": 4,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.935660719871521
          ],
          [
            "8",
            0.23269039392471313
          ]
        ],
        "inference_time": 1.3147048950195312
      },
      {
        "repetition": 5,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.935660719871521
          ],
          [
            "7",
            0.2664335370063782
          ]
        ],
        "inference_time": 1.3149123191833496
      },
      {
        "repetition": 6,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.935660719871521
          ],
          [
            "6",
            0.21186703443527222
          ]
        ],
        "inference_time": 1.3152742385864258
      },
      {
        "repetition": 7,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.935660719871521
          ],
          [
            "8",
            0.23269039392471313
          ]
        ],
        "inference_time": 1.3132855892181396
      },
      {
        "repetition": 8,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.935660719871521
          ],
          [
            "7",
            0.2664335370063782
          ]
        ],
        "inference_time": 1.3149943351745605
      },
      {
        "repetition": 9,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.935660719871521
          ],
          [
            "6",
            0.21186703443527222
          ]
        ],
        "inference_time": 1.3158619403839111
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 75,
    "sentence": "The snap comes after Selena surprised fans on Monday with a very racy photo of Benny grabbing her cleavage  Gomez has been linked with Blanco, a musical artist, producer, and songwriter, since last year  In the first image from the post, the Emmy-nominated actress embraced Blanco, who has a passion for cooking, while he was preparing a platter of meatballs  Blanco was posed behind Gomez as they relaxed in the kitchen area of a home alongside friends including The Bear actor Matty Matheson  On Sunday, the couple was seen kissing one another while posed against a velvet red couch in a shot Gomez posted to Instagram  Gomez and Blanco have frequently shared their light-hearted and romantic moments via Instagram in the early days of their relationship.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.07721389085054398
          ]
        ],
        "inference_time": 1.4117274284362793
      },
      {
        "repetition": 1,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.1398162841796875
          ]
        ],
        "inference_time": 1.4136500358581543
      },
      {
        "repetition": 2,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.2667101323604584
          ]
        ],
        "inference_time": 1.409914493560791
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.2667101323604584
          ]
        ],
        "inference_time": 1.4131355285644531
      },
      {
        "repetition": 4,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.20988912880420685
          ]
        ],
        "inference_time": 1.4098687171936035
      },
      {
        "repetition": 5,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.07721389085054398
          ]
        ],
        "inference_time": 1.4121570587158203
      },
      {
        "repetition": 6,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.20988912880420685
          ]
        ],
        "inference_time": 1.4115135669708252
      },
      {
        "repetition": 7,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "3",
            0.24032600224018097
          ]
        ],
        "inference_time": 1.4116418361663818
      },
      {
        "repetition": 8,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.20988912880420685
          ]
        ],
        "inference_time": 1.4109854698181152
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.2667101323604584
          ]
        ],
        "inference_time": 1.4097743034362793
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 76,
    "sentence": "November 17, 2023  Sir, your article \u2018BBC crisis over \u00a31.7bn pension bill for stars\u2019 (4/11/2023) is incorrect and significantly inflates the BBC\u2019s obligation to fund its defined benefit pension scheme shortfall and employer contribution rate.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.11768370866775513
          ]
        ],
        "inference_time": 1.342130184173584
      },
      {
        "repetition": 1,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1152573674917221
          ]
        ],
        "inference_time": 1.3430593013763428
      },
      {
        "repetition": 2,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.14048273861408234
          ]
        ],
        "inference_time": 1.3434226512908936
      },
      {
        "repetition": 3,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.14048273861408234
          ]
        ],
        "inference_time": 1.344106674194336
      },
      {
        "repetition": 4,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1152573674917221
          ]
        ],
        "inference_time": 1.343153476715088
      },
      {
        "repetition": 5,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.19201713800430298
          ]
        ],
        "inference_time": 1.3427019119262695
      },
      {
        "repetition": 6,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.14048273861408234
          ]
        ],
        "inference_time": 1.3419930934906006
      },
      {
        "repetition": 7,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.14048273861408234
          ]
        ],
        "inference_time": 1.3444242477416992
      },
      {
        "repetition": 8,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1152573674917221
          ]
        ],
        "inference_time": 1.341615915298462
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.10604192316532135
          ]
        ],
        "inference_time": 1.341583251953125
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 77,
    "sentence": "The crime currently falls under homicide provisions, which rights groups say do not account for the unequal power relations between men and women that drive and characterise the killings.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.18023473024368286
          ]
        ],
        "inference_time": 1.3146884441375732
      },
      {
        "repetition": 1,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.2174045890569687
          ]
        ],
        "inference_time": 1.312330961227417
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.21292223036289215
          ]
        ],
        "inference_time": 1.3143584728240967
      },
      {
        "repetition": 3,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.21292223036289215
          ]
        ],
        "inference_time": 1.314453363418579
      },
      {
        "repetition": 4,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.21292223036289215
          ]
        ],
        "inference_time": 1.3127923011779785
      },
      {
        "repetition": 5,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "3",
            0.1332433521747589
          ]
        ],
        "inference_time": 1.313706636428833
      },
      {
        "repetition": 6,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.09547305852174759
          ]
        ],
        "inference_time": 1.3145771026611328
      },
      {
        "repetition": 7,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.21292223036289215
          ]
        ],
        "inference_time": 1.3126089572906494
      },
      {
        "repetition": 8,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "4",
            0.18023473024368286
          ]
        ],
        "inference_time": 1.314180612564087
      },
      {
        "repetition": 9,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.2174045890569687
          ]
        ],
        "inference_time": 1.3150060176849365
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 78,
    "sentence": "Fr\u00fch Natur Radler  2.5%; The Real Ale Store, \u00a31.85 for 500ml; Hop Burns & Black, \u00a32.30  If grapefruit is not your bag, seek out this lemony-fresh delight from Fr\u00fch.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9471207857131958
          ],
          [
            "0",
            0.3834797739982605
          ]
        ],
        "inference_time": 1.340411901473999
      },
      {
        "repetition": 1,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9471207857131958
          ],
          [
            "1",
            0.32460853457450867
          ]
        ],
        "inference_time": 1.3420732021331787
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9471207857131958
          ],
          [
            "0",
            0.3834797739982605
          ]
        ],
        "inference_time": 1.3411695957183838
      },
      {
        "repetition": 3,
        "generated_text": "\n1",
        "token_probs": [
          [
            "\n",
            0.05287922918796539
          ],
          [
            "1",
            0.11989156901836395
          ]
        ],
        "inference_time": 1.3408842086791992
      },
      {
        "repetition": 4,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9471207857131958
          ],
          [
            "1",
            0.32460853457450867
          ]
        ],
        "inference_time": 1.3419904708862305
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9471207857131958
          ],
          [
            "0",
            0.3834797739982605
          ]
        ],
        "inference_time": 1.340195894241333
      },
      {
        "repetition": 6,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9471207857131958
          ],
          [
            "1",
            0.32460853457450867
          ]
        ],
        "inference_time": 1.3411777019500732
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9471207857131958
          ],
          [
            "0",
            0.3834797739982605
          ]
        ],
        "inference_time": 1.341578722000122
      },
      {
        "repetition": 8,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9471207857131958
          ],
          [
            "1",
            0.32460853457450867
          ]
        ],
        "inference_time": 1.342200756072998
      },
      {
        "repetition": 9,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9471207857131958
          ],
          [
            "1",
            0.32460853457450867
          ]
        ],
        "inference_time": 1.3417716026306152
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 79,
    "sentence": "Following on from this, Jim went on to star in the 2012 adaptation of David Mitchell's Cloud Atlas, which also divided audiences.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "5",
            0.12610721588134766
          ]
        ],
        "inference_time": 1.3109042644500732
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "0",
            0.5309311747550964
          ]
        ],
        "inference_time": 1.312983751296997
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "0",
            0.5309311747550964
          ]
        ],
        "inference_time": 1.3136940002441406
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "0",
            0.5309311747550964
          ]
        ],
        "inference_time": 1.310640811920166
      },
      {
        "repetition": 4,
        "generated_text": "\n2",
        "token_probs": [
          [
            "\n",
            0.1595662385225296
          ],
          [
            "2",
            0.0701294019818306
          ]
        ],
        "inference_time": 1.3132874965667725
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "0",
            0.5309311747550964
          ]
        ],
        "inference_time": 1.31327223777771
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "0",
            0.5309311747550964
          ]
        ],
        "inference_time": 1.3121399879455566
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "0",
            0.5309311747550964
          ]
        ],
        "inference_time": 1.313279390335083
      },
      {
        "repetition": 8,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "1",
            0.2725893557071686
          ]
        ],
        "inference_time": 1.3153586387634277
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8404337763786316
          ],
          [
            "5",
            0.12610721588134766
          ]
        ],
        "inference_time": 1.3121275901794434
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 80,
    "sentence": "Limit your spending and you have limited your income too.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "\n---",
        "token_probs": [
          [
            "\n",
            0.15982301533222198
          ],
          [
            "---",
            0.12043122202157974
          ]
        ],
        "inference_time": 1.3094046115875244
      },
      {
        "repetition": 1,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.7624729871749878
          ],
          [
            "6",
            0.16043727099895477
          ]
        ],
        "inference_time": 1.3111662864685059
      },
      {
        "repetition": 2,
        "generated_text": "\n\n",
        "token_probs": [
          [
            "\n",
            0.15982301533222198
          ],
          [
            "\n",
            0.12819837033748627
          ]
        ],
        "inference_time": 1.3105974197387695
      },
      {
        "repetition": 3,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.7624729871749878
          ],
          [
            "7",
            0.14607980847358704
          ]
        ],
        "inference_time": 1.309187650680542
      },
      {
        "repetition": 4,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.7624729871749878
          ],
          [
            "6",
            0.16043727099895477
          ]
        ],
        "inference_time": 1.3097374439239502
      },
      {
        "repetition": 5,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.7624729871749878
          ],
          [
            "6",
            0.16043727099895477
          ]
        ],
        "inference_time": 1.3109073638916016
      },
      {
        "repetition": 6,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.7624729871749878
          ],
          [
            "5",
            0.13722927868366241
          ]
        ],
        "inference_time": 1.3093502521514893
      },
      {
        "repetition": 7,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.7624729871749878
          ],
          [
            "4",
            0.13300718367099762
          ]
        ],
        "inference_time": 1.3114933967590332
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.7624729871749878
          ],
          [
            "5",
            0.13722927868366241
          ]
        ],
        "inference_time": 1.3105602264404297
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.7624729871749878
          ],
          [
            "5",
            0.13722927868366241
          ]
        ],
        "inference_time": 1.3117666244506836
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 81,
    "sentence": "Unlike some of the other lemon offerings out there, this isn\u2019t soapy at all and has a very natural lemon flavouring.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9449946880340576
          ],
          [
            "5",
            0.2218017876148224
          ]
        ],
        "inference_time": 1.3118062019348145
      },
      {
        "repetition": 1,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9449946880340576
          ],
          [
            "3",
            0.22647106647491455
          ]
        ],
        "inference_time": 1.312821626663208
      },
      {
        "repetition": 2,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.9449946880340576
          ],
          [
            "4",
            0.2195032835006714
          ]
        ],
        "inference_time": 1.3111333847045898
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9449946880340576
          ],
          [
            "2",
            0.13736164569854736
          ]
        ],
        "inference_time": 1.3106029033660889
      },
      {
        "repetition": 4,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9449946880340576
          ],
          [
            "5",
            0.2218017876148224
          ]
        ],
        "inference_time": 1.314478874206543
      },
      {
        "repetition": 5,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9449946880340576
          ],
          [
            "5",
            0.2218017876148224
          ]
        ],
        "inference_time": 1.3127434253692627
      },
      {
        "repetition": 6,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9449946880340576
          ],
          [
            "5",
            0.2218017876148224
          ]
        ],
        "inference_time": 1.3104944229125977
      },
      {
        "repetition": 7,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9449946880340576
          ],
          [
            "5",
            0.2218017876148224
          ]
        ],
        "inference_time": 1.3125669956207275
      },
      {
        "repetition": 8,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9449946880340576
          ],
          [
            "2",
            0.13736164569854736
          ]
        ],
        "inference_time": 1.3107316493988037
      },
      {
        "repetition": 9,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.9449946880340576
          ],
          [
            "6",
            0.12506920099258423
          ]
        ],
        "inference_time": 1.3121838569641113
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 82,
    "sentence": "Blanco was past rumored to be in a romance with Elsie Hewitt, a 27-year-old model-actress from London (who has since been linked with Jason Sudeikis, 48).",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.4606863856315613
          ]
        ],
        "inference_time": 1.3392436504364014
      },
      {
        "repetition": 1,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.30370309948921204
          ]
        ],
        "inference_time": 1.3410940170288086
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.13904540240764618
          ]
        ],
        "inference_time": 1.3369719982147217
      },
      {
        "repetition": 3,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.0965651124715805
          ]
        ],
        "inference_time": 1.3399817943572998
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.4606863856315613
          ]
        ],
        "inference_time": 1.3385188579559326
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.4606863856315613
          ]
        ],
        "inference_time": 1.3384552001953125
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.4606863856315613
          ]
        ],
        "inference_time": 1.3396456241607666
      },
      {
        "repetition": 7,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "2",
            0.0965651124715805
          ]
        ],
        "inference_time": 1.3400166034698486
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            0.4606863856315613
          ]
        ],
        "inference_time": 1.34254789352417
      },
      {
        "repetition": 9,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "1",
            0.30370309948921204
          ]
        ],
        "inference_time": 1.338775634765625
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 83,
    "sentence": "The Schedule of Contributions agreed with the Scheme Trustee as part of the 2022 actuarial valuation states that the employer contribution rate for the defined benefit pension scheme is currently set to 30% of members\u2019 pensionable salaries.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3390452861785889
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3406291007995605
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.34201979637146
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.340592384338379
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3390538692474365
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3401694297790527
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3402388095855713
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3382208347320557
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3385965824127197
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "0",
            1.0
          ]
        ],
        "inference_time": 1.3398053646087646
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 84,
    "sentence": "So I wanted more.'",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "\n-----",
        "token_probs": [
          [
            "\n",
            0.1782657504081726
          ],
          [
            "-----",
            0.01353483647108078
          ]
        ],
        "inference_time": 1.3085432052612305
      },
      {
        "repetition": 1,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.6030652523040771
          ],
          [
            "3",
            0.1735415756702423
          ]
        ],
        "inference_time": 1.308582067489624
      },
      {
        "repetition": 2,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.6030652523040771
          ],
          [
            "1",
            0.0900321826338768
          ]
        ],
        "inference_time": 1.3084580898284912
      },
      {
        "repetition": 3,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.6030652523040771
          ],
          [
            "3",
            0.1735415756702423
          ]
        ],
        "inference_time": 1.3111152648925781
      },
      {
        "repetition": 4,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.6030652523040771
          ],
          [
            "4",
            0.13944457471370697
          ]
        ],
        "inference_time": 1.308640718460083
      },
      {
        "repetition": 5,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.6030652523040771
          ],
          [
            "5",
            0.184734046459198
          ]
        ],
        "inference_time": 1.3084385395050049
      },
      {
        "repetition": 6,
        "generated_text": "\n\n",
        "token_probs": [
          [
            "\n",
            0.1782657504081726
          ],
          [
            "\n",
            0.23619124293327332
          ]
        ],
        "inference_time": 1.3096282482147217
      },
      {
        "repetition": 7,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.6030652523040771
          ],
          [
            "4",
            0.13944457471370697
          ]
        ],
        "inference_time": 1.31020188331604
      },
      {
        "repetition": 8,
        "generated_text": "____",
        "token_probs": [
          [
            "_",
            0.057874418795108795
          ],
          [
            "___",
            0.17435777187347412
          ]
        ],
        "inference_time": 1.3103280067443848
      },
      {
        "repetition": 9,
        "generated_text": "\n---",
        "token_probs": [
          [
            "\n",
            0.1782657504081726
          ],
          [
            "---",
            0.14030364155769348
          ]
        ],
        "inference_time": 1.3086490631103516
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 85,
    "sentence": "Nearly half of Republicans and right-leaning independents said the US was providing too much aid to Ukraine, according to a survey by the Pew Research Center conducted late last year.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8670357465744019
          ],
          [
            "2",
            0.11266437917947769
          ]
        ],
        "inference_time": 1.3130619525909424
      },
      {
        "repetition": 1,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8670357465744019
          ],
          [
            "2",
            0.11266437917947769
          ]
        ],
        "inference_time": 1.314610242843628
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8670357465744019
          ],
          [
            "5",
            0.16564209759235382
          ]
        ],
        "inference_time": 1.314824104309082
      },
      {
        "repetition": 3,
        "generated_text": "\n0",
        "token_probs": [
          [
            "\n",
            0.13296423852443695
          ],
          [
            "0",
            0.09658575057983398
          ]
        ],
        "inference_time": 1.3141427040100098
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.8670357465744019
          ],
          [
            "0",
            0.2619525194168091
          ]
        ],
        "inference_time": 1.3124110698699951
      },
      {
        "repetition": 5,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8670357465744019
          ],
          [
            "1",
            0.4597409963607788
          ]
        ],
        "inference_time": 1.3134090900421143
      },
      {
        "repetition": 6,
        "generated_text": "\n---",
        "token_probs": [
          [
            "\n",
            0.13296423852443695
          ],
          [
            "---",
            0.07965646684169769
          ]
        ],
        "inference_time": 1.3141717910766602
      },
      {
        "repetition": 7,
        "generated_text": "\n1",
        "token_probs": [
          [
            "\n",
            0.13296423852443695
          ],
          [
            "1",
            0.11957851052284241
          ]
        ],
        "inference_time": 1.3137521743774414
      },
      {
        "repetition": 8,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8670357465744019
          ],
          [
            "1",
            0.4597409963607788
          ]
        ],
        "inference_time": 1.3142266273498535
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8670357465744019
          ],
          [
            "5",
            0.16564209759235382
          ]
        ],
        "inference_time": 1.3137495517730713
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 86,
    "sentence": "Meanwhile, some arch-conservatives suggested it was time for McConnell to step down.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8835042715072632
          ],
          [
            "5",
            0.19902081787586212
          ]
        ],
        "inference_time": 1.311690092086792
      },
      {
        "repetition": 1,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.8835042715072632
          ],
          [
            "3",
            0.10433172434568405
          ]
        ],
        "inference_time": 1.3135628700256348
      },
      {
        "repetition": 2,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.8835042715072632
          ],
          [
            "4",
            0.15022878348827362
          ]
        ],
        "inference_time": 1.3104362487792969
      },
      {
        "repetition": 3,
        "generated_text": "\n8",
        "token_probs": [
          [
            "\n",
            0.11649567633867264
          ],
          [
            "8",
            0.01908947341144085
          ]
        ],
        "inference_time": 1.3117332458496094
      },
      {
        "repetition": 4,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8835042715072632
          ],
          [
            "5",
            0.19902081787586212
          ]
        ],
        "inference_time": 1.3113930225372314
      },
      {
        "repetition": 5,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.8835042715072632
          ],
          [
            "4",
            0.15022878348827362
          ]
        ],
        "inference_time": 1.3112072944641113
      },
      {
        "repetition": 6,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.8835042715072632
          ],
          [
            "6",
            0.23026767373085022
          ]
        ],
        "inference_time": 1.3115150928497314
      },
      {
        "repetition": 7,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.8835042715072632
          ],
          [
            "8",
            0.12325340509414673
          ]
        ],
        "inference_time": 1.313169240951538
      },
      {
        "repetition": 8,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8835042715072632
          ],
          [
            "5",
            0.19902081787586212
          ]
        ],
        "inference_time": 1.3124384880065918
      },
      {
        "repetition": 9,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.8835042715072632
          ],
          [
            "6",
            0.23026767373085022
          ]
        ],
        "inference_time": 1.3125803470611572
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 87,
    "sentence": "\u201cI maintain a healthy weight that preserves my facial structure and collagen.\u201d",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.32206711173057556
          ]
        ],
        "inference_time": 1.3115406036376953
      },
      {
        "repetition": 1,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2482270747423172
          ]
        ],
        "inference_time": 1.3089001178741455
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.08759088814258575
          ]
        ],
        "inference_time": 1.3111257553100586
      },
      {
        "repetition": 3,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.18350830674171448
          ]
        ],
        "inference_time": 1.3105378150939941
      },
      {
        "repetition": 4,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.08759088814258575
          ]
        ],
        "inference_time": 1.3100147247314453
      },
      {
        "repetition": 5,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1586066037416458
          ]
        ],
        "inference_time": 1.3126208782196045
      },
      {
        "repetition": 6,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.08759088814258575
          ]
        ],
        "inference_time": 1.3115723133087158
      },
      {
        "repetition": 7,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.18350830674171448
          ]
        ],
        "inference_time": 1.3131260871887207
      },
      {
        "repetition": 8,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.18350830674171448
          ]
        ],
        "inference_time": 1.3114523887634277
      },
      {
        "repetition": 9,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1586066037416458
          ]
        ],
        "inference_time": 1.310309648513794
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 88,
    "sentence": "Later in a campaign speech, Trump rattled American allies in Europe when he claimed that he would encourage Russia to attack Nato allies who did not pay enough to maintain the security alliance.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "\n--",
        "token_probs": [
          [
            "\n",
            0.19032235443592072
          ],
          [
            "--",
            0.007110944949090481
          ]
        ],
        "inference_time": 1.3146541118621826
      },
      {
        "repetition": 1,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.8096776604652405
          ],
          [
            "2",
            0.22237667441368103
          ]
        ],
        "inference_time": 1.3139770030975342
      },
      {
        "repetition": 2,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.8096776604652405
          ],
          [
            "4",
            0.16439774632453918
          ]
        ],
        "inference_time": 1.3126864433288574
      },
      {
        "repetition": 3,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.8096776604652405
          ],
          [
            "4",
            0.16439774632453918
          ]
        ],
        "inference_time": 1.31471586227417
      },
      {
        "repetition": 4,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.8096776604652405
          ],
          [
            "4",
            0.16439774632453918
          ]
        ],
        "inference_time": 1.3136086463928223
      },
      {
        "repetition": 5,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.8096776604652405
          ],
          [
            "5",
            0.1465996950864792
          ]
        ],
        "inference_time": 1.3134238719940186
      },
      {
        "repetition": 6,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.8096776604652405
          ],
          [
            "4",
            0.16439774632453918
          ]
        ],
        "inference_time": 1.3128418922424316
      },
      {
        "repetition": 7,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.8096776604652405
          ],
          [
            "1",
            0.11065925657749176
          ]
        ],
        "inference_time": 1.3119292259216309
      },
      {
        "repetition": 8,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.8096776604652405
          ],
          [
            "4",
            0.16439774632453918
          ]
        ],
        "inference_time": 1.3129684925079346
      },
      {
        "repetition": 9,
        "generated_text": "\n\n",
        "token_probs": [
          [
            "\n",
            0.19032235443592072
          ],
          [
            "\n",
            0.16184435784816742
          ]
        ],
        "inference_time": 1.3137507438659668
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 89,
    "sentence": "Mark made the cheeky confession on-air while hosting his Heart FM radio programme on Monday, admitting he got 'clocked' by Michelle when she found the restaurant takeaway bag in the bin.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9270117282867432
          ],
          [
            "1",
            0.38313552737236023
          ]
        ],
        "inference_time": 1.3140521049499512
      },
      {
        "repetition": 1,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9270117282867432
          ],
          [
            "1",
            0.38313552737236023
          ]
        ],
        "inference_time": 1.3122735023498535
      },
      {
        "repetition": 2,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9270117282867432
          ],
          [
            "5",
            0.21830402314662933
          ]
        ],
        "inference_time": 1.3138649463653564
      },
      {
        "repetition": 3,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9270117282867432
          ],
          [
            "5",
            0.21830402314662933
          ]
        ],
        "inference_time": 1.3133764266967773
      },
      {
        "repetition": 4,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9270117282867432
          ],
          [
            "2",
            0.21830402314662933
          ]
        ],
        "inference_time": 1.3124146461486816
      },
      {
        "repetition": 5,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9270117282867432
          ],
          [
            "5",
            0.21830402314662933
          ]
        ],
        "inference_time": 1.3147778511047363
      },
      {
        "repetition": 6,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9270117282867432
          ],
          [
            "3",
            0.09994687139987946
          ]
        ],
        "inference_time": 1.3117074966430664
      },
      {
        "repetition": 7,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9270117282867432
          ],
          [
            "1",
            0.38313552737236023
          ]
        ],
        "inference_time": 1.3125767707824707
      },
      {
        "repetition": 8,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9270117282867432
          ],
          [
            "1",
            0.38313552737236023
          ]
        ],
        "inference_time": 1.3142285346984863
      },
      {
        "repetition": 9,
        "generated_text": "2",
        "token_probs": [
          [
            "",
            0.9270117282867432
          ],
          [
            "2",
            0.21830402314662933
          ]
        ],
        "inference_time": 1.311767339706421
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 90,
    "sentence": "\u201cIt has my facial expressions \u2013 my eyes, lips, hair, arms, legs, chest and butt, all dimples and textures fully integrated.\u201d  Fabulous will pay for your exclusive stories.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.9014590382575989
          ],
          [
            "8",
            0.3617905378341675
          ]
        ],
        "inference_time": 1.3104069232940674
      },
      {
        "repetition": 1,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.9014590382575989
          ],
          [
            "6",
            0.08157170563936234
          ]
        ],
        "inference_time": 1.3130862712860107
      },
      {
        "repetition": 2,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.9014590382575989
          ],
          [
            "7",
            0.18382467329502106
          ]
        ],
        "inference_time": 1.3146326541900635
      },
      {
        "repetition": 3,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.9014590382575989
          ],
          [
            "7",
            0.18382467329502106
          ]
        ],
        "inference_time": 1.3141863346099854
      },
      {
        "repetition": 4,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9014590382575989
          ],
          [
            "1",
            0.07906201481819153
          ]
        ],
        "inference_time": 1.313337802886963
      },
      {
        "repetition": 5,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.9014590382575989
          ],
          [
            "6",
            0.08157170563936234
          ]
        ],
        "inference_time": 1.3135600090026855
      },
      {
        "repetition": 6,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.9014590382575989
          ],
          [
            "8",
            0.3617905378341675
          ]
        ],
        "inference_time": 1.3148775100708008
      },
      {
        "repetition": 7,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            0.9014590382575989
          ],
          [
            "9",
            0.2937510013580322
          ]
        ],
        "inference_time": 1.3139708042144775
      },
      {
        "repetition": 8,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.9014590382575989
          ],
          [
            "8",
            0.3617905378341675
          ]
        ],
        "inference_time": 1.3146979808807373
      },
      {
        "repetition": 9,
        "generated_text": "\n\n",
        "token_probs": [
          [
            "\n",
            0.09854099154472351
          ],
          [
            "\n",
            0.07660087198019028
          ]
        ],
        "inference_time": 1.3131225109100342
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 91,
    "sentence": "Since the 2022 valuation, funding has improved.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9188694357872009
          ],
          [
            "0",
            0.9055452346801758
          ]
        ],
        "inference_time": 1.3111319541931152
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9188694357872009
          ],
          [
            "0",
            0.9055452346801758
          ]
        ],
        "inference_time": 1.3097162246704102
      },
      {
        "repetition": 2,
        "generated_text": "\n2",
        "token_probs": [
          [
            "\n",
            0.08113058656454086
          ],
          [
            "2",
            0.03302584961056709
          ]
        ],
        "inference_time": 1.311244010925293
      },
      {
        "repetition": 3,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9188694357872009
          ],
          [
            "1",
            0.09445478767156601
          ]
        ],
        "inference_time": 1.3108489513397217
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9188694357872009
          ],
          [
            "0",
            0.9055452346801758
          ]
        ],
        "inference_time": 1.3088417053222656
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9188694357872009
          ],
          [
            "0",
            0.9055452346801758
          ]
        ],
        "inference_time": 1.3106107711791992
      },
      {
        "repetition": 6,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9188694357872009
          ],
          [
            "1",
            0.09445478767156601
          ]
        ],
        "inference_time": 1.3107209205627441
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9188694357872009
          ],
          [
            "0",
            0.9055452346801758
          ]
        ],
        "inference_time": 1.310295820236206
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9188694357872009
          ],
          [
            "0",
            0.9055452346801758
          ]
        ],
        "inference_time": 1.3111016750335693
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9188694357872009
          ],
          [
            "0",
            0.9055452346801758
          ]
        ],
        "inference_time": 1.310788869857788
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 92,
    "sentence": "He said: 'At a very young age, the local theatre in my town went to local schools to cast a load of kids to be in a professional production of Wind In The Willows.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9000623226165771
          ],
          [
            "0",
            0.8035262227058411
          ]
        ],
        "inference_time": 1.3128578662872314
      },
      {
        "repetition": 1,
        "generated_text": "1",
        "token_probs": [
          [
            "",
            0.9000623226165771
          ],
          [
            "1",
            0.132545605301857
          ]
        ],
        "inference_time": 1.3147647380828857
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9000623226165771
          ],
          [
            "0",
            0.8035262227058411
          ]
        ],
        "inference_time": 1.31162428855896
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9000623226165771
          ],
          [
            "0",
            0.8035262227058411
          ]
        ],
        "inference_time": 1.3143351078033447
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9000623226165771
          ],
          [
            "0",
            0.8035262227058411
          ]
        ],
        "inference_time": 1.3135182857513428
      },
      {
        "repetition": 5,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9000623226165771
          ],
          [
            "5",
            0.06392815709114075
          ]
        ],
        "inference_time": 1.3118681907653809
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9000623226165771
          ],
          [
            "0",
            0.8035262227058411
          ]
        ],
        "inference_time": 1.314805030822754
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9000623226165771
          ],
          [
            "0",
            0.8035262227058411
          ]
        ],
        "inference_time": 1.3141255378723145
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "",
            0.9000623226165771
          ],
          [
            "0",
            0.8035262227058411
          ]
        ],
        "inference_time": 1.3123400211334229
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9000623226165771
          ],
          [
            "5",
            0.06392815709114075
          ]
        ],
        "inference_time": 1.3145320415496826
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 93,
    "sentence": "RULE 9: LOVE  According to Gina, you should love yourself, love your life, love others.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1617719829082489
          ]
        ],
        "inference_time": 1.3140244483947754
      },
      {
        "repetition": 1,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1617719829082489
          ]
        ],
        "inference_time": 1.31217360496521
      },
      {
        "repetition": 2,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1617719829082489
          ]
        ],
        "inference_time": 1.3100330829620361
      },
      {
        "repetition": 3,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.33541035652160645
          ]
        ],
        "inference_time": 1.3137800693511963
      },
      {
        "repetition": 4,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.08480501919984818
          ]
        ],
        "inference_time": 1.312056541442871
      },
      {
        "repetition": 5,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.1617719829082489
          ]
        ],
        "inference_time": 1.3111701011657715
      },
      {
        "repetition": 6,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.15679477155208588
          ]
        ],
        "inference_time": 1.3134093284606934
      },
      {
        "repetition": 7,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.33541035652160645
          ]
        ],
        "inference_time": 1.3107094764709473
      },
      {
        "repetition": 8,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.26121786236763
          ]
        ],
        "inference_time": 1.3114659786224365
      },
      {
        "repetition": 9,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.26121786236763
          ]
        ],
        "inference_time": 1.311856746673584
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 94,
    "sentence": "Anne Hathaway is not it.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.6263195872306824
          ],
          [
            "5",
            0.12405870854854584
          ]
        ],
        "inference_time": 1.309537410736084
      },
      {
        "repetition": 1,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            0.6263195872306824
          ],
          [
            "9",
            0.1153346598148346
          ]
        ],
        "inference_time": 1.309687852859497
      },
      {
        "repetition": 2,
        "generated_text": "\n\n",
        "token_probs": [
          [
            "\n",
            0.1794435679912567
          ],
          [
            "\n",
            0.17221978306770325
          ]
        ],
        "inference_time": 1.3094096183776855
      },
      {
        "repetition": 3,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.6263195872306824
          ],
          [
            "6",
            0.15601013600826263
          ]
        ],
        "inference_time": 1.3094696998596191
      },
      {
        "repetition": 4,
        "generated_text": "\n\n",
        "token_probs": [
          [
            "\n",
            0.1794435679912567
          ],
          [
            "\n",
            0.17221978306770325
          ]
        ],
        "inference_time": 1.3110156059265137
      },
      {
        "repetition": 5,
        "generated_text": "__\n",
        "token_probs": [
          [
            "__",
            0.02199692651629448
          ],
          [
            "\n",
            0.6565122604370117
          ]
        ],
        "inference_time": 1.3106725215911865
      },
      {
        "repetition": 6,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.6263195872306824
          ],
          [
            "6",
            0.15601013600826263
          ]
        ],
        "inference_time": 1.3089501857757568
      },
      {
        "repetition": 7,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.6263195872306824
          ],
          [
            "7",
            0.19415774941444397
          ]
        ],
        "inference_time": 1.3094992637634277
      },
      {
        "repetition": 8,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.6263195872306824
          ],
          [
            "3",
            0.055050723254680634
          ]
        ],
        "inference_time": 1.311025857925415
      },
      {
        "repetition": 9,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.6263195872306824
          ],
          [
            "5",
            0.12405870854854584
          ]
        ],
        "inference_time": 1.310739278793335
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 95,
    "sentence": "As she watches her granddaughters play, Wairimu wonders if things could have played out differently.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "\n---",
        "token_probs": [
          [
            "\n",
            0.07405265420675278
          ],
          [
            "---",
            0.10112979263067245
          ]
        ],
        "inference_time": 1.3093349933624268
      },
      {
        "repetition": 1,
        "generated_text": "\n7",
        "token_probs": [
          [
            "\n",
            0.07405265420675278
          ],
          [
            "7",
            0.12520429491996765
          ]
        ],
        "inference_time": 1.3117358684539795
      },
      {
        "repetition": 2,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.925947368144989
          ],
          [
            "6",
            0.22552761435508728
          ]
        ],
        "inference_time": 1.3113408088684082
      },
      {
        "repetition": 3,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.925947368144989
          ],
          [
            "6",
            0.22552761435508728
          ]
        ],
        "inference_time": 1.3104872703552246
      },
      {
        "repetition": 4,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.925947368144989
          ],
          [
            "7",
            0.1812165379524231
          ]
        ],
        "inference_time": 1.3121063709259033
      },
      {
        "repetition": 5,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.925947368144989
          ],
          [
            "7",
            0.1812165379524231
          ]
        ],
        "inference_time": 1.3101427555084229
      },
      {
        "repetition": 6,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.925947368144989
          ],
          [
            "5",
            0.20749549567699432
          ]
        ],
        "inference_time": 1.3108739852905273
      },
      {
        "repetition": 7,
        "generated_text": "\n(",
        "token_probs": [
          [
            "\n",
            0.07405265420675278
          ],
          [
            "(",
            0.027647346258163452
          ]
        ],
        "inference_time": 1.312354326248169
      },
      {
        "repetition": 8,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.925947368144989
          ],
          [
            "8",
            0.1271701157093048
          ]
        ],
        "inference_time": 1.3110439777374268
      },
      {
        "repetition": 9,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.925947368144989
          ],
          [
            "6",
            0.22552761435508728
          ]
        ],
        "inference_time": 1.308159589767456
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 96,
    "sentence": "RULE 5: ATTITUDE IS EVERYTHING  Gina stressed the importance of \"thinking yourself young\" as she suggested: \"You are what you think.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.3904983699321747
          ]
        ],
        "inference_time": 1.3135936260223389
      },
      {
        "repetition": 1,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2683853507041931
          ]
        ],
        "inference_time": 1.3134765625
      },
      {
        "repetition": 2,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.3904983699321747
          ]
        ],
        "inference_time": 1.3116097450256348
      },
      {
        "repetition": 3,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.2156536728143692
          ]
        ],
        "inference_time": 1.3127360343933105
      },
      {
        "repetition": 4,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.2156536728143692
          ]
        ],
        "inference_time": 1.3133304119110107
      },
      {
        "repetition": 5,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.3904983699321747
          ]
        ],
        "inference_time": 1.3144292831420898
      },
      {
        "repetition": 6,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2683853507041931
          ]
        ],
        "inference_time": 1.3127472400665283
      },
      {
        "repetition": 7,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2683853507041931
          ]
        ],
        "inference_time": 1.3120348453521729
      },
      {
        "repetition": 8,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2683853507041931
          ]
        ],
        "inference_time": 1.3146405220031738
      },
      {
        "repetition": 9,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.3904983699321747
          ]
        ],
        "inference_time": 1.3114051818847656
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 97,
    "sentence": "However, Variety wasn't so gushing - and said the drama 'should have stayed in quarantine'.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.21733610332012177
          ]
        ],
        "inference_time": 1.3114655017852783
      },
      {
        "repetition": 1,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2621573805809021
          ]
        ],
        "inference_time": 1.31235671043396
      },
      {
        "repetition": 2,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.4145853817462921
          ]
        ],
        "inference_time": 1.3111522197723389
      },
      {
        "repetition": 3,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.4145853817462921
          ]
        ],
        "inference_time": 1.312854528427124
      },
      {
        "repetition": 4,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2621573805809021
          ]
        ],
        "inference_time": 1.311063528060913
      },
      {
        "repetition": 5,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.4145853817462921
          ]
        ],
        "inference_time": 1.309020757675171
      },
      {
        "repetition": 6,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.21733610332012177
          ]
        ],
        "inference_time": 1.3129956722259521
      },
      {
        "repetition": 7,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.2621573805809021
          ]
        ],
        "inference_time": 1.311629295349121
      },
      {
        "repetition": 8,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.4145853817462921
          ]
        ],
        "inference_time": 1.3129632472991943
      },
      {
        "repetition": 9,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.21733610332012177
          ]
        ],
        "inference_time": 1.3115839958190918
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 98,
    "sentence": "The Ohio senator JD Vance, another Trump loyalist, claimed the effort to replenish Ukraine\u2019s war chest was a \u201cplot\u201d by the Republican establishment to \u201cstop the election of Donald Trump\u201d.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.30420809984207153
          ]
        ],
        "inference_time": 1.3133461475372314
      },
      {
        "repetition": 1,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.30420809984207153
          ]
        ],
        "inference_time": 1.3155415058135986
      },
      {
        "repetition": 2,
        "generated_text": "9",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "9",
            0.10513149946928024
          ]
        ],
        "inference_time": 1.3158848285675049
      },
      {
        "repetition": 3,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.30420809984207153
          ]
        ],
        "inference_time": 1.314671277999878
      },
      {
        "repetition": 4,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "8",
            0.30420809984207153
          ]
        ],
        "inference_time": 1.316232442855835
      },
      {
        "repetition": 5,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.32047203183174133
          ]
        ],
        "inference_time": 1.3147180080413818
      },
      {
        "repetition": 6,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.19641152024269104
          ]
        ],
        "inference_time": 1.3140428066253662
      },
      {
        "repetition": 7,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "5",
            0.07377685606479645
          ]
        ],
        "inference_time": 1.3154757022857666
      },
      {
        "repetition": 8,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "6",
            0.19641152024269104
          ]
        ],
        "inference_time": 1.3145601749420166
      },
      {
        "repetition": 9,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            1.0
          ],
          [
            "7",
            0.32047203183174133
          ]
        ],
        "inference_time": 1.3146862983703613
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 99,
    "sentence": "It\u2019s made me realise how much we take older people for granted.\u201d  Both Brunero and Hamilton can see how mutually beneficial a multigenerational community such as Ayrton House could be.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "3",
        "token_probs": [
          [
            "",
            0.9387258291244507
          ],
          [
            "3",
            0.10448060929775238
          ]
        ],
        "inference_time": 1.3148283958435059
      },
      {
        "repetition": 1,
        "generated_text": "\n7",
        "token_probs": [
          [
            "\n",
            0.06127411872148514
          ],
          [
            "7",
            0.21676704287528992
          ]
        ],
        "inference_time": 1.3125810623168945
      },
      {
        "repetition": 2,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.9387258291244507
          ],
          [
            "7",
            0.18528930842876434
          ]
        ],
        "inference_time": 1.3139212131500244
      },
      {
        "repetition": 3,
        "generated_text": "4",
        "token_probs": [
          [
            "",
            0.9387258291244507
          ],
          [
            "4",
            0.15201839804649353
          ]
        ],
        "inference_time": 1.3140192031860352
      },
      {
        "repetition": 4,
        "generated_text": "7",
        "token_probs": [
          [
            "",
            0.9387258291244507
          ],
          [
            "7",
            0.18528930842876434
          ]
        ],
        "inference_time": 1.3124806880950928
      },
      {
        "repetition": 5,
        "generated_text": "6",
        "token_probs": [
          [
            "",
            0.9387258291244507
          ],
          [
            "6",
            0.22820661962032318
          ]
        ],
        "inference_time": 1.3149335384368896
      },
      {
        "repetition": 6,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.9387258291244507
          ],
          [
            "8",
            0.13276563584804535
          ]
        ],
        "inference_time": 1.3153307437896729
      },
      {
        "repetition": 7,
        "generated_text": "5",
        "token_probs": [
          [
            "",
            0.9387258291244507
          ],
          [
            "5",
            0.1972394436597824
          ]
        ],
        "inference_time": 1.3122782707214355
      },
      {
        "repetition": 8,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.9387258291244507
          ],
          [
            "8",
            0.13276563584804535
          ]
        ],
        "inference_time": 1.3151071071624756
      },
      {
        "repetition": 9,
        "generated_text": "8",
        "token_probs": [
          [
            "",
            0.9387258291244507
          ],
          [
            "8",
            0.13276563584804535
          ]
        ],
        "inference_time": 1.3135943412780762
      }
    ],
    "predicted_label": 0
  }
]