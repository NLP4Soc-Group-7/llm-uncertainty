[
  {
    "sample_idx": 0,
    "sentence": "Blanco established himself earlier in his career working for Dr. Luke's Kasz Money Productions.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 6.424258232116699
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2625546455383301
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2647104263305664
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.263671875
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2651956081390381
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2655370235443115
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2668592929840088
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2658376693725586
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2648181915283203
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26541662216186523
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 1,
    "sentence": "RULE 13: ARTIFICIAL INTELLIGENCE  Not only this, but Gina also created an AI model of herself to achieve immortality.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7343677878379822
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2754979133605957
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7343677878379822
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26760387420654297
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7343677878379822
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26590728759765625
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2656322121620178
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2673311233520508
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2656322121620178
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2653803825378418
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7343677878379822
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26664257049560547
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7343677878379822
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26535749435424805
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7343677878379822
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26702237129211426
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2656322121620178
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26801633834838867
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7343677878379822
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2670762538909912
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 2,
    "sentence": "The valuation is required by law and the figure is assessed independently by a pension specialist and has been reviewed by the National Audit Office.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26847386360168457
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26663756370544434
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2670583724975586
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26615262031555176
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2675206661224365
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2638256549835205
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2673177719116211
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2684333324432373
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26738500595092773
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2671163082122803
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 3,
    "sentence": "A sip can really hit the spot after a long bike ride or a walk.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2928575277328491
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26541709899902344
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7071424722671509
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2675607204437256
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7071424722671509
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26554203033447266
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2928575277328491
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26618504524230957
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7071424722671509
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2653970718383789
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7071424722671509
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26536059379577637
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2928575277328491
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26395678520202637
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7071424722671509
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2646503448486328
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7071424722671509
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2657480239868164
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2928575277328491
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26253509521484375
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 4,
    "sentence": "Lobster!\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Objective",
        "token_probs": [
          [
            "Object",
            0.2672685980796814
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24498963356018066
      },
      {
        "repetition": 1,
        "generated_text": "This sentence",
        "token_probs": [
          [
            "This",
            0.18257378041744232
          ],
          [
            "sentence",
            1.0
          ]
        ],
        "inference_time": 0.24341821670532227
      },
      {
        "repetition": 2,
        "generated_text": "This sentence",
        "token_probs": [
          [
            "This",
            0.18257378041744232
          ],
          [
            "sentence",
            1.0
          ]
        ],
        "inference_time": 0.2455308437347412
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.404999703168869
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24538969993591309
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.404999703168869
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24768710136413574
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.404999703168869
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24495506286621094
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.404999703168869
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2456803321838379
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.404999703168869
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24574899673461914
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.404999703168869
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24533915519714355
      },
      {
        "repetition": 9,
        "generated_text": "Objective",
        "token_probs": [
          [
            "Object",
            0.2672685980796814
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24562883377075195
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 5,
    "sentence": "But this is precisely the reason why Labour must reject the austerian urges that, inevitably, spring from the credit card analogy.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8917691111564636
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2668747901916504
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8917691111564636
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26887083053588867
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8917691111564636
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2682034969329834
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8917691111564636
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2665584087371826
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8917691111564636
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2671043872833252
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8917691111564636
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26520228385925293
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.10823091864585876
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2698044776916504
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8917691111564636
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2692372798919678
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8917691111564636
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26545095443725586
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8917691111564636
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26925230026245117
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 6,
    "sentence": "Googled how to cook a good lobster and I read how hard it is to get it good because it can turn very tough, rubbery.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.23392675817012787
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2663078308105469
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7660732865333557
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26765990257263184
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7660732865333557
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2694971561431885
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7660732865333557
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26789188385009766
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.23392675817012787
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2684171199798584
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7660732865333557
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2648465633392334
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7660732865333557
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2680015563964844
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7660732865333557
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2662820816040039
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7660732865333557
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26712608337402344
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7660732865333557
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.267122745513916
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 7,
    "sentence": "Apartments cost from \u00a3392 per week to rent, which makes it more expensive than an average room in first-year halls (a single room without bathroom typically costs \u00a3250 per week) but more affordable than a lot of the postgraduate accommodation on offer.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3142402172088623
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31540632247924805
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31459641456604004
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31580615043640137
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3171229362487793
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31691884994506836
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3172132968902588
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3138749599456787
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31447482109069824
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31612181663513184
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 8,
    "sentence": "We apologise to TikTok for not approaching it for comment prior to publication.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26849913597106934
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26451969146728516
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26688456535339355
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26668334007263184
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26653313636779785
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2674987316131592
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26679301261901855
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2674274444580078
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2674872875213623
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.266620397567749
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 9,
    "sentence": "Crumbling parliament patched up with a few fig leaves  Parliament gained some new residents yesterday, and there are already questions as to their expenses.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2675788402557373
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2649812698364258
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26740336418151855
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26925230026245117
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26569461822509766
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26984214782714844
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26640844345092773
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2671041488647461
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26809191703796387
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2670567035675049
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 10,
    "sentence": "In 2019, he bagged a role in the ensemble movie Berlin, I Love You - which was labelled a 'empty, boring flop' by The Observer.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5746968984603882
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2693760395050049
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.4253031015396118
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27116918563842773
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5746968984603882
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26818203926086426
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5746968984603882
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27016663551330566
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5746968984603882
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27079105377197266
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5746968984603882
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2676661014556885
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5746968984603882
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2701082229614258
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5746968984603882
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26850175857543945
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5746968984603882
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.271312952041626
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.4253031015396118
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27042365074157715
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 11,
    "sentence": "By the way, she is honestly the best cook.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3727584779262543
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24535894393920898
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3727584779262543
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24848651885986328
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6272415518760681
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24750804901123047
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6272415518760681
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24895000457763672
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6272415518760681
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24673700332641602
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6272415518760681
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24815702438354492
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6272415518760681
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24843239784240723
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6272415518760681
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2493898868560791
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3727584779262543
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24730229377746582
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3727584779262543
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2481071949005127
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 12,
    "sentence": "Families are doubling down on calls for perpetrators to be brought to justice, and say changes on the handling of femicide cases are necessary.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7370646595954895
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2710530757904053
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7370646595954895
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26839780807495117
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7370646595954895
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26824092864990234
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7370646595954895
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2694261074066162
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2629353702068329
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26732444763183594
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7370646595954895
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2685055732727051
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7370646595954895
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2688255310058594
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2629353702068329
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26825404167175293
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2629353702068329
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27052760124206543
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7370646595954895
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26761746406555176
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 13,
    "sentence": "Anything we can actually do, we can afford.\u201d Britain\u2019s conundrum, today, is that the next government, whose job will be to fix the Tories\u2019 mess, is led by politicians who share neither Keynes\u2019s aims nor his innovative approach to public finance.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.3811599612236023
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3158433437347412
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.3617039918899536
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31813693046569824
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2571360468864441
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3174402713775635
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.3811599612236023
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32004237174987793
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2571360468864441
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31620121002197266
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2571360468864441
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31441569328308105
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.3811599612236023
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3147413730621338
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.3811599612236023
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31593799591064453
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.3811599612236023
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3185403347015381
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2571360468864441
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31780195236206055
      }
    ],
    "predicted_label": "ambiguous"
  },
  {
    "sample_idx": 14,
    "sentence": "\u201cI just believe in being the best version of myself that I can possibly be, it makes me feel good.\u201d  Read more real life stories  Not only does Gina swear by hydration - but she also has 13 other rules she sticks to like glue.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.34845778346061707
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3176000118255615
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.42399361729621887
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31821155548095703
      },
      {
        "repetition": 2,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.22754861414432526
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.31861305236816406
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.42399361729621887
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3145630359649658
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.42399361729621887
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3167381286621094
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.34845778346061707
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31646251678466797
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.34845778346061707
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3178689479827881
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.42399361729621887
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31755900382995605
      },
      {
        "repetition": 8,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.22754861414432526
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.3171346187591553
      },
      {
        "repetition": 9,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.22754861414432526
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.3188652992248535
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 15,
    "sentence": "\u201cRussia\u2019s dominance in the Black Sea is now challenged.\u201d  The Boxing Day blast saw Vlad's valuable landing ship - docked in Crimea - turned into a raging fireball.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.6230898499488831
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2750983238220215
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.6230898499488831
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2701084613800049
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.6230898499488831
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27094411849975586
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.06202709302306175
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26903223991394043
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.6230898499488831
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2712254524230957
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.6230898499488831
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2719888687133789
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.6230898499488831
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2698061466217041
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.6230898499488831
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27228260040283203
      },
      {
        "repetition": 8,
        "generated_text": "Objective",
        "token_probs": [
          [
            "Object",
            0.3148830533027649
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26999402046203613
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.6230898499488831
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27217721939086914
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 16,
    "sentence": "Sea drones & anti-ship missiles  The February 1 attack came after Ukraine unveiled its new underwater robot drone, a stealth Autonomous Underwater Vehicle (AUV).",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27188658714294434
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2686765193939209
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27251100540161133
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27298521995544434
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.270982027053833
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27246952056884766
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26854825019836426
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2722036838531494
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27190184593200684
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27015209197998047
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 17,
    "sentence": "\u201cThey\u2019re people who appreciate the onsite facilities such as the restaurant and gym and see living around older people as a lifestyle benefit rather than a hindrance,\u201d she explains.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.40833988785743713
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27106356620788574
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5916601419448853
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26938962936401367
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.40833988785743713
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27012157440185547
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.40833988785743713
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2710857391357422
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.40833988785743713
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27040648460388184
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5916601419448853
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.270932674407959
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5916601419448853
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2698354721069336
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.40833988785743713
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27126574516296387
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.40833988785743713
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27084898948669434
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5916601419448853
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26946210861206055
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 18,
    "sentence": "But none of this means that the ditched \u00a328bn policy was optimal or, indeed, that an incoming chancellor can safely commit the Treasury to borrow and spend unlimited amounts.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2712397575378418
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2693932056427002
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27131128311157227
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.271364688873291
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27058839797973633
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27191162109375
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26840829849243164
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2722005844116211
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27221155166625977
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.270737886428833
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 19,
    "sentence": "The record, which topped out at 41 on the Billboard 200, included contributions from Bieber, Halsey, Calvin Harris, Omar Apollo and Gracie Abrams.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31487417221069336
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.315305233001709
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3135688304901123
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3142366409301758
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31554102897644043
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3159818649291992
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3155355453491211
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3164095878601074
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31707167625427246
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31632447242736816
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 20,
    "sentence": "The journalist Mike Smith was struck yesterday when he noticed",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24654030799865723
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2501649856567383
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2481551170349121
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24963116645812988
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24811315536499023
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2492365837097168
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24954605102539062
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24919414520263672
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24899911880493164
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24831461906433105
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 21,
    "sentence": "Two years later, he stepped into a leading man role once again when he appeared in The Other Me - about a architect who has an eye disease which enables him to see people's real motives.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5347985029220581
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2772500514984131
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.4652014672756195
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2708296775817871
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5347985029220581
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2712395191192627
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5347985029220581
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2724311351776123
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5347985029220581
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26874804496765137
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5347985029220581
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2721288204193115
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5347985029220581
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27188706398010254
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5347985029220581
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2704930305480957
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5347985029220581
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.271648645401001
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.4652014672756195
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26970744132995605
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 22,
    "sentence": "At the time, Time magazine dubbed the film 'disjoined' - saying that 'characters that Nicholls brought so cunningly to life in the book feel rushed through a timeline, tied to an agenda'.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6982137560844421
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3147609233856201
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6982137560844421
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31690025329589844
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6982137560844421
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3180537223815918
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6982137560844421
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3159148693084717
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6982137560844421
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3159189224243164
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6982137560844421
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31502532958984375
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6982137560844421
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3147859573364258
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6982137560844421
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3161334991455078
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.30178630352020264
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3169846534729004
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6982137560844421
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31606364250183105
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 23,
    "sentence": "\u201cWe were in shock,\u201d says Wangari\u2019s father.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.45101383328437805
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24870944023132324
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5489861369132996
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24974966049194336
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5489861369132996
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2506711483001709
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5489861369132996
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24774384498596191
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.45101383328437805
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25002288818359375
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.45101383328437805
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2501065731048584
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5489861369132996
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.250993013381958
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.45101383328437805
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2493126392364502
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5489861369132996
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24790191650390625
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.45101383328437805
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25035643577575684
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 24,
    "sentence": "House Democrats and the remaining pro-Ukraine House Republicans are casting about behind the scenes for a solution.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26917409896850586
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26949262619018555
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2700212001800537
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26776576042175293
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2717928886413574
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2671971321105957
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26914334297180176
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2680518627166748
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26959228515625
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.269517183303833
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 25,
    "sentence": "Austerity, and the credit card analogy that provides its thin veneer of logic, is not just bad for workers and people in desperate need of state support during tough times; it also depresses investment.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7831204533576965
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2710893154144287
      },
      {
        "repetition": 1,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.10216227173805237
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.27344775199890137
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7831204533576965
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.271090030670166
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7831204533576965
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27171969413757324
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7831204533576965
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27185821533203125
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7831204533576965
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27169179916381836
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7831204533576965
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2715282440185547
      },
      {
        "repetition": 7,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.10216227173805237
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.2717728614807129
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7831204533576965
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27211880683898926
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7831204533576965
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27115321159362793
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 26,
    "sentence": "In a pre-dawn vote on Tuesday, Graham joined the majority of Senate Republicans in opposing a foreign aid package that would rush wartime assistance to Ukraine as it approaches the second anniversary of Russia\u2019s full invasion.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.315753698348999
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31812596321105957
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31772303581237793
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31618547439575195
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31472086906433105
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3162405490875244
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3157787322998047
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3168036937713623
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31760716438293457
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3141777515411377
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 27,
    "sentence": "The Observer's Philip French dubbed it 'thin, superficial and sentimental' and said the casting of Anne Hathway was 'disastrous'.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7393169403076172
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27173447608947754
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7393169403076172
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27312541007995605
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7393169403076172
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27020764350891113
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2606830596923828
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27156758308410645
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7393169403076172
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2723972797393799
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7393169403076172
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27082037925720215
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7393169403076172
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2708909511566162
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7393169403076172
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2701754570007324
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7393169403076172
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27126598358154297
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7393169403076172
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2732274532318115
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 28,
    "sentence": "A third commented: \"$20 for $6k - not bad!\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26724863052368164
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2688913345336914
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2666130065917969
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2676525115966797
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26964688301086426
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26651978492736816
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26744985580444336
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2672436237335205
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2690718173980713
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26907896995544434
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 29,
    "sentence": "The plan incorporates cash payments supplemented by contingent contributions.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24648404121398926
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2495560646057129
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24888062477111816
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2512640953063965
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24931740760803223
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2502586841583252
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2486248016357422
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25069189071655273
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24913287162780762
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25043487548828125
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 30,
    "sentence": "It is true that the Tories will leave scorched earth behind for the next government, with a budget dripping in red ink and a pitiful level of investment in the technologies and services the UK needs to escape a long-term slump.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.13128608465194702
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31815338134765625
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.868713915348053
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31701231002807617
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.868713915348053
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3182094097137451
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.868713915348053
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.317598819732666
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.868713915348053
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3181483745574951
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.13128608465194702
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3178067207336426
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.868713915348053
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3154735565185547
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.13128608465194702
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31511664390563965
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.868713915348053
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3169093132019043
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.868713915348053
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3163480758666992
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 31,
    "sentence": "A WOMAN who has been dubbed \u2018the world\u2019s hottest gran\u2019 has revealed how she stays looking eternally young at the age of 53.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27454543113708496
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2717568874359131
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2707390785217285
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27091526985168457
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2696845531463623
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27081727981567383
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27126073837280273
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2702517509460449
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2721879482269287
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27265048027038574
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 32,
    "sentence": "Couldn't say everything I wanted to in the video.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.4192656874656677
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24781465530395508
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5807343125343323
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25139856338500977
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5807343125343323
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24926018714904785
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5807343125343323
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.251772403717041
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5807343125343323
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24968981742858887
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5807343125343323
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25188732147216797
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5807343125343323
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24950742721557617
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.4192656874656677
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24971270561218262
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5807343125343323
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24952197074890137
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5807343125343323
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2506272792816162
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 33,
    "sentence": "From the Senate floor, Senator Mitch McConnell, the top Republican, delivered increasingly urgent pleas for his conference to rise to the occasion and support America\u2019s allies, even after his plan to tie border security to foreign aid collapsed, torpedoed by Trump\u2019s opposition.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32149362564086914
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3200380802154541
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31938934326171875
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3202321529388428
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31942319869995117
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3195512294769287
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31707024574279785
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31778407096862793
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31896162033081055
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3193345069885254
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 34,
    "sentence": "The Hollywood Reporter was particularly gushing of Jim Sturgess' performance - saying the actor had 'staked his claim as the new Hugh Grant only without the fussy mannerisms'.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7786161303520203
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2740304470062256
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.22138389945030212
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2713017463684082
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7786161303520203
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2712843418121338
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.22138389945030212
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27296924591064453
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7786161303520203
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2709083557128906
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7786161303520203
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2725076675415039
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.22138389945030212
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2727377414703369
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7786161303520203
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27013635635375977
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7786161303520203
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2726283073425293
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.22138389945030212
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26962971687316895
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 35,
    "sentence": "The Neptune \"super missile\", revealed in August last year, was reportedly snatched from behind enemy lines during a raid on Putin's prized \u00a3200million air defence system.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27161431312561035
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2727186679840088
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27082037925720215
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27377915382385254
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.273421049118042
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.271806001663208
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2718698978424072
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2717723846435547
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27286648750305176
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2729978561401367
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 36,
    "sentence": "- Actor was on track to become a Hollywood star when he appeared in One Day  - Read More: How Taylor Swift's savvy marketing executive mother Andrea turned her daughter into a superstar  David Nicholls' romantic novel One Day became an overnight fan favourite when it was first released in 2009 and is now being rediscovered by a new audience thanks to Netflix's adaptation.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32087111473083496
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3209190368652344
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32169628143310547
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32195472717285156
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32422780990600586
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3219265937805176
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3212761878967285
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32272768020629883
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32149457931518555
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.49776482582092285
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 37,
    "sentence": "\"$6k is a lot of money,\" wrote one.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6920487880706787
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2470707893371582
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3079511821269989
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24939274787902832
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3079511821269989
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24767351150512695
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6920487880706787
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.251192569732666
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6920487880706787
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2496659755706787
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3079511821269989
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.251145601272583
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6920487880706787
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24789667129516602
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6920487880706787
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2507302761077881
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6920487880706787
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24738693237304688
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6920487880706787
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25118160247802734
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 38,
    "sentence": "He told The Independent in 2021: 'If someone does a bad one, I can\u2019t watch the film.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3091377913951874
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27119946479797363
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3091377913951874
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26979875564575195
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.690862238407135
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.269850492477417
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.690862238407135
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26940417289733887
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.690862238407135
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2690913677215576
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3091377913951874
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2684342861175537
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3091377913951874
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2708406448364258
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3091377913951874
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2702953815460205
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3091377913951874
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27037477493286133
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.690862238407135
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27098608016967773
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 39,
    "sentence": "Gina Stewart has previously hit the headlines for her youthful appearance and most recently, immortalising herself as an AI model.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.541406512260437
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2684659957885742
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.541406512260437
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26999497413635254
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.3174731135368347
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2695882320404053
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.14112043380737305
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26967573165893555
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.541406512260437
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2714042663574219
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.3174731135368347
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2689340114593506
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.541406512260437
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2696235179901123
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.14112043380737305
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2709953784942627
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.3174731135368347
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2698040008544922
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.3174731135368347
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2710144519805908
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 40,
    "sentence": "Anne is a very warm actress.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7086423635482788
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2470090389251709
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2913576066493988
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2508125305175781
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7086423635482788
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2478804588317871
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7086423635482788
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24864649772644043
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2913576066493988
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24874329566955566
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2913576066493988
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25197815895080566
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2913576066493988
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24875569343566895
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7086423635482788
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2507491111755371
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7086423635482788
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24920058250427246
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2913576066493988
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25107884407043457
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 41,
    "sentence": "And I was good at it.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7977645993232727
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25086259841918945
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7977645993232727
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25135374069213867
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7977645993232727
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2508723735809326
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2022353857755661
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2493600845336914
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7977645993232727
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25041651725769043
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7977645993232727
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.251237154006958
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7977645993232727
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24948859214782715
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7977645993232727
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2480175495147705
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2022353857755661
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2504003047943115
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7977645993232727
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2469635009765625
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 42,
    "sentence": "\u201cOn matters like femicide which society takes lightly, you don\u2019t just get justice,\u201d says Kamande.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.18370285630226135
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.2767033576965332
      },
      {
        "repetition": 1,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.18370285630226135
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.2694718837738037
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5248091220855713
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2700309753417969
      },
      {
        "repetition": 3,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.18370285630226135
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.27077555656433105
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.29148802161216736
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26938486099243164
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5248091220855713
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2693657875061035
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.29148802161216736
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2693910598754883
      },
      {
        "repetition": 7,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.18370285630226135
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.27019810676574707
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5248091220855713
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2695002555847168
      },
      {
        "repetition": 9,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.18370285630226135
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.26921749114990234
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 43,
    "sentence": "hosted by Laura Rangeley and Michael Deakin).",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24781537055969238
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25002574920654297
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2510850429534912
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24950551986694336
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25049281120300293
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24916315078735352
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2513387203216553
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25017666816711426
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25197267532348633
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25061988830566406
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 44,
    "sentence": "Following One Day, the actor was dubbed the 'new Hugh Grant'  Pictured: Jim Sturgess - who is now a musician - opposite David Jason in A Touch of Frost in March 2003  Speaking to The Telegraph at the time, Jim - who starred in the Beatles-inspired movie Across the Universe beforehand - admitted that he hadn't read the book when he had his first audition.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.47132736444473267
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3349945545196533
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.47132736444473267
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32254934310913086
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.25435373187065125
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3234744071960449
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.47132736444473267
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32340455055236816
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.25435373187065125
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3234443664550781
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.47132736444473267
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32544565200805664
      },
      {
        "repetition": 6,
        "generated_text": "Objective",
        "token_probs": [
          [
            "Object",
            0.0893949344754219
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3242816925048828
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.47132736444473267
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32402515411376953
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.18492400646209717
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32377028465270996
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.18492400646209717
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3251044750213623
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 45,
    "sentence": "He has collaborated with a bevy of big name artists - including Gomez herself, on tracks such as 2023's Single Soon, and his 2019 song I Can\u2019t Get Enough.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3160114288330078
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31833529472351074
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3163871765136719
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.315021276473999
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31783080101013184
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31900835037231445
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31800246238708496
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31680798530578613
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31810498237609863
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3173539638519287
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 46,
    "sentence": "RULE 4: MOISTURISE  Gina uses organic coconut oil every day on her body, as she admitted \"I have moisturised my entire body every day since I was 19.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.18961955606937408
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27257323265075684
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.18961955606937408
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2733910083770752
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.18961955606937408
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27387285232543945
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8103804588317871
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27066612243652344
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8103804588317871
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2723557949066162
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8103804588317871
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27218127250671387
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8103804588317871
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2732713222503662
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8103804588317871
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2734098434448242
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8103804588317871
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2714958190917969
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8103804588317871
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2725248336791992
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 47,
    "sentence": "It\u2019s this second group that Barratt is targeting for Ayrton House \u2013 final year medical students and graduate trainees from the surrounding universities, which include Westminster, Middlesex and UCL.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6230422854423523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3160974979400635
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3769576847553253
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3140270709991455
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3769576847553253
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31522560119628906
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6230422854423523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31707024574279785
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3769576847553253
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3172752857208252
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3769576847553253
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31748461723327637
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6230422854423523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31822848320007324
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6230422854423523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31557297706604004
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6230422854423523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3154335021972656
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6230422854423523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3147146701812744
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 48,
    "sentence": "This is why the more Osborne slashed public spending in the 2010s, the more money he needed to borrow.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.47558867931365967
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2718338966369629
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.47558867931365967
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2730293273925781
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.47558867931365967
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27024292945861816
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5244113206863403
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27150821685791016
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.47558867931365967
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2719550132751465
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.47558867931365967
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27044224739074707
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5244113206863403
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2711522579193115
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.47558867931365967
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26984429359436035
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5244113206863403
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27166223526000977
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5244113206863403
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26987791061401367
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 49,
    "sentence": "When your credit card is \u201cmaxed out\u201d, you do indeed need immediately to tighten your belt.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6500191688537598
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27154111862182617
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6500191688537598
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27156782150268555
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3499808609485626
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26996493339538574
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6500191688537598
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27135562896728516
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6500191688537598
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.268604040145874
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6500191688537598
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27059459686279297
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3499808609485626
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26995086669921875
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3499808609485626
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27220773696899414
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6500191688537598
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2718024253845215
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3499808609485626
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26932668685913086
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 50,
    "sentence": "This was inaccurate.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24798965454101562
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24793624877929688
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25067877769470215
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.248748779296875
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25090503692626953
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2507669925689697
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25038814544677734
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25043797492980957
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2504856586456299
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2504136562347412
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 51,
    "sentence": "She now has her 26-year-old granddaughter, Eliza Brunero, lodging with her on Wednesdays each week.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.273392915725708
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2711503505706787
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27205967903137207
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26998329162597656
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2699286937713623
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2690248489379883
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27046990394592285
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2692410945892334
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27067136764526367
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27144360542297363
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 52,
    "sentence": "Wangari is one of 16 Kenyan women who have died allegedly at the hands of their partners since the start of 2024.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2691831588745117
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2711198329925537
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26878786087036133
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2706151008605957
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2722797393798828
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26821160316467285
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2710437774658203
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27165675163269043
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27161335945129395
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2718052864074707
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 53,
    "sentence": "And the Caesar Kunikov's watery demise is just the latest blow to have embarrassed Putin.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3018421530723572
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26892638206481934
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3018421530723572
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27055931091308594
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6981578469276428
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2688467502593994
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6981578469276428
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2702372074127197
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6981578469276428
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27169036865234375
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3018421530723572
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26734280586242676
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6981578469276428
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2703864574432373
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6981578469276428
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27043676376342773
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6981578469276428
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2690567970275879
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6981578469276428
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27225661277770996
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 54,
    "sentence": "Beks then shared a clip of what happened straight after and continues: \"It was my lunch break and I just dipped out and didn't tell anybody.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8097577691078186
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2700004577636719
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8097577691078186
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2710728645324707
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8097577691078186
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2718942165374756
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8097577691078186
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26915955543518066
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8097577691078186
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27140092849731445
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8097577691078186
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27095556259155273
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8097577691078186
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27013683319091797
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8097577691078186
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2720954418182373
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8097577691078186
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2696497440338135
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8097577691078186
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2722647190093994
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 55,
    "sentence": "I know you was heartbroken lol.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.4965863823890686
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24765801429748535
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5034136176109314
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24916648864746094
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5034136176109314
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2502119541168213
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5034136176109314
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2507801055908203
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5034136176109314
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2507741451263428
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5034136176109314
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2492372989654541
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.4965863823890686
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2507302761077881
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.4965863823890686
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24994587898254395
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5034136176109314
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25084471702575684
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.4965863823890686
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24991464614868164
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 56,
    "sentence": "\u201cI can\u2019t say I add anything to her life but she certainly brightens up mine.\u201d  Brunero begs to differ.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6472958922386169
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2813398838043213
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.35270413756370544
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27026891708374023
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6472958922386169
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27066540718078613
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.35270413756370544
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2692222595214844
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6472958922386169
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27236461639404297
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6472958922386169
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2715117931365967
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.35270413756370544
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2694389820098877
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6472958922386169
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27032899856567383
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.35270413756370544
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2704122066497803
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.35270413756370544
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27082180976867676
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 57,
    "sentence": "But while Leo Woodall is enjoying a career boost for his portrayal as 'pampered Southern toff' Dexter Mayhew, the 2011 film adaptation had the exact opposite effect for actor Jim Sturgess.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8556286692619324
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.317000150680542
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8556286692619324
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3170490264892578
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8556286692619324
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31577038764953613
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8556286692619324
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31711649894714355
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8556286692619324
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31685519218444824
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8556286692619324
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31807613372802734
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8556286692619324
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31941723823547363
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8556286692619324
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3199279308319092
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8556286692619324
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3190155029296875
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8556286692619324
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31900858879089355
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 58,
    "sentence": "I scribbled down what I saw and what I felt and the song kind of wrote itself.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7214715480804443
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27018141746520996
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7214715480804443
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26972413063049316
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7214715480804443
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2686648368835449
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.27852845191955566
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2683084011077881
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7214715480804443
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26895666122436523
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.27852845191955566
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2715754508972168
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7214715480804443
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.269594669342041
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.27852845191955566
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2715573310852051
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7214715480804443
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2692220211029053
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7214715480804443
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2706868648529053
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 59,
    "sentence": "In the first image, the Emmy-nominated actress embraced Blanco, who has a passion for cooking, while he was preparing a platter of meatballs.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27231335639953613
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2717461585998535
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2727317810058594
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2700228691101074
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27199220657348633
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27340030670166016
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27048516273498535
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2726302146911621
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2709031105041504
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27150392532348633
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 60,
    "sentence": "It follows their range of Unmanned Surface Vehicles (USVs) which have been hugely successful in Black Sea attacks.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27304744720458984
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26894283294677734
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2711632251739502
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.273144006729126
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2700173854827881
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27143239974975586
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2703745365142822
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27129507064819336
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2715165615081787
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26973414421081543
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 61,
    "sentence": "But one person who knows exactly what's that like after getting the winning number on a scratchcard has told how they were left bitterly \"disappointed.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.4285607933998108
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27167320251464844
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.4285607933998108
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2715482711791992
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.4285607933998108
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27144289016723633
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.4285607933998108
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27194738388061523
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.4285607933998108
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26938366889953613
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.4285607933998108
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27115654945373535
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5714392066001892
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27102184295654297
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5714392066001892
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2708606719970703
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5714392066001892
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27173614501953125
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5714392066001892
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2692136764526367
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 62,
    "sentence": "Selena looked chic in a brown turtleneck, with her hair brushed back into a ponytail, while her other half rocked a white tee, and gold chains.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7016352415084839
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2728240489959717
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7016352415084839
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27229905128479004
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2983647882938385
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27124667167663574
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7016352415084839
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2735569477081299
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2983647882938385
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27265477180480957
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7016352415084839
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2723555564880371
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2983647882938385
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27194809913635254
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7016352415084839
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2705855369567871
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7016352415084839
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27352094650268555
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7016352415084839
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2732987403869629
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 63,
    "sentence": "The refreshing beer-and-fizzy-pop combination bubbled away as a quietly constant \u2013 if not cult \u2013 pub choice for over half my lifetime, then seemed to fizzle out over the past 15 years.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7147940993309021
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31667327880859375
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7147940993309021
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.319411039352417
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7147940993309021
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31802845001220703
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7147940993309021
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31892943382263184
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2852059006690979
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31865382194519043
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7147940993309021
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3179454803466797
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7147940993309021
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3173980712890625
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2852059006690979
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31781697273254395
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7147940993309021
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31525325775146484
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7147940993309021
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31577038764953613
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 64,
    "sentence": "Kyiv continues to target Russia\u2019s Black Sea Fleet with great effectDr Bastian Giegerich, IISS security analyst  And Vlad's Black Sea fleet was \"put on the defensive by several events\", which included the sea drone attack in December that \"badly damaged a landing ship off Novorossiysk\".",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32199573516845703
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32239651679992676
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32247304916381836
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3217897415161133
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3226280212402344
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32326340675354004
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3215672969818115
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31957387924194336
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3202180862426758
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3201465606689453
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 65,
    "sentence": "\u201cIt\u2019s such a bonus \u2013 sometimes I cook for her, sometimes she cooks for me, we play cards, we watch TV and we chat,\u201d Hamilton says.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.3987084925174713
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27278685569763184
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.3987084925174713
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27085351943969727
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5022346377372742
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.269852876663208
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5022346377372742
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2718675136566162
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5022346377372742
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2715566158294678
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5022346377372742
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2716507911682129
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.3987084925174713
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2735257148742676
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.3987084925174713
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27031421661376953
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5022346377372742
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27193641662597656
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5022346377372742
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.270491361618042
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 66,
    "sentence": "She was fairly close to Wangari, and recalls with sadness how she had promised to send her money the following week so she could move to a new flat.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3966866135597229
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2724640369415283
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3966866135597229
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2730252742767334
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3966866135597229
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2713024616241455
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.47162362933158875
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27076148986816406
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.47162362933158875
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27194833755493164
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.47162362933158875
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2699320316314697
      },
      {
        "repetition": 6,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.13168980181217194
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.2711188793182373
      },
      {
        "repetition": 7,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.13168980181217194
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.27074766159057617
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3966866135597229
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2697575092315674
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3966866135597229
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27154970169067383
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 67,
    "sentence": "And it could even be used to gather intelligence on Russian operations.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24828433990478516
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25176215171813965
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.249284029006958
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25127315521240234
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24976468086242676
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2518043518066406
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24945330619812012
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25153160095214844
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2506997585296631
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25200748443603516
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 68,
    "sentence": "\"I'm not really a gambler - it was a $10k (\u00a37.9k) a week for life scratch card and I scratched it off.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5168365240097046
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27434825897216797
      },
      {
        "repetition": 1,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.2070910930633545
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.2729823589324951
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5168365240097046
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.271653413772583
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5168365240097046
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2731132507324219
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5168365240097046
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27316904067993164
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5168365240097046
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2710905075073242
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.27607232332229614
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2744309902191162
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.27607232332229614
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2723240852355957
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.27607232332229614
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27324509620666504
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.5168365240097046
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27358150482177734
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 69,
    "sentence": "When it was an Emma and Dex day I felt good about it.'",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.23875465989112854
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2667098045349121
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7612453103065491
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26972436904907227
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7612453103065491
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26743006706237793
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7612453103065491
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2710416316986084
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7612453103065491
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26865196228027344
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.23875465989112854
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26929140090942383
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7612453103065491
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2714383602142334
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7612453103065491
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2660250663757324
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7612453103065491
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2683119773864746
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7612453103065491
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26831793785095215
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 70,
    "sentence": "RULE 10: BE HAPPY  She then advised: \u201cLike the song don\u2019t worry be happy and create a life of meaningful memories.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.31805020570755005
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2707204818725586
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.68194979429245
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2709524631500244
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.31805020570755005
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2692544460296631
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.68194979429245
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27131032943725586
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.68194979429245
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2713747024536133
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.68194979429245
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2704353332519531
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.68194979429245
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27144742012023926
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.68194979429245
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26899123191833496
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.68194979429245
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2713770866394043
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.31805020570755005
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2719295024871826
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 71,
    "sentence": "But perhaps most impressively, Ukrainian forces managed to blow up Russia's flagship vessel - the Moskva - in April 2022.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2713027000427246
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27309465408325195
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2701833248138428
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27161550521850586
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2711155414581299
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2707061767578125
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27295494079589844
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2697160243988037
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27191710472106934
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27204012870788574
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 72,
    "sentence": "But Michelle evidently didn't hold the blunder against him; the couple have been married since 2015 after meeting in late 2012.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2729058265686035
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27316832542419434
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27092742919921875
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2714989185333252
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27207350730895996
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2716846466064453
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2733032703399658
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2689552307128906
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27121782302856445
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2715647220611572
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 73,
    "sentence": "Vigils, dubbed \u201cDark Valentine\u201d, were held across Kenya this week after a month in which more than a dozen women have been killed, allegedly by their partners.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.271348237991333
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2720968723297119
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27055907249450684
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27251696586608887
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2716350555419922
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2714977264404297
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2712414264678955
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27053380012512207
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27306246757507324
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2709319591522217
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 74,
    "sentence": "The radio presenter revealed the Fool Me Once star rumbled his porky pies the next day and fumed: 'Mark, you're a liar!'",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6169903874397278
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2724132537841797
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6169903874397278
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2735013961791992
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3830096125602722
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2715177536010742
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6169903874397278
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27320075035095215
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6169903874397278
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2713766098022461
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3830096125602722
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2729675769805908
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3830096125602722
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.272993803024292
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6169903874397278
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2730560302734375
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6169903874397278
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27320337295532227
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6169903874397278
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27164149284362793
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 75,
    "sentence": "The snap comes after Selena surprised fans on Monday with a very racy photo of Benny grabbing her cleavage  Gomez has been linked with Blanco, a musical artist, producer, and songwriter, since last year  In the first image from the post, the Emmy-nominated actress embraced Blanco, who has a passion for cooking, while he was preparing a platter of meatballs  Blanco was posed behind Gomez as they relaxed in the kitchen area of a home alongside friends including The Bear actor Matty Matheson  On Sunday, the couple was seen kissing one another while posed against a velvet red couch in a shot Gomez posted to Instagram  Gomez and Blanco have frequently shared their light-hearted and romantic moments via Instagram in the early days of their relationship.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8523851037025452
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.4972705841064453
      },
      {
        "repetition": 1,
        "generated_text": "Objective",
        "token_probs": [
          [
            "Object",
            0.14761494100093842
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.4981698989868164
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8523851037025452
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.4980039596557617
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8523851037025452
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.49256014823913574
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8523851037025452
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.49347925186157227
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8523851037025452
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.4946014881134033
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8523851037025452
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.49768710136413574
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8523851037025452
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.49523425102233887
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.8523851037025452
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.4984011650085449
      },
      {
        "repetition": 9,
        "generated_text": "Objective",
        "token_probs": [
          [
            "Object",
            0.14761494100093842
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.49893903732299805
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 76,
    "sentence": "November 17, 2023  Sir, your article \u2018BBC crisis over \u00a31.7bn pension bill for stars\u2019 (4/11/2023) is incorrect and significantly inflates the BBC\u2019s obligation to fund its defined benefit pension scheme shortfall and employer contribution rate.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32184600830078125
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3211643695831299
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3224952220916748
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32221293449401855
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3225069046020508
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3184778690338135
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32018184661865234
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.321519136428833
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32245945930480957
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3217353820800781
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 77,
    "sentence": "The crime currently falls under homicide provisions, which rights groups say do not account for the unequal power relations between men and women that drive and characterise the killings.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3099277913570404
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27639341354370117
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.690072238445282
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2736787796020508
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.690072238445282
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27045130729675293
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.690072238445282
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27178502082824707
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.690072238445282
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26972007751464844
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.690072238445282
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2720062732696533
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.690072238445282
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.273226261138916
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.690072238445282
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2715723514556885
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.690072238445282
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27187156677246094
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.690072238445282
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27117466926574707
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 78,
    "sentence": "Fr\u00fch Natur Radler  2.5%; The Real Ale Store, \u00a31.85 for 500ml; Hop Burns & Black, \u00a32.30  If grapefruit is not your bag, seek out this lemony-fresh delight from Fr\u00fch.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31851911544799805
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3204638957977295
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32022714614868164
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3216683864593506
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3223233222961426
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31955504417419434
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31896018981933594
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31757497787475586
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31871604919433594
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31984543800354004
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 79,
    "sentence": "Following on from this, Jim went on to star in the 2012 adaptation of David Mitchell's Cloud Atlas, which also divided audiences.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27345895767211914
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2723395824432373
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27072787284851074
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2712526321411133
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27040600776672363
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.272106409072876
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2713024616241455
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2699594497680664
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27107763290405273
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27278566360473633
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 80,
    "sentence": "Limit your spending and you have limited your income too.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3222143352031708
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2481389045715332
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6777856945991516
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25186872482299805
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6777856945991516
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25015735626220703
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6777856945991516
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2517094612121582
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6777856945991516
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2503993511199951
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6777856945991516
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.251664400100708
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6777856945991516
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25016021728515625
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.6777856945991516
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25100159645080566
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3222143352031708
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2507741451263428
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.3222143352031708
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2510364055633545
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 81,
    "sentence": "Unlike some of the other lemon offerings out there, this isn\u2019t soapy at all and has a very natural lemon flavouring.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7363909482955933
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2738165855407715
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7363909482955933
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27022528648376465
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7363909482955933
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.269212007522583
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7363909482955933
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27202558517456055
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7363909482955933
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27318310737609863
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7363909482955933
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2697269916534424
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7363909482955933
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27152180671691895
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7363909482955933
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2699096202850342
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7363909482955933
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27146482467651367
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7363909482955933
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27216148376464844
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 82,
    "sentence": "Blanco was past rumored to be in a romance with Elsie Hewitt, a 27-year-old model-actress from London (who has since been linked with Jason Sudeikis, 48).",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3163576126098633
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3183896541595459
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3180232048034668
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3176877498626709
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31735992431640625
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3171193599700928
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.320770263671875
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3176767826080322
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31639885902404785
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3159492015838623
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 83,
    "sentence": "The Schedule of Contributions agreed with the Scheme Trustee as part of the 2022 actuarial valuation states that the employer contribution rate for the defined benefit pension scheme is currently set to 30% of members\u2019 pensionable salaries.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31938672065734863
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3199269771575928
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31963443756103516
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3187718391418457
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31919026374816895
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.32088232040405273
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31856513023376465
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.3168821334838867
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.318587064743042
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.31932926177978516
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 84,
    "sentence": "So I wanted more.'",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.1310272216796875
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2488257884979248
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8689727783203125
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2496795654296875
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8689727783203125
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24901294708251953
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8689727783203125
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2494955062866211
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8689727783203125
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2506442070007324
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8689727783203125
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25012826919555664
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8689727783203125
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24926543235778809
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8689727783203125
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2470853328704834
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8689727783203125
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2503194808959961
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.8689727783203125
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2479252815246582
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 85,
    "sentence": "Nearly half of Republicans and right-leaning independents said the US was providing too much aid to Ukraine, according to a survey by the Pew Research Center conducted late last year.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2787618637084961
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27141380310058594
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27332472801208496
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2738664150238037
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27042365074157715
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27241015434265137
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2731471061706543
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27162861824035645
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27289915084838867
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27341222763061523
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 86,
    "sentence": "Meanwhile, some arch-conservatives suggested it was time for McConnell to step down.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.914794921875
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2700991630554199
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.08520513772964478
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2699546813964844
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.914794921875
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.268047571182251
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.914794921875
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2714543342590332
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.914794921875
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2719767093658447
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.914794921875
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26883578300476074
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.914794921875
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2708606719970703
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.914794921875
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2687094211578369
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.914794921875
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26917004585266113
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            0.914794921875
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2702651023864746
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 87,
    "sentence": "\u201cI maintain a healthy weight that preserves my facial structure and collagen.\u201d",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.38607165217399597
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2702338695526123
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.38607165217399597
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26896142959594727
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.38607165217399597
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26998066902160645
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.3898380398750305
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27001500129699707
      },
      {
        "repetition": 4,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.22409029304981232
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.2687067985534668
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.38607165217399597
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27071428298950195
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.3898380398750305
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26821208000183105
      },
      {
        "repetition": 7,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.22409029304981232
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.2696797847747803
      },
      {
        "repetition": 8,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.22409029304981232
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.26874375343322754
      },
      {
        "repetition": 9,
        "generated_text": "\"subject",
        "token_probs": [
          [
            "\"",
            0.22409029304981232
          ],
          [
            "subject",
            1.0
          ]
        ],
        "inference_time": 0.26756954193115234
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 88,
    "sentence": "Later in a campaign speech, Trump rattled American allies in Europe when he claimed that he would encourage Russia to attack Nato allies who did not pay enough to maintain the security alliance.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27137184143066406
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27490925788879395
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27163124084472656
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2744579315185547
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2727186679840088
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27158212661743164
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2746725082397461
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2712831497192383
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2734863758087158
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27460575103759766
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 89,
    "sentence": "Mark made the cheeky confession on-air while hosting his Heart FM radio programme on Monday, admitting he got 'clocked' by Michelle when she found the restaurant takeaway bag in the bin.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7888616323471069
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27179455757141113
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7888616323471069
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2733609676361084
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.21113839745521545
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2731144428253174
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7888616323471069
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2733924388885498
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7888616323471069
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2729330062866211
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.21113839745521545
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27124810218811035
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.21113839745521545
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27378058433532715
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7888616323471069
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27280330657958984
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7888616323471069
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27221083641052246
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7888616323471069
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2746429443359375
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 90,
    "sentence": "\u201cIt has my facial expressions \u2013 my eyes, lips, hair, arms, legs, chest and butt, all dimples and textures fully integrated.\u201d  Fabulous will pay for your exclusive stories.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.7505691647529602
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27080392837524414
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.7505691647529602
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2731666564941406
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.7505691647529602
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27464866638183594
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.2494308352470398
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27065587043762207
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.7505691647529602
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2730729579925537
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.7505691647529602
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2729020118713379
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.7505691647529602
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2721073627471924
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.7505691647529602
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2727177143096924
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.7505691647529602
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27228784561157227
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.7505691647529602
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27338743209838867
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 91,
    "sentence": "Since the 2022 valuation, funding has improved.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2724144458770752
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26783013343811035
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2716524600982666
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26878952980041504
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26903772354125977
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26772642135620117
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27045464515686035
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2700052261352539
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2686154842376709
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2706892490386963
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 92,
    "sentence": "He said: 'At a very young age, the local theatre in my town went to local schools to cast a load of kids to be in a professional production of Wind In The Willows.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2725679874420166
      },
      {
        "repetition": 1,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27219128608703613
      },
      {
        "repetition": 2,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27313923835754395
      },
      {
        "repetition": 3,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27231335639953613
      },
      {
        "repetition": 4,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2730255126953125
      },
      {
        "repetition": 5,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2729380130767822
      },
      {
        "repetition": 6,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2713477611541748
      },
      {
        "repetition": 7,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2734658718109131
      },
      {
        "repetition": 8,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2708761692047119
      },
      {
        "repetition": 9,
        "generated_text": "objective",
        "token_probs": [
          [
            "object",
            1.0
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2730216979980469
      }
    ],
    "predicted_label": "objective"
  },
  {
    "sample_idx": 93,
    "sentence": "RULE 9: LOVE  According to Gina, you should love yourself, love your life, love others.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7358081340789795
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2717466354370117
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2641918659210205
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.271190881729126
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7358081340789795
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27158665657043457
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7358081340789795
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26811909675598145
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7358081340789795
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2709367275238037
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7358081340789795
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27045226097106934
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2641918659210205
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27157044410705566
      },
      {
        "repetition": 7,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2641918659210205
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2732279300689697
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2641918659210205
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26949620246887207
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7358081340789795
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27051305770874023
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 94,
    "sentence": "Anne Hathaway is not it.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7604248523712158
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24839448928833008
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2395751178264618
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24984288215637207
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2395751178264618
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25125694274902344
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7604248523712158
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24982523918151855
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2395751178264618
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.251739501953125
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7604248523712158
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.25093555450439453
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7604248523712158
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24854731559753418
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7604248523712158
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2511606216430664
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2395751178264618
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.24820184707641602
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7604248523712158
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2507474422454834
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 95,
    "sentence": "As she watches her granddaughters play, Wairimu wonders if things could have played out differently.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2650882601737976
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27138614654541016
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7349117398262024
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27073097229003906
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7349117398262024
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26956844329833984
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7349117398262024
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2713310718536377
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7349117398262024
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2713794708251953
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2650882601737976
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26810312271118164
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7349117398262024
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2726173400878906
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7349117398262024
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27164483070373535
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7349117398262024
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2719724178314209
      },
      {
        "repetition": 9,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2650882601737976
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2723963260650635
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 96,
    "sentence": "RULE 5: ATTITUDE IS EVERYTHING  Gina stressed the importance of \"thinking yourself young\" as she suggested: \"You are what you think.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7476105093955994
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2733192443847656
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.25238946080207825
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2740590572357178
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7476105093955994
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27420854568481445
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7476105093955994
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27280688285827637
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7476105093955994
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2739288806915283
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.25238946080207825
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2722141742706299
      },
      {
        "repetition": 6,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.25238946080207825
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2732577323913574
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7476105093955994
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27156710624694824
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.25238946080207825
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27333855628967285
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7476105093955994
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27546072006225586
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 97,
    "sentence": "However, Variety wasn't so gushing - and said the drama 'should have stayed in quarantine'.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.4534149765968323
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26882266998291016
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.546584963798523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27011847496032715
      },
      {
        "repetition": 2,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.546584963798523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26809072494506836
      },
      {
        "repetition": 3,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.546584963798523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27076077461242676
      },
      {
        "repetition": 4,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.4534149765968323
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27051377296447754
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.546584963798523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27112269401550293
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.546584963798523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27248549461364746
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.546584963798523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2691824436187744
      },
      {
        "repetition": 8,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.546584963798523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27134156227111816
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.546584963798523
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.26892542839050293
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 98,
    "sentence": "The Ohio senator JD Vance, another Trump loyalist, claimed the effort to replenish Ukraine\u2019s war chest was a \u201cplot\u201d by the Republican establishment to \u201cstop the election of Donald Trump\u201d.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7000212073326111
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2726261615753174
      },
      {
        "repetition": 1,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7000212073326111
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2732579708099365
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2999788224697113
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2736027240753174
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2999788224697113
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2743237018585205
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7000212073326111
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27135205268859863
      },
      {
        "repetition": 5,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7000212073326111
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27347540855407715
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7000212073326111
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2732276916503906
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7000212073326111
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2725255489349365
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.2999788224697113
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2750885486602783
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.7000212073326111
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27234458923339844
      }
    ],
    "predicted_label": "subjective"
  },
  {
    "sample_idx": 99,
    "sentence": "It\u2019s made me realise how much we take older people for granted.\u201d  Both Brunero and Hamilton can see how mutually beneficial a multigenerational community such as Ayrton House could be.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.431234210729599
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2737691402435303
      },
      {
        "repetition": 1,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.431234210729599
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2722630500793457
      },
      {
        "repetition": 2,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.431234210729599
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2733902931213379
      },
      {
        "repetition": 3,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.431234210729599
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2748394012451172
      },
      {
        "repetition": 4,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5687657594680786
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2723257541656494
      },
      {
        "repetition": 5,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.431234210729599
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27337145805358887
      },
      {
        "repetition": 6,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5687657594680786
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.2706475257873535
      },
      {
        "repetition": 7,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5687657594680786
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27327585220336914
      },
      {
        "repetition": 8,
        "generated_text": "Subjective",
        "token_probs": [
          [
            "Subject",
            0.431234210729599
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27373170852661133
      },
      {
        "repetition": 9,
        "generated_text": "subjective",
        "token_probs": [
          [
            "subject",
            0.5687657594680786
          ],
          [
            "ive",
            1.0
          ]
        ],
        "inference_time": 0.27203941345214844
      }
    ],
    "predicted_label": "subjective"
  }
]