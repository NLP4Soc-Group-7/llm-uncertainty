[
  {
    "sample_idx": 0,
    "sentence": "Blanco established himself earlier in his career working for Dr. Luke's Kasz Money Productions.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8942572167123626
          ]
        ],
        "inference_time": 0.5060524940490723
      },
      {
        "repetition": 1,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.21898725945219405
          ]
        ],
        "inference_time": 0.8059241771697998
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8944680571764815
          ]
        ],
        "inference_time": 0.5156040191650391
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8720332120474606
          ]
        ],
        "inference_time": 0.4324910640716553
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8035195683664133
          ]
        ],
        "inference_time": 0.3992452621459961
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8720332120474606
          ]
        ],
        "inference_time": 0.39362239837646484
      },
      {
        "repetition": 6,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.14578922333583838
          ]
        ],
        "inference_time": 0.5123400688171387
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8973029376187346
          ]
        ],
        "inference_time": 0.6131160259246826
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8707070867993277
          ]
        ],
        "inference_time": 0.7161026000976562
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8720332120474606
          ]
        ],
        "inference_time": 0.7174723148345947
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 1,
    "sentence": "RULE 13: ARTIFICIAL INTELLIGENCE  Not only this, but Gina also created an AI model of herself to achieve immortality.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.2686966400475822
          ]
        ],
        "inference_time": 0.5089759826660156
      },
      {
        "repetition": 1,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.24275094699497085
          ]
        ],
        "inference_time": 0.40763235092163086
      },
      {
        "repetition": 2,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.2859677164104178
          ]
        ],
        "inference_time": 0.4273824691772461
      },
      {
        "repetition": 3,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.4184076227423586
          ]
        ],
        "inference_time": 0.4980781078338623
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.4184076227423586
          ]
        ],
        "inference_time": 0.8200027942657471
      },
      {
        "repetition": 5,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3240438754775178
          ]
        ],
        "inference_time": 0.39760589599609375
      },
      {
        "repetition": 6,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3935529565698573
          ]
        ],
        "inference_time": 0.41715168952941895
      },
      {
        "repetition": 7,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3950965055708793
          ]
        ],
        "inference_time": 0.408275842666626
      },
      {
        "repetition": 8,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.25945552728040483
          ]
        ],
        "inference_time": 0.3761906623840332
      },
      {
        "repetition": 9,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3950965055708793
          ]
        ],
        "inference_time": 0.6739435195922852
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 2,
    "sentence": "The valuation is required by law and the figure is assessed independently by a pension specialist and has been reviewed by the National Audit Office.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9998590441354105
          ]
        ],
        "inference_time": 0.39658689498901367
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9993069854906786
          ]
        ],
        "inference_time": 0.4986872673034668
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9996059856153359
          ]
        ],
        "inference_time": 0.4729747772216797
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9995878849181743
          ]
        ],
        "inference_time": 0.7125115394592285
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9993069854906786
          ]
        ],
        "inference_time": 0.4472668170928955
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999334121654941
          ]
        ],
        "inference_time": 0.41333913803100586
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9996712636200928
          ]
        ],
        "inference_time": 0.5134475231170654
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.999955463614667
          ]
        ],
        "inference_time": 0.7161381244659424
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9998590441354105
          ]
        ],
        "inference_time": 0.34575676918029785
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9997355998264572
          ]
        ],
        "inference_time": 0.4716684818267822
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 3,
    "sentence": "A sip can really hit the spot after a long bike ride or a walk.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.4795134833741224
          ]
        ],
        "inference_time": 0.5061953067779541
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.48144051901095014
          ]
        ],
        "inference_time": 0.41358160972595215
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.4185213602104454
          ]
        ],
        "inference_time": 0.5124461650848389
      },
      {
        "repetition": 3,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.48144051901095014
          ]
        ],
        "inference_time": 0.4093329906463623
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.42885494801773005
          ]
        ],
        "inference_time": 0.510664701461792
      },
      {
        "repetition": 5,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.33667776017617346
          ]
        ],
        "inference_time": 0.511737585067749
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.46327571640713483
          ]
        ],
        "inference_time": 0.4089367389678955
      },
      {
        "repetition": 7,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5787163084077926
          ]
        ],
        "inference_time": 0.5123417377471924
      },
      {
        "repetition": 8,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.41852540145231143
          ]
        ],
        "inference_time": 0.5128300189971924
      },
      {
        "repetition": 9,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3133247551438157
          ]
        ],
        "inference_time": 0.39630770683288574
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 4,
    "sentence": "Lobster!\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.999990508546513
          ]
        ],
        "inference_time": 0.5221579074859619
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999919389781311
          ]
        ],
        "inference_time": 0.5113949775695801
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999851444466235
          ]
        ],
        "inference_time": 0.41004514694213867
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999839524294449
          ]
        ],
        "inference_time": 0.4798014163970947
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999913429648598
          ]
        ],
        "inference_time": 0.9736676216125488
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999942038320746
          ]
        ],
        "inference_time": 0.4923675060272217
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999909853565219
          ]
        ],
        "inference_time": 0.3562347888946533
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.999990508546513
          ]
        ],
        "inference_time": 0.46169185638427734
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999900317367315
          ]
        ],
        "inference_time": 0.5108156204223633
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.999990508546513
          ]
        ],
        "inference_time": 0.4102325439453125
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 5,
    "sentence": "But this is precisely the reason why Labour must reject the austerian urges that, inevitably, spring from the credit card analogy.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.06964387493717146
          ]
        ],
        "inference_time": 0.7409489154815674
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8484361490354961
          ]
        ],
        "inference_time": 0.38243651390075684
      },
      {
        "repetition": 2,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8926653486556047
          ]
        ],
        "inference_time": 0.4097168445587158
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.898106364054846
          ]
        ],
        "inference_time": 0.41012096405029297
      },
      {
        "repetition": 4,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8565277410004378
          ]
        ],
        "inference_time": 0.5121364593505859
      },
      {
        "repetition": 5,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8557632569008372
          ]
        ],
        "inference_time": 0.7177577018737793
      },
      {
        "repetition": 6,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.889450962441234
          ]
        ],
        "inference_time": 0.5210061073303223
      },
      {
        "repetition": 7,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8860942930386997
          ]
        ],
        "inference_time": 0.5002830028533936
      },
      {
        "repetition": 8,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.05639224275091107
          ]
        ],
        "inference_time": 0.46880054473876953
      },
      {
        "repetition": 9,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.870955597799651
          ]
        ],
        "inference_time": 0.5548107624053955
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 6,
    "sentence": "Googled how to cook a good lobster and I read how hard it is to get it good because it can turn very tough, rubbery.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.24909953811905639
          ]
        ],
        "inference_time": 0.40802812576293945
      },
      {
        "repetition": 1,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.3499145725632835
          ]
        ],
        "inference_time": 1.0150146484375
      },
      {
        "repetition": 2,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.41437234454327215
          ]
        ],
        "inference_time": 0.4181826114654541
      },
      {
        "repetition": 3,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.38397244240431083
          ]
        ],
        "inference_time": 0.6012182235717773
      },
      {
        "repetition": 4,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.2725137431203811
          ]
        ],
        "inference_time": 0.4231076240539551
      },
      {
        "repetition": 5,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.33485084773533796
          ]
        ],
        "inference_time": 0.5115871429443359
      },
      {
        "repetition": 6,
        "generated_text": "35",
        "token_probs": [
          [
            "35",
            0.032106696323791456
          ]
        ],
        "inference_time": 0.5123052597045898
      },
      {
        "repetition": 7,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.3624376893485864
          ]
        ],
        "inference_time": 0.4083266258239746
      },
      {
        "repetition": 8,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.056672619476467095
          ]
        ],
        "inference_time": 0.8196096420288086
      },
      {
        "repetition": 9,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.06593604923129902
          ]
        ],
        "inference_time": 0.4717388153076172
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 7,
    "sentence": "Apartments cost from \u00a3392 per week to rent, which makes it more expensive than an average room in first-year halls (a single room without bathroom typically costs \u00a3250 per week) but more affordable than a lot of the postgraduate accommodation on offer.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.311965066663647
          ]
        ],
        "inference_time": 0.44907379150390625
      },
      {
        "repetition": 1,
        "generated_text": "15",
        "token_probs": [
          [
            "15",
            0.04766526236580101
          ]
        ],
        "inference_time": 0.37021946907043457
      },
      {
        "repetition": 2,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3660437201962568
          ]
        ],
        "inference_time": 0.5486054420471191
      },
      {
        "repetition": 3,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.537632735159025
          ]
        ],
        "inference_time": 0.40932250022888184
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.08979115694083624
          ]
        ],
        "inference_time": 0.9206550121307373
      },
      {
        "repetition": 5,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.43109991031207306
          ]
        ],
        "inference_time": 0.5121917724609375
      },
      {
        "repetition": 6,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.5245359144830035
          ]
        ],
        "inference_time": 1.1252384185791016
      },
      {
        "repetition": 7,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.05244991941480816
          ]
        ],
        "inference_time": 0.48236823081970215
      },
      {
        "repetition": 8,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.514645227701427
          ]
        ],
        "inference_time": 0.5414185523986816
      },
      {
        "repetition": 9,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.5585894685754944
          ]
        ],
        "inference_time": 0.7167744636535645
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 8,
    "sentence": "We apologise to TikTok for not approaching it for comment prior to publication.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.3545085872154503
          ]
        ],
        "inference_time": 4.094951629638672
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.2744469326971796
          ]
        ],
        "inference_time": 0.5118811130523682
      },
      {
        "repetition": 2,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.17637017156034487
          ]
        ],
        "inference_time": 0.40860581398010254
      },
      {
        "repetition": 3,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.5300511761869942
          ]
        ],
        "inference_time": 5.751133680343628
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.2837159497540215
          ]
        ],
        "inference_time": 0.4957551956176758
      },
      {
        "repetition": 5,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.2130075882485957
          ]
        ],
        "inference_time": 0.511836051940918
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.3545085872154503
          ]
        ],
        "inference_time": 0.5691647529602051
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.25848766597664374
          ]
        ],
        "inference_time": 0.45357561111450195
      },
      {
        "repetition": 8,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.44496554589923093
          ]
        ],
        "inference_time": 0.41105175018310547
      },
      {
        "repetition": 9,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.21502032727758072
          ]
        ],
        "inference_time": 0.40787458419799805
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 9,
    "sentence": "Crumbling parliament patched up with a few fig leaves  Parliament gained some new residents yesterday, and there are already questions as to their expenses.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.36886217459041676
          ]
        ],
        "inference_time": 0.5125882625579834
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.4526744636758365
          ]
        ],
        "inference_time": 0.4595179557800293
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.341651237985399
          ]
        ],
        "inference_time": 0.459975004196167
      },
      {
        "repetition": 3,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.47831956221390987
          ]
        ],
        "inference_time": 0.37954211235046387
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.470176521970261
          ]
        ],
        "inference_time": 0.43980860710144043
      },
      {
        "repetition": 5,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.3572969121641593
          ]
        ],
        "inference_time": 0.4012773036956787
      },
      {
        "repetition": 6,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.1503138402258747
          ]
        ],
        "inference_time": 0.6239614486694336
      },
      {
        "repetition": 7,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.4821657845317791
          ]
        ],
        "inference_time": 0.49788951873779297
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.4731813070633161
          ]
        ],
        "inference_time": 0.4198145866394043
      },
      {
        "repetition": 9,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.12389465967908805
          ]
        ],
        "inference_time": 0.4107801914215088
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 10,
    "sentence": "In 2019, he bagged a role in the ensemble movie Berlin, I Love You - which was labelled a 'empty, boring flop' by The Observer.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.49853756641004804
          ]
        ],
        "inference_time": 0.4063906669616699
      },
      {
        "repetition": 1,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.22327849990803073
          ]
        ],
        "inference_time": 0.6143877506256104
      },
      {
        "repetition": 2,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.10312298819160295
          ]
        ],
        "inference_time": 0.4079904556274414
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.06590903143639248
          ]
        ],
        "inference_time": 0.46628618240356445
      },
      {
        "repetition": 4,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.08295461231085334
          ]
        ],
        "inference_time": 0.42272448539733887
      },
      {
        "repetition": 5,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.051228640031689573
          ]
        ],
        "inference_time": 0.4409444332122803
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5176451109912167
          ]
        ],
        "inference_time": 0.4959249496459961
      },
      {
        "repetition": 7,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.21215079618497082
          ]
        ],
        "inference_time": 0.5284578800201416
      },
      {
        "repetition": 8,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.09399989061480177
          ]
        ],
        "inference_time": 0.39888691902160645
      },
      {
        "repetition": 9,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.06743559280083151
          ]
        ],
        "inference_time": 0.4210319519042969
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 11,
    "sentence": "By the way, she is honestly the best cook.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.4959166795858249
          ]
        ],
        "inference_time": 0.4011540412902832
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5797096264537979
          ]
        ],
        "inference_time": 0.41849493980407715
      },
      {
        "repetition": 2,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.45801093840120094
          ]
        ],
        "inference_time": 0.5118999481201172
      },
      {
        "repetition": 3,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.2680780951494165
          ]
        ],
        "inference_time": 0.388826847076416
      },
      {
        "repetition": 4,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.4845044095232505
          ]
        ],
        "inference_time": 0.5326831340789795
      },
      {
        "repetition": 5,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.23453171916154156
          ]
        ],
        "inference_time": 0.4659759998321533
      },
      {
        "repetition": 6,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.2285278154659293
          ]
        ],
        "inference_time": 0.4408860206604004
      },
      {
        "repetition": 7,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.23774931520636933
          ]
        ],
        "inference_time": 0.5262608528137207
      },
      {
        "repetition": 8,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.2307285161169971
          ]
        ],
        "inference_time": 0.7918987274169922
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.08488026745292003
          ]
        ],
        "inference_time": 0.4372246265411377
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 12,
    "sentence": "Families are doubling down on calls for perpetrators to be brought to justice, and say changes on the handling of femicide cases are necessary.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.289130771170581
          ]
        ],
        "inference_time": 0.5712082386016846
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5553466752214731
          ]
        ],
        "inference_time": 0.3421752452850342
      },
      {
        "repetition": 2,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.585349250306339
          ]
        ],
        "inference_time": 0.34537172317504883
      },
      {
        "repetition": 3,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.23863326693854042
          ]
        ],
        "inference_time": 0.35144543647766113
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3864629188113944
          ]
        ],
        "inference_time": 0.5367732048034668
      },
      {
        "repetition": 5,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.6424931177296288
          ]
        ],
        "inference_time": 0.3788597583770752
      },
      {
        "repetition": 6,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.23863326693854042
          ]
        ],
        "inference_time": 0.7463994026184082
      },
      {
        "repetition": 7,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.3864629188113944
          ]
        ],
        "inference_time": 0.41122865676879883
      },
      {
        "repetition": 8,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.3864629188113944
          ]
        ],
        "inference_time": 0.5105147361755371
      },
      {
        "repetition": 9,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.13657570566919852
          ]
        ],
        "inference_time": 0.35860109329223633
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 13,
    "sentence": "Anything we can actually do, we can afford.\u201d Britain\u2019s conundrum, today, is that the next government, whose job will be to fix the Tories\u2019 mess, is led by politicians who share neither Keynes\u2019s aims nor his innovative approach to public finance.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8455917471695188
          ]
        ],
        "inference_time": 0.463728666305542
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8048629532900432
          ]
        ],
        "inference_time": 0.4031689167022705
      },
      {
        "repetition": 2,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8048629532900432
          ]
        ],
        "inference_time": 0.5135056972503662
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8099747021919242
          ]
        ],
        "inference_time": 0.5122416019439697
      },
      {
        "repetition": 4,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8048629532900432
          ]
        ],
        "inference_time": 0.38142967224121094
      },
      {
        "repetition": 5,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8238519780796425
          ]
        ],
        "inference_time": 0.5393240451812744
      },
      {
        "repetition": 6,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8046397512280387
          ]
        ],
        "inference_time": 0.4074516296386719
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.2036083898803776
          ]
        ],
        "inference_time": 1.4349002838134766
      },
      {
        "repetition": 8,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8688592691839568
          ]
        ],
        "inference_time": 0.34967947006225586
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.16473057344631584
          ]
        ],
        "inference_time": 0.3632383346557617
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 14,
    "sentence": "\u201cI just believe in being the best version of myself that I can possibly be, it makes me feel good.\u201d  Read more real life stories  Not only does Gina swear by hydration - but she also has 13 other rules she sticks to like glue.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.7518168800336908
          ]
        ],
        "inference_time": 0.5293514728546143
      },
      {
        "repetition": 1,
        "generated_text": "90",
        "token_probs": [
          [
            "90",
            0.1890596759816081
          ]
        ],
        "inference_time": 0.4960470199584961
      },
      {
        "repetition": 2,
        "generated_text": "90",
        "token_probs": [
          [
            "90",
            0.20875693248231877
          ]
        ],
        "inference_time": 0.5135948657989502
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.7477455682868724
          ]
        ],
        "inference_time": 0.41220974922180176
      },
      {
        "repetition": 4,
        "generated_text": "90",
        "token_probs": [
          [
            "90",
            0.15652903416601416
          ]
        ],
        "inference_time": 0.6100668907165527
      },
      {
        "repetition": 5,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.7614771672867944
          ]
        ],
        "inference_time": 0.41123151779174805
      },
      {
        "repetition": 6,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8088607602005771
          ]
        ],
        "inference_time": 0.5083024501800537
      },
      {
        "repetition": 7,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.6137096607705138
          ]
        ],
        "inference_time": 0.4115018844604492
      },
      {
        "repetition": 8,
        "generated_text": "90",
        "token_probs": [
          [
            "90",
            0.21046238936651626
          ]
        ],
        "inference_time": 0.4097788333892822
      },
      {
        "repetition": 9,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.7286332673960345
          ]
        ],
        "inference_time": 0.4771735668182373
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 15,
    "sentence": "\u201cRussia\u2019s dominance in the Black Sea is now challenged.\u201d  The Boxing Day blast saw Vlad's valuable landing ship - docked in Crimea - turned into a raging fireball.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.14659426325717104
          ]
        ],
        "inference_time": 0.44122767448425293
      },
      {
        "repetition": 1,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.27036043838286994
          ]
        ],
        "inference_time": 0.39461469650268555
      },
      {
        "repetition": 2,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.27036043838286994
          ]
        ],
        "inference_time": 0.525515079498291
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.0907609096921442
          ]
        ],
        "inference_time": 0.4218592643737793
      },
      {
        "repetition": 4,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.18819990906546435
          ]
        ],
        "inference_time": 0.49971699714660645
      },
      {
        "repetition": 5,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.053213783691409736
          ]
        ],
        "inference_time": 0.4880702495574951
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.2056315935297657
          ]
        ],
        "inference_time": 0.6374971866607666
      },
      {
        "repetition": 7,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.21403961855041861
          ]
        ],
        "inference_time": 0.47565412521362305
      },
      {
        "repetition": 8,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.1226254839236838
          ]
        ],
        "inference_time": 0.4454796314239502
      },
      {
        "repetition": 9,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.25190443198450985
          ]
        ],
        "inference_time": 0.5176258087158203
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 16,
    "sentence": "Sea drones & anti-ship missiles  The February 1 attack came after Ukraine unveiled its new underwater robot drone, a stealth Autonomous Underwater Vehicle (AUV).",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.8589850849647342
          ]
        ],
        "inference_time": 0.40262675285339355
      },
      {
        "repetition": 1,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.8601994218731978
          ]
        ],
        "inference_time": 0.5110392570495605
      },
      {
        "repetition": 2,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.7275762555261492
          ]
        ],
        "inference_time": 0.5129549503326416
      },
      {
        "repetition": 3,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.6958503115945155
          ]
        ],
        "inference_time": 0.49401354789733887
      },
      {
        "repetition": 4,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.8373826029206621
          ]
        ],
        "inference_time": 0.7349305152893066
      },
      {
        "repetition": 5,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.8499730058803251
          ]
        ],
        "inference_time": 0.3692190647125244
      },
      {
        "repetition": 6,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.055984886871313984
          ]
        ],
        "inference_time": 0.7545762062072754
      },
      {
        "repetition": 7,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.8757510025052971
          ]
        ],
        "inference_time": 0.5123085975646973
      },
      {
        "repetition": 8,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.8757510025052971
          ]
        ],
        "inference_time": 0.4092442989349365
      },
      {
        "repetition": 9,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.7237355970972392
          ]
        ],
        "inference_time": 0.3515925407409668
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 17,
    "sentence": "\u201cThey\u2019re people who appreciate the onsite facilities such as the restaurant and gym and see living around older people as a lifestyle benefit rather than a hindrance,\u201d she explains.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3254331641680832
          ]
        ],
        "inference_time": 0.5699748992919922
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.23864475992538733
          ]
        ],
        "inference_time": 0.48351478576660156
      },
      {
        "repetition": 2,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.29031447765607515
          ]
        ],
        "inference_time": 0.43479490280151367
      },
      {
        "repetition": 3,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.09992265989642524
          ]
        ],
        "inference_time": 0.9219849109649658
      },
      {
        "repetition": 4,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5454220121018273
          ]
        ],
        "inference_time": 0.46140003204345703
      },
      {
        "repetition": 5,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5871018580957729
          ]
        ],
        "inference_time": 0.47582292556762695
      },
      {
        "repetition": 6,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5588505919750886
          ]
        ],
        "inference_time": 0.49680137634277344
      },
      {
        "repetition": 7,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.2837694943621001
          ]
        ],
        "inference_time": 0.4078354835510254
      },
      {
        "repetition": 8,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5454220121018273
          ]
        ],
        "inference_time": 0.5129837989807129
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5854367597986133
          ]
        ],
        "inference_time": 0.40810084342956543
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 18,
    "sentence": "But none of this means that the ditched \u00a328bn policy was optimal or, indeed, that an incoming chancellor can safely commit the Treasury to borrow and spend unlimited amounts.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.07203385594175475
          ]
        ],
        "inference_time": 0.6126008033752441
      },
      {
        "repetition": 1,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.27971642731403384
          ]
        ],
        "inference_time": 0.4101874828338623
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.2895472952901818
          ]
        ],
        "inference_time": 0.5108468532562256
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.28026939641965776
          ]
        ],
        "inference_time": 1.1264452934265137
      },
      {
        "repetition": 4,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.13491482833392046
          ]
        ],
        "inference_time": 0.9223780632019043
      },
      {
        "repetition": 5,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.373666708117005
          ]
        ],
        "inference_time": 0.5127382278442383
      },
      {
        "repetition": 6,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.24750906671294504
          ]
        ],
        "inference_time": 0.510073184967041
      },
      {
        "repetition": 7,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.1190619181174172
          ]
        ],
        "inference_time": 0.5118522644042969
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.4080734629807696
          ]
        ],
        "inference_time": 0.5219347476959229
      },
      {
        "repetition": 9,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.42080574872147336
          ]
        ],
        "inference_time": 0.5022249221801758
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 19,
    "sentence": "The record, which topped out at 41 on the Billboard 200, included contributions from Bieber, Halsey, Calvin Harris, Omar Apollo and Gracie Abrams.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9981114704281625
          ]
        ],
        "inference_time": 0.40960049629211426
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9997494202371443
          ]
        ],
        "inference_time": 0.40677523612976074
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9995067806635336
          ]
        ],
        "inference_time": 0.40264177322387695
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9998510586344636
          ]
        ],
        "inference_time": 0.4161849021911621
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9997073637642253
          ]
        ],
        "inference_time": 0.5870640277862549
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9998125696760369
          ]
        ],
        "inference_time": 0.640894889831543
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9965430024354368
          ]
        ],
        "inference_time": 0.38658666610717773
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9997677621789485
          ]
        ],
        "inference_time": 0.43238353729248047
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.996271737222858
          ]
        ],
        "inference_time": 0.444230318069458
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9998125696760369
          ]
        ],
        "inference_time": 0.8189091682434082
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 20,
    "sentence": "The journalist Mike Smith was struck yesterday when he noticed",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.24486932393416502
          ]
        ],
        "inference_time": 0.36858487129211426
      },
      {
        "repetition": 1,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.5179490817725314
          ]
        ],
        "inference_time": 0.4165530204772949
      },
      {
        "repetition": 2,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.6029979070170072
          ]
        ],
        "inference_time": 0.38033366203308105
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.2690644167635675
          ]
        ],
        "inference_time": 0.4325375556945801
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.3649490106429937
          ]
        ],
        "inference_time": 0.5108246803283691
      },
      {
        "repetition": 5,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.24945265360040533
          ]
        ],
        "inference_time": 1.9464058876037598
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.0821314331891901
          ]
        ],
        "inference_time": 1.1372647285461426
      },
      {
        "repetition": 7,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.6622549764295793
          ]
        ],
        "inference_time": 0.444338321685791
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.2295152270279181
          ]
        ],
        "inference_time": 0.46474146842956543
      },
      {
        "repetition": 9,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.5179490817725314
          ]
        ],
        "inference_time": 0.48378586769104004
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 21,
    "sentence": "Two years later, he stepped into a leading man role once again when he appeared in The Other Me - about a architect who has an eye disease which enables him to see people's real motives.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3469498913020837
          ]
        ],
        "inference_time": 0.8466517925262451
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.18275421901929637
          ]
        ],
        "inference_time": 0.8190255165100098
      },
      {
        "repetition": 2,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.12024139325697952
          ]
        ],
        "inference_time": 0.42436647415161133
      },
      {
        "repetition": 3,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.7583220234437597
          ]
        ],
        "inference_time": 0.4980008602142334
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.29070550174475457
          ]
        ],
        "inference_time": 0.4181382656097412
      },
      {
        "repetition": 5,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.7583220234437597
          ]
        ],
        "inference_time": 1.1379082202911377
      },
      {
        "repetition": 6,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.1680384358360041
          ]
        ],
        "inference_time": 0.6932854652404785
      },
      {
        "repetition": 7,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.7100267416915111
          ]
        ],
        "inference_time": 0.40921735763549805
      },
      {
        "repetition": 8,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.6936371171552773
          ]
        ],
        "inference_time": 0.4100480079650879
      },
      {
        "repetition": 9,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.7830528403397763
          ]
        ],
        "inference_time": 0.47669291496276855
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 22,
    "sentence": "At the time, Time magazine dubbed the film 'disjoined' - saying that 'characters that Nicholls brought so cunningly to life in the book feel rushed through a timeline, tied to an agenda'.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.264770845234905
          ]
        ],
        "inference_time": 0.5469756126403809
      },
      {
        "repetition": 1,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.3830913389387177
          ]
        ],
        "inference_time": 0.4552786350250244
      },
      {
        "repetition": 2,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3530227379224529
          ]
        ],
        "inference_time": 0.46405768394470215
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.061346153296457644
          ]
        ],
        "inference_time": 0.39275431632995605
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.41096467647471874
          ]
        ],
        "inference_time": 0.8819785118103027
      },
      {
        "repetition": 5,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.47847519547694406
          ]
        ],
        "inference_time": 0.5837852954864502
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.555149526129456
          ]
        ],
        "inference_time": 0.497225284576416
      },
      {
        "repetition": 7,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.06694455349007447
          ]
        ],
        "inference_time": 0.8171257972717285
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.4301566320805324
          ]
        ],
        "inference_time": 0.512078046798706
      },
      {
        "repetition": 9,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3945472638801494
          ]
        ],
        "inference_time": 0.5122621059417725
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 23,
    "sentence": "\u201cWe were in shock,\u201d says Wangari\u2019s father.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5315757611378429
          ]
        ],
        "inference_time": 0.3967866897583008
      },
      {
        "repetition": 1,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.1309747339549975
          ]
        ],
        "inference_time": 0.37840819358825684
      },
      {
        "repetition": 2,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5527862565765608
          ]
        ],
        "inference_time": 0.454819917678833
      },
      {
        "repetition": 3,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.14151007349366226
          ]
        ],
        "inference_time": 0.39552736282348633
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.561464332371977
          ]
        ],
        "inference_time": 0.524550199508667
      },
      {
        "repetition": 5,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.17946341142251301
          ]
        ],
        "inference_time": 0.4066474437713623
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5023110398283779
          ]
        ],
        "inference_time": 0.5136318206787109
      },
      {
        "repetition": 7,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5547419471211558
          ]
        ],
        "inference_time": 1.1254973411560059
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.48353326885849696
          ]
        ],
        "inference_time": 0.8233742713928223
      },
      {
        "repetition": 9,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5613934895692767
          ]
        ],
        "inference_time": 0.5119519233703613
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 24,
    "sentence": "House Democrats and the remaining pro-Ukraine House Republicans are casting about behind the scenes for a solution.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.39659180666293353
          ]
        ],
        "inference_time": 0.7154624462127686
      },
      {
        "repetition": 1,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.05998738168310145
          ]
        ],
        "inference_time": 0.4892723560333252
      },
      {
        "repetition": 2,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4357781923716271
          ]
        ],
        "inference_time": 0.43101072311401367
      },
      {
        "repetition": 3,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3907239845915751
          ]
        ],
        "inference_time": 0.4094886779785156
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.4461761426573977
          ]
        ],
        "inference_time": 0.4108603000640869
      },
      {
        "repetition": 5,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.07419969033499575
          ]
        ],
        "inference_time": 0.42510271072387695
      },
      {
        "repetition": 6,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.5519585154568105
          ]
        ],
        "inference_time": 0.6080305576324463
      },
      {
        "repetition": 7,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.49942195976535236
          ]
        ],
        "inference_time": 0.5006346702575684
      },
      {
        "repetition": 8,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.06045409212562383
          ]
        ],
        "inference_time": 0.7179934978485107
      },
      {
        "repetition": 9,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.07419969033499575
          ]
        ],
        "inference_time": 0.44579601287841797
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 25,
    "sentence": "Austerity, and the credit card analogy that provides its thin veneer of logic, is not just bad for workers and people in desperate need of state support during tough times; it also depresses investment.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9554042655297463
          ]
        ],
        "inference_time": 0.6764569282531738
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9632723869787088
          ]
        ],
        "inference_time": 0.4794638156890869
      },
      {
        "repetition": 2,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9665513784165093
          ]
        ],
        "inference_time": 0.5446798801422119
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.969623686662885
          ]
        ],
        "inference_time": 0.4822382926940918
      },
      {
        "repetition": 4,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.964487576956486
          ]
        ],
        "inference_time": 0.5417490005493164
      },
      {
        "repetition": 5,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9613033815491948
          ]
        ],
        "inference_time": 0.3948650360107422
      },
      {
        "repetition": 6,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9573324535549566
          ]
        ],
        "inference_time": 0.4226346015930176
      },
      {
        "repetition": 7,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9525295532686886
          ]
        ],
        "inference_time": 0.3725295066833496
      },
      {
        "repetition": 8,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9613019455154688
          ]
        ],
        "inference_time": 0.6460955142974854
      },
      {
        "repetition": 9,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9639325433524637
          ]
        ],
        "inference_time": 0.46964454650878906
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 26,
    "sentence": "In a pre-dawn vote on Tuesday, Graham joined the majority of Senate Republicans in opposing a foreign aid package that would rush wartime assistance to Ukraine as it approaches the second anniversary of Russia\u2019s full invasion.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.666778065100968
          ]
        ],
        "inference_time": 0.4554324150085449
      },
      {
        "repetition": 1,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.745446002809632
          ]
        ],
        "inference_time": 0.41193652153015137
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.38059543472662916
          ]
        ],
        "inference_time": 0.5094516277313232
      },
      {
        "repetition": 3,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.6224423005337834
          ]
        ],
        "inference_time": 0.41019105911254883
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.19578801500465604
          ]
        ],
        "inference_time": 0.6129140853881836
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.38059543472662916
          ]
        ],
        "inference_time": 0.5744662284851074
      },
      {
        "repetition": 6,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.619108970932913
          ]
        ],
        "inference_time": 0.5523035526275635
      },
      {
        "repetition": 7,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.56666841908356
          ]
        ],
        "inference_time": 0.4347696304321289
      },
      {
        "repetition": 8,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.5545199257012017
          ]
        ],
        "inference_time": 0.4857010841369629
      },
      {
        "repetition": 9,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.6987684994435174
          ]
        ],
        "inference_time": 0.5139832496643066
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 27,
    "sentence": "The Observer's Philip French dubbed it 'thin, superficial and sentimental' and said the casting of Anne Hathway was 'disastrous'.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8647159209018106
          ]
        ],
        "inference_time": 0.6098747253417969
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9303804024682281
          ]
        ],
        "inference_time": 0.44772768020629883
      },
      {
        "repetition": 2,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9132342826339181
          ]
        ],
        "inference_time": 0.4751932621002197
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9043409895296698
          ]
        ],
        "inference_time": 0.46519970893859863
      },
      {
        "repetition": 4,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9262345906608421
          ]
        ],
        "inference_time": 0.5558722019195557
      },
      {
        "repetition": 5,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8992198492484142
          ]
        ],
        "inference_time": 0.40975308418273926
      },
      {
        "repetition": 6,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9163968126065147
          ]
        ],
        "inference_time": 0.4096212387084961
      },
      {
        "repetition": 7,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8952374555123936
          ]
        ],
        "inference_time": 0.40962815284729004
      },
      {
        "repetition": 8,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8956530620214944
          ]
        ],
        "inference_time": 0.5992145538330078
      },
      {
        "repetition": 9,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8647159209018106
          ]
        ],
        "inference_time": 1.1361370086669922
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 28,
    "sentence": "A third commented: \"$20 for $6k - not bad!\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.33107219973361574
          ]
        ],
        "inference_time": 0.39768409729003906
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.2541642165010229
          ]
        ],
        "inference_time": 0.5208570957183838
      },
      {
        "repetition": 2,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.08514899452639355
          ]
        ],
        "inference_time": 0.6667437553405762
      },
      {
        "repetition": 3,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.11649053439632984
          ]
        ],
        "inference_time": 0.6638376712799072
      },
      {
        "repetition": 4,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.05650901193793406
          ]
        ],
        "inference_time": 0.3262026309967041
      },
      {
        "repetition": 5,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.09683808814412431
          ]
        ],
        "inference_time": 0.4923369884490967
      },
      {
        "repetition": 6,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.12668936281288784
          ]
        ],
        "inference_time": 0.40519070625305176
      },
      {
        "repetition": 7,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.11860068041903306
          ]
        ],
        "inference_time": 0.400343656539917
      },
      {
        "repetition": 8,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.0875144608067969
          ]
        ],
        "inference_time": 0.5249745845794678
      },
      {
        "repetition": 9,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.1442869358256746
          ]
        ],
        "inference_time": 0.44008517265319824
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 29,
    "sentence": "The plan incorporates cash payments supplemented by contingent contributions.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.7098956859863801
          ]
        ],
        "inference_time": 0.5820310115814209
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9921793736651265
          ]
        ],
        "inference_time": 0.41045331954956055
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9871486234791608
          ]
        ],
        "inference_time": 0.40816307067871094
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.973425280861544
          ]
        ],
        "inference_time": 4.316828727722168
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8660978870242255
          ]
        ],
        "inference_time": 0.6003189086914062
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9335834035588961
          ]
        ],
        "inference_time": 0.3825340270996094
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9922578743496401
          ]
        ],
        "inference_time": 0.4339478015899658
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.7091933826021632
          ]
        ],
        "inference_time": 0.49564647674560547
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9454469045071358
          ]
        ],
        "inference_time": 0.5284202098846436
      },
      {
        "repetition": 9,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.21785342284700776
          ]
        ],
        "inference_time": 0.3838369846343994
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 30,
    "sentence": "It is true that the Tories will leave scorched earth behind for the next government, with a budget dripping in red ink and a pitiful level of investment in the technologies and services the UK needs to escape a long-term slump.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9127916726886725
          ]
        ],
        "inference_time": 0.528886079788208
      },
      {
        "repetition": 1,
        "generated_text": "90",
        "token_probs": [
          [
            "90",
            0.12949599935043518
          ]
        ],
        "inference_time": 0.5114176273345947
      },
      {
        "repetition": 2,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8849461059770806
          ]
        ],
        "inference_time": 0.4107203483581543
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9440269282013795
          ]
        ],
        "inference_time": 0.5107173919677734
      },
      {
        "repetition": 4,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8816078955062423
          ]
        ],
        "inference_time": 0.4096074104309082
      },
      {
        "repetition": 5,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8444199130735468
          ]
        ],
        "inference_time": 0.5111217498779297
      },
      {
        "repetition": 6,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8947588547938726
          ]
        ],
        "inference_time": 0.5152738094329834
      },
      {
        "repetition": 7,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9042047197313676
          ]
        ],
        "inference_time": 0.6106486320495605
      },
      {
        "repetition": 8,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8410372049296714
          ]
        ],
        "inference_time": 0.5123658180236816
      },
      {
        "repetition": 9,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.9363208891904569
          ]
        ],
        "inference_time": 0.46992063522338867
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 31,
    "sentence": "A WOMAN who has been dubbed \u2018the world\u2019s hottest gran\u2019 has revealed how she stays looking eternally young at the age of 53.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5745548905976682
          ]
        ],
        "inference_time": 0.450528621673584
      },
      {
        "repetition": 1,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4682875382132495
          ]
        ],
        "inference_time": 0.7165975570678711
      },
      {
        "repetition": 2,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.3261537957145342
          ]
        ],
        "inference_time": 0.4096863269805908
      },
      {
        "repetition": 3,
        "generated_text": "45",
        "token_probs": [
          [
            "45",
            0.02331466507050404
          ]
        ],
        "inference_time": 0.5102579593658447
      },
      {
        "repetition": 4,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.16024655297847418
          ]
        ],
        "inference_time": 0.409512996673584
      },
      {
        "repetition": 5,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.11840163893952518
          ]
        ],
        "inference_time": 0.4092288017272949
      },
      {
        "repetition": 6,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.05280765240439484
          ]
        ],
        "inference_time": 0.41152024269104004
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.038327171225406256
          ]
        ],
        "inference_time": 0.38480567932128906
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.46487310937205667
          ]
        ],
        "inference_time": 0.4326026439666748
      },
      {
        "repetition": 9,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.11840163893952518
          ]
        ],
        "inference_time": 0.7167096138000488
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 32,
    "sentence": "Couldn't say everything I wanted to in the video.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3118498016477017
          ]
        ],
        "inference_time": 0.509091854095459
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.2598759521359072
          ]
        ],
        "inference_time": 0.45122623443603516
      },
      {
        "repetition": 2,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.15329863411442504
          ]
        ],
        "inference_time": 0.36970949172973633
      },
      {
        "repetition": 3,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.37172391022704404
          ]
        ],
        "inference_time": 0.4232974052429199
      },
      {
        "repetition": 4,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.12068107024499804
          ]
        ],
        "inference_time": 0.4946296215057373
      },
      {
        "repetition": 5,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.40588969097714794
          ]
        ],
        "inference_time": 0.40998077392578125
      },
      {
        "repetition": 6,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.18507231853150943
          ]
        ],
        "inference_time": 0.4091770648956299
      },
      {
        "repetition": 7,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.17051083723109947
          ]
        ],
        "inference_time": 0.4091215133666992
      },
      {
        "repetition": 8,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.06237882169723063
          ]
        ],
        "inference_time": 0.44048190116882324
      },
      {
        "repetition": 9,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.178391718752633
          ]
        ],
        "inference_time": 0.4123091697692871
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 33,
    "sentence": "From the Senate floor, Senator Mitch McConnell, the top Republican, delivered increasingly urgent pleas for his conference to rise to the occasion and support America\u2019s allies, even after his plan to tie border security to foreign aid collapsed, torpedoed by Trump\u2019s opposition.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.4149424817877324
          ]
        ],
        "inference_time": 0.5805883407592773
      },
      {
        "repetition": 1,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.24982440585501794
          ]
        ],
        "inference_time": 0.5103709697723389
      },
      {
        "repetition": 2,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.07638182398109761
          ]
        ],
        "inference_time": 0.4067378044128418
      },
      {
        "repetition": 3,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3878989090001441
          ]
        ],
        "inference_time": 0.514585018157959
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.41077634998530466
          ]
        ],
        "inference_time": 0.40915799140930176
      },
      {
        "repetition": 5,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4391483491424937
          ]
        ],
        "inference_time": 0.48256587982177734
      },
      {
        "repetition": 6,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5646013873826972
          ]
        ],
        "inference_time": 0.43874335289001465
      },
      {
        "repetition": 7,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5313185778551733
          ]
        ],
        "inference_time": 0.6153452396392822
      },
      {
        "repetition": 8,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5051171375813835
          ]
        ],
        "inference_time": 0.4858884811401367
      },
      {
        "repetition": 9,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.1553041949385646
          ]
        ],
        "inference_time": 0.546943187713623
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 34,
    "sentence": "The Hollywood Reporter was particularly gushing of Jim Sturgess' performance - saying the actor had 'staked his claim as the new Hugh Grant only without the fussy mannerisms'.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5483725457443271
          ]
        ],
        "inference_time": 0.4005396366119385
      },
      {
        "repetition": 1,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.4584750478382791
          ]
        ],
        "inference_time": 0.4524807929992676
      },
      {
        "repetition": 2,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.12838860915303638
          ]
        ],
        "inference_time": 0.46561646461486816
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.276291714019166
          ]
        ],
        "inference_time": 0.40895867347717285
      },
      {
        "repetition": 4,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.47683777062604693
          ]
        ],
        "inference_time": 0.35914182662963867
      },
      {
        "repetition": 5,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.2342127915299321
          ]
        ],
        "inference_time": 0.3804337978363037
      },
      {
        "repetition": 6,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5151464904497928
          ]
        ],
        "inference_time": 0.3766944408416748
      },
      {
        "repetition": 7,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.11414032006342013
          ]
        ],
        "inference_time": 1.6473355293273926
      },
      {
        "repetition": 8,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5166464659211468
          ]
        ],
        "inference_time": 0.405869722366333
      },
      {
        "repetition": 9,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.15480656799059117
          ]
        ],
        "inference_time": 0.5157122611999512
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 35,
    "sentence": "The Neptune \"super missile\", revealed in August last year, was reportedly snatched from behind enemy lines during a raid on Putin's prized \u00a3200million air defence system.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.44494910255481734
          ]
        ],
        "inference_time": 0.5929875373840332
      },
      {
        "repetition": 1,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.3851662024214616
          ]
        ],
        "inference_time": 0.693840503692627
      },
      {
        "repetition": 2,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.3605290981022769
          ]
        ],
        "inference_time": 0.4038565158843994
      },
      {
        "repetition": 3,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.33401876864889884
          ]
        ],
        "inference_time": 0.45750951766967773
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.223039315820691
          ]
        ],
        "inference_time": 0.3801276683807373
      },
      {
        "repetition": 5,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.048997887310383986
          ]
        ],
        "inference_time": 1.0737817287445068
      },
      {
        "repetition": 6,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4417442293802677
          ]
        ],
        "inference_time": 0.4829082489013672
      },
      {
        "repetition": 7,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.30601376786690304
          ]
        ],
        "inference_time": 0.4005136489868164
      },
      {
        "repetition": 8,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5282434835569519
          ]
        ],
        "inference_time": 0.5292048454284668
      },
      {
        "repetition": 9,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4147985636062008
          ]
        ],
        "inference_time": 0.466306209564209
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 36,
    "sentence": "- Actor was on track to become a Hollywood star when he appeared in One Day  - Read More: How Taylor Swift's savvy marketing executive mother Andrea turned her daughter into a superstar  David Nicholls' romantic novel One Day became an overnight fan favourite when it was first released in 2009 and is now being rediscovered by a new audience thanks to Netflix's adaptation.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.43357675256107375
          ]
        ],
        "inference_time": 0.5557987689971924
      },
      {
        "repetition": 1,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5778161591868275
          ]
        ],
        "inference_time": 0.5107038021087646
      },
      {
        "repetition": 2,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.4626399131050128
          ]
        ],
        "inference_time": 0.4114341735839844
      },
      {
        "repetition": 3,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.43357675256107375
          ]
        ],
        "inference_time": 0.714364767074585
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.5238211263839415
          ]
        ],
        "inference_time": 0.7281625270843506
      },
      {
        "repetition": 5,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.04558659022314929
          ]
        ],
        "inference_time": 0.5009715557098389
      },
      {
        "repetition": 6,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.3355814521984097
          ]
        ],
        "inference_time": 0.6136510372161865
      },
      {
        "repetition": 7,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.05178335852981407
          ]
        ],
        "inference_time": 0.46083569526672363
      },
      {
        "repetition": 8,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.40716226924727
          ]
        ],
        "inference_time": 0.4601900577545166
      },
      {
        "repetition": 9,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5329320910431262
          ]
        ],
        "inference_time": 0.41048097610473633
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 37,
    "sentence": "\"$6k is a lot of money,\" wrote one.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.08285572236319838
          ]
        ],
        "inference_time": 0.5086925029754639
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3423638240860935
          ]
        ],
        "inference_time": 0.40932226181030273
      },
      {
        "repetition": 2,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3747253806402056
          ]
        ],
        "inference_time": 0.513047456741333
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.1007159916088467
          ]
        ],
        "inference_time": 0.4085516929626465
      },
      {
        "repetition": 4,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.2434567892100243
          ]
        ],
        "inference_time": 0.37453627586364746
      },
      {
        "repetition": 5,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.346583844833872
          ]
        ],
        "inference_time": 0.5465030670166016
      },
      {
        "repetition": 6,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.12260285719759417
          ]
        ],
        "inference_time": 0.45611119270324707
      },
      {
        "repetition": 7,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5153980575222071
          ]
        ],
        "inference_time": 0.46367740631103516
      },
      {
        "repetition": 8,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.23527345062626953
          ]
        ],
        "inference_time": 0.5825941562652588
      },
      {
        "repetition": 9,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.0633580635575029
          ]
        ],
        "inference_time": 0.5443627834320068
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 38,
    "sentence": "He told The Independent in 2021: 'If someone does a bad one, I can\u2019t watch the film.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.33124728163227146
          ]
        ],
        "inference_time": 0.356762170791626
      },
      {
        "repetition": 1,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.29192923592661774
          ]
        ],
        "inference_time": 0.45942020416259766
      },
      {
        "repetition": 2,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.08443857369442043
          ]
        ],
        "inference_time": 1.0238182544708252
      },
      {
        "repetition": 3,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.3424889794558691
          ]
        ],
        "inference_time": 0.4111940860748291
      },
      {
        "repetition": 4,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.3044088722385734
          ]
        ],
        "inference_time": 0.5108208656311035
      },
      {
        "repetition": 5,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.03348836107603542
          ]
        ],
        "inference_time": 0.4935441017150879
      },
      {
        "repetition": 6,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.43792113762151286
          ]
        ],
        "inference_time": 0.5302870273590088
      },
      {
        "repetition": 7,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.10668753989715898
          ]
        ],
        "inference_time": 0.5115821361541748
      },
      {
        "repetition": 8,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3478018691006283
          ]
        ],
        "inference_time": 0.40837693214416504
      },
      {
        "repetition": 9,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.428170031731137
          ]
        ],
        "inference_time": 0.9672069549560547
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 39,
    "sentence": "Gina Stewart has previously hit the headlines for her youthful appearance and most recently, immortalising herself as an AI model.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4523239209094975
          ]
        ],
        "inference_time": 0.5687470436096191
      },
      {
        "repetition": 1,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.31741757132307574
          ]
        ],
        "inference_time": 0.4072756767272949
      },
      {
        "repetition": 2,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.40561923180360415
          ]
        ],
        "inference_time": 0.4095759391784668
      },
      {
        "repetition": 3,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5095215418408374
          ]
        ],
        "inference_time": 0.35616588592529297
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.40561923180360415
          ]
        ],
        "inference_time": 0.46297192573547363
      },
      {
        "repetition": 5,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.34583159539846203
          ]
        ],
        "inference_time": 0.459550142288208
      },
      {
        "repetition": 6,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.06664025179558421
          ]
        ],
        "inference_time": 0.6660549640655518
      },
      {
        "repetition": 7,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3968157757773938
          ]
        ],
        "inference_time": 0.6140272617340088
      },
      {
        "repetition": 8,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.4014797460016444
          ]
        ],
        "inference_time": 0.4115285873413086
      },
      {
        "repetition": 9,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3143532994285809
          ]
        ],
        "inference_time": 0.49007701873779297
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 40,
    "sentence": "Anne is a very warm actress.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.816302184300348
          ]
        ],
        "inference_time": 0.5227594375610352
      },
      {
        "repetition": 1,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.25360318894052264
          ]
        ],
        "inference_time": 0.510822057723999
      },
      {
        "repetition": 2,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.7362764628319619
          ]
        ],
        "inference_time": 0.41646361351013184
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.1433782939813558
          ]
        ],
        "inference_time": 0.40225791931152344
      },
      {
        "repetition": 4,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.1433782939813558
          ]
        ],
        "inference_time": 0.4091463088989258
      },
      {
        "repetition": 5,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.6466881710005252
          ]
        ],
        "inference_time": 0.7166886329650879
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.7422723321339509
          ]
        ],
        "inference_time": 0.34195423126220703
      },
      {
        "repetition": 7,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.8204702474540702
          ]
        ],
        "inference_time": 0.37409305572509766
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.7829713524982229
          ]
        ],
        "inference_time": 0.4884343147277832
      },
      {
        "repetition": 9,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.8250851265209728
          ]
        ],
        "inference_time": 0.43438005447387695
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 41,
    "sentence": "And I was good at it.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.21921282104482892
          ]
        ],
        "inference_time": 0.5086359977722168
      },
      {
        "repetition": 1,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.12385189489529308
          ]
        ],
        "inference_time": 0.5116777420043945
      },
      {
        "repetition": 2,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.45448941450601604
          ]
        ],
        "inference_time": 0.5116486549377441
      },
      {
        "repetition": 3,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.0409619377928177
          ]
        ],
        "inference_time": 0.4096074104309082
      },
      {
        "repetition": 4,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.41778722580239913
          ]
        ],
        "inference_time": 0.6158840656280518
      },
      {
        "repetition": 5,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.48301471455461287
          ]
        ],
        "inference_time": 0.40863513946533203
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.1919901916924138
          ]
        ],
        "inference_time": 0.5104246139526367
      },
      {
        "repetition": 7,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.03988406561816171
          ]
        ],
        "inference_time": 0.3680548667907715
      },
      {
        "repetition": 8,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.4322855633498622
          ]
        ],
        "inference_time": 0.4521336555480957
      },
      {
        "repetition": 9,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.1029617781361557
          ]
        ],
        "inference_time": 0.4952518939971924
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 42,
    "sentence": "\u201cOn matters like femicide which society takes lightly, you don\u2019t just get justice,\u201d says Kamande.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.14006024524306127
          ]
        ],
        "inference_time": 0.5256624221801758
      },
      {
        "repetition": 1,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.4585135808691978
          ]
        ],
        "inference_time": 0.47382545471191406
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.47141257605592213
          ]
        ],
        "inference_time": 0.5498766899108887
      },
      {
        "repetition": 3,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3485893614231867
          ]
        ],
        "inference_time": 0.506824254989624
      },
      {
        "repetition": 4,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.14003341656581528
          ]
        ],
        "inference_time": 0.41352200508117676
      },
      {
        "repetition": 5,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.48767075007744565
          ]
        ],
        "inference_time": 0.38236331939697266
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3869203416161283
          ]
        ],
        "inference_time": 0.43787646293640137
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.4339294745742077
          ]
        ],
        "inference_time": 0.5104203224182129
      },
      {
        "repetition": 8,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.4585135808691978
          ]
        ],
        "inference_time": 0.4089486598968506
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.4585135808691978
          ]
        ],
        "inference_time": 0.40998172760009766
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 43,
    "sentence": "hosted by Laura Rangeley and Michael Deakin).",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.999998137537802
          ]
        ],
        "inference_time": 0.8178050518035889
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999980183344259
          ]
        ],
        "inference_time": 0.4104115962982178
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999978991308366
          ]
        ],
        "inference_time": 0.5126795768737793
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999913429648598
          ]
        ],
        "inference_time": 0.40720582008361816
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999978991308366
          ]
        ],
        "inference_time": 0.40935659408569336
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999971839107363
          ]
        ],
        "inference_time": 0.4106919765472412
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999976607241555
          ]
        ],
        "inference_time": 0.5102450847625732
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999971839107363
          ]
        ],
        "inference_time": 0.4109609127044678
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999971839107363
          ]
        ],
        "inference_time": 0.47487640380859375
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999984951481292
          ]
        ],
        "inference_time": 0.44559216499328613
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 44,
    "sentence": "Following One Day, the actor was dubbed the 'new Hugh Grant'  Pictured: Jim Sturgess - who is now a musician - opposite David Jason in A Touch of Frost in March 2003  Speaking to The Telegraph at the time, Jim - who starred in the Beatles-inspired movie Across the Universe beforehand - admitted that he hadn't read the book when he had his first audition.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.23446328708275457
          ]
        ],
        "inference_time": 0.4069194793701172
      },
      {
        "repetition": 1,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.47503736359703586
          ]
        ],
        "inference_time": 0.41078758239746094
      },
      {
        "repetition": 2,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4709839897337788
          ]
        ],
        "inference_time": 0.5101611614227295
      },
      {
        "repetition": 3,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.2823867061511573
          ]
        ],
        "inference_time": 0.4915769100189209
      },
      {
        "repetition": 4,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4430931964392295
          ]
        ],
        "inference_time": 0.4317588806152344
      },
      {
        "repetition": 5,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.15422204298683284
          ]
        ],
        "inference_time": 0.8187952041625977
      },
      {
        "repetition": 6,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.336809870757868
          ]
        ],
        "inference_time": 0.3543412685394287
      },
      {
        "repetition": 7,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.14629123892149914
          ]
        ],
        "inference_time": 4.867213010787964
      },
      {
        "repetition": 8,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.07130872563372193
          ]
        ],
        "inference_time": 0.40900206565856934
      },
      {
        "repetition": 9,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.45122254819576757
          ]
        ],
        "inference_time": 0.5111932754516602
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 45,
    "sentence": "He has collaborated with a bevy of big name artists - including Gomez herself, on tracks such as 2023's Single Soon, and his 2019 song I Can\u2019t Get Enough.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.11325096599377008
          ]
        ],
        "inference_time": 0.40811824798583984
      },
      {
        "repetition": 1,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.868419324612236
          ]
        ],
        "inference_time": 0.4092831611633301
      },
      {
        "repetition": 2,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.7649127455468309
          ]
        ],
        "inference_time": 0.39005208015441895
      },
      {
        "repetition": 3,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.7641549886955927
          ]
        ],
        "inference_time": 0.4291720390319824
      },
      {
        "repetition": 4,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.8589900129308274
          ]
        ],
        "inference_time": 0.3474128246307373
      },
      {
        "repetition": 5,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.8435865228868901
          ]
        ],
        "inference_time": 0.42589879035949707
      },
      {
        "repetition": 6,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.8833289610720029
          ]
        ],
        "inference_time": 0.36943626403808594
      },
      {
        "repetition": 7,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.8589900129308274
          ]
        ],
        "inference_time": 0.391247034072876
      },
      {
        "repetition": 8,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.8496098978189066
          ]
        ],
        "inference_time": 0.6143503189086914
      },
      {
        "repetition": 9,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.6413252272327565
          ]
        ],
        "inference_time": 0.4210231304168701
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 46,
    "sentence": "RULE 4: MOISTURISE  Gina uses organic coconut oil every day on her body, as she admitted \"I have moisturised my entire body every day since I was 19.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.1656386070352624
          ]
        ],
        "inference_time": 0.49861788749694824
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5199555742487803
          ]
        ],
        "inference_time": 0.41022825241088867
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.14795156627970948
          ]
        ],
        "inference_time": 0.511366605758667
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.12054942109894957
          ]
        ],
        "inference_time": 0.4835941791534424
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5074790527614285
          ]
        ],
        "inference_time": 0.7441391944885254
      },
      {
        "repetition": 5,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.104922150384749
          ]
        ],
        "inference_time": 0.4693293571472168
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.512573889450659
          ]
        ],
        "inference_time": 0.45333123207092285
      },
      {
        "repetition": 7,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5199555742487803
          ]
        ],
        "inference_time": 0.714914083480835
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5409474662438837
          ]
        ],
        "inference_time": 0.5127768516540527
      },
      {
        "repetition": 9,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5602058548087757
          ]
        ],
        "inference_time": 0.5118279457092285
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 47,
    "sentence": "It\u2019s this second group that Barratt is targeting for Ayrton House \u2013 final year medical students and graduate trainees from the surrounding universities, which include Westminster, Middlesex and UCL.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.597659461877829
          ]
        ],
        "inference_time": 0.4264538288116455
      },
      {
        "repetition": 1,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.4711223248955487
          ]
        ],
        "inference_time": 1.0041451454162598
      },
      {
        "repetition": 2,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.25857041516077545
          ]
        ],
        "inference_time": 0.38347601890563965
      },
      {
        "repetition": 3,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.1069416963402492
          ]
        ],
        "inference_time": 0.43555235862731934
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.7066713059102692
          ]
        ],
        "inference_time": 0.5102996826171875
      },
      {
        "repetition": 5,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.4661873258101292
          ]
        ],
        "inference_time": 0.3933546543121338
      },
      {
        "repetition": 6,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.6855085604512631
          ]
        ],
        "inference_time": 0.42760777473449707
      },
      {
        "repetition": 7,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.30707987895614347
          ]
        ],
        "inference_time": 0.5107073783874512
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.5964006159642881
          ]
        ],
        "inference_time": 0.5113906860351562
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.4710022935768193
          ]
        ],
        "inference_time": 0.6136500835418701
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 48,
    "sentence": "This is why the more Osborne slashed public spending in the 2010s, the more money he needed to borrow.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.1758968630736294
          ]
        ],
        "inference_time": 0.5294837951660156
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.24805522288121543
          ]
        ],
        "inference_time": 0.8776102066040039
      },
      {
        "repetition": 2,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.15720546943473088
          ]
        ],
        "inference_time": 0.35604023933410645
      },
      {
        "repetition": 3,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.13856803883491686
          ]
        ],
        "inference_time": 0.3951711654663086
      },
      {
        "repetition": 4,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.12398437190631753
          ]
        ],
        "inference_time": 0.5035147666931152
      },
      {
        "repetition": 5,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.21973121653529937
          ]
        ],
        "inference_time": 0.40721631050109863
      },
      {
        "repetition": 6,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.1066868531194944
          ]
        ],
        "inference_time": 0.39425230026245117
      },
      {
        "repetition": 7,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.3158769562496344
          ]
        ],
        "inference_time": 0.5265400409698486
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.19188022820457637
          ]
        ],
        "inference_time": 0.5917069911956787
      },
      {
        "repetition": 9,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.09542980950781425
          ]
        ],
        "inference_time": 0.4342024326324463
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 49,
    "sentence": "When your credit card is \u201cmaxed out\u201d, you do indeed need immediately to tighten your belt.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.1674622912631125
          ]
        ],
        "inference_time": 0.5187640190124512
      },
      {
        "repetition": 1,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.21309584540704074
          ]
        ],
        "inference_time": 0.4005091190338135
      },
      {
        "repetition": 2,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.2188185275196494
          ]
        ],
        "inference_time": 0.5235180854797363
      },
      {
        "repetition": 3,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5176669561216426
          ]
        ],
        "inference_time": 0.3975033760070801
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3913266549462409
          ]
        ],
        "inference_time": 0.41673851013183594
      },
      {
        "repetition": 5,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.23735161418768155
          ]
        ],
        "inference_time": 0.343273401260376
      },
      {
        "repetition": 6,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.21309584540704074
          ]
        ],
        "inference_time": 0.46782422065734863
      },
      {
        "repetition": 7,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.20594466902749262
          ]
        ],
        "inference_time": 0.46769070625305176
      },
      {
        "repetition": 8,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.20846463002621535
          ]
        ],
        "inference_time": 0.4545257091522217
      },
      {
        "repetition": 9,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.048165740881719696
          ]
        ],
        "inference_time": 0.45159435272216797
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 50,
    "sentence": "This was inaccurate.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.09906528572905447
          ]
        ],
        "inference_time": 0.4621922969818115
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.061528092886010084
          ]
        ],
        "inference_time": 0.4515681266784668
      },
      {
        "repetition": 2,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.10613671940624818
          ]
        ],
        "inference_time": 0.5742676258087158
      },
      {
        "repetition": 3,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3778569475377857
          ]
        ],
        "inference_time": 1.3242928981781006
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.40389287328858914
          ]
        ],
        "inference_time": 0.7191329002380371
      },
      {
        "repetition": 5,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.32808935307689197
          ]
        ],
        "inference_time": 0.4068739414215088
      },
      {
        "repetition": 6,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.3778569475377857
          ]
        ],
        "inference_time": 0.5103490352630615
      },
      {
        "repetition": 7,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.08431127619195915
          ]
        ],
        "inference_time": 0.346604585647583
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.4572281374932858
          ]
        ],
        "inference_time": 0.47290492057800293
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.1134581189149944
          ]
        ],
        "inference_time": 0.37472033500671387
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 51,
    "sentence": "She now has her 26-year-old granddaughter, Eliza Brunero, lodging with her on Wednesdays each week.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9951954561048004
          ]
        ],
        "inference_time": 0.44255518913269043
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9995776376913623
          ]
        ],
        "inference_time": 0.41701555252075195
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9994259248489007
          ]
        ],
        "inference_time": 0.7104127407073975
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9995869316955196
          ]
        ],
        "inference_time": 0.4217967987060547
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9995776376913623
          ]
        ],
        "inference_time": 0.4047360420227051
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9994259248489007
          ]
        ],
        "inference_time": 0.5016987323760986
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9995660872538118
          ]
        ],
        "inference_time": 0.4481844902038574
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9991221541070437
          ]
        ],
        "inference_time": 0.47316932678222656
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9992087887523283
          ]
        ],
        "inference_time": 0.5107355117797852
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.992238407193881
          ]
        ],
        "inference_time": 0.37899231910705566
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 52,
    "sentence": "Wangari is one of 16 Kenyan women who have died allegedly at the hands of their partners since the start of 2024.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8727262528092431
          ]
        ],
        "inference_time": 0.6040961742401123
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.841792045940127
          ]
        ],
        "inference_time": 0.4507927894592285
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.841792045940127
          ]
        ],
        "inference_time": 0.6136727333068848
      },
      {
        "repetition": 3,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.18057684221871725
          ]
        ],
        "inference_time": 3.8919594287872314
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8079165882731192
          ]
        ],
        "inference_time": 0.5113673210144043
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.841792045940127
          ]
        ],
        "inference_time": 0.6668987274169922
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8432720821972683
          ]
        ],
        "inference_time": 0.45876598358154297
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8433237038093311
          ]
        ],
        "inference_time": 11.577739238739014
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9498964320524605
          ]
        ],
        "inference_time": 0.40222907066345215
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8092883918550724
          ]
        ],
        "inference_time": 0.6326842308044434
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 53,
    "sentence": "And the Caesar Kunikov's watery demise is just the latest blow to have embarrassed Putin.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5214575861126447
          ]
        ],
        "inference_time": 0.5667557716369629
      },
      {
        "repetition": 1,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.3696329689679193
          ]
        ],
        "inference_time": 7.766665935516357
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.3066459562693061
          ]
        ],
        "inference_time": 0.7604072093963623
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.3696329689679193
          ]
        ],
        "inference_time": 0.5166120529174805
      },
      {
        "repetition": 4,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.55000696615566
          ]
        ],
        "inference_time": 0.5905072689056396
      },
      {
        "repetition": 5,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.2617213622565947
          ]
        ],
        "inference_time": 0.42806291580200195
      },
      {
        "repetition": 6,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.6014107751628985
          ]
        ],
        "inference_time": 0.5118963718414307
      },
      {
        "repetition": 7,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5055894712862088
          ]
        ],
        "inference_time": 0.7167634963989258
      },
      {
        "repetition": 8,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.3696329689679193
          ]
        ],
        "inference_time": 0.8203158378601074
      },
      {
        "repetition": 9,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.1462259608456999
          ]
        ],
        "inference_time": 0.4080536365509033
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 54,
    "sentence": "Beks then shared a clip of what happened straight after and continues: \"It was my lunch break and I just dipped out and didn't tell anybody.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.07730953704597339
          ]
        ],
        "inference_time": 0.510366678237915
      },
      {
        "repetition": 1,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.19435068690069746
          ]
        ],
        "inference_time": 0.5108828544616699
      },
      {
        "repetition": 2,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.031631092199691874
          ]
        ],
        "inference_time": 0.4114193916320801
      },
      {
        "repetition": 3,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.19846404545515425
          ]
        ],
        "inference_time": 0.421952486038208
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.11035230661216353
          ]
        ],
        "inference_time": 0.42769289016723633
      },
      {
        "repetition": 5,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.11356366501913372
          ]
        ],
        "inference_time": 0.4790055751800537
      },
      {
        "repetition": 6,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.13640221066681169
          ]
        ],
        "inference_time": 0.4101114273071289
      },
      {
        "repetition": 7,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.052220131521359306
          ]
        ],
        "inference_time": 0.5115060806274414
      },
      {
        "repetition": 8,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.23718241672055718
          ]
        ],
        "inference_time": 0.40898942947387695
      },
      {
        "repetition": 9,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.035010557590938074
          ]
        ],
        "inference_time": 0.4087233543395996
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 55,
    "sentence": "I know you was heartbroken lol.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "100",
        "token_probs": [
          [
            "100",
            0.0871143307579783
          ]
        ],
        "inference_time": 0.4070296287536621
      },
      {
        "repetition": 1,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.3338222841224216
          ]
        ],
        "inference_time": 0.4162161350250244
      },
      {
        "repetition": 2,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.19741907807744724
          ]
        ],
        "inference_time": 0.5056710243225098
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.061891201927160244
          ]
        ],
        "inference_time": 0.38824963569641113
      },
      {
        "repetition": 4,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.04722824172718107
          ]
        ],
        "inference_time": 0.4300689697265625
      },
      {
        "repetition": 5,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.05564649155864025
          ]
        ],
        "inference_time": 0.5129280090332031
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.21602154652708605
          ]
        ],
        "inference_time": 0.6143510341644287
      },
      {
        "repetition": 7,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.31430949556945653
          ]
        ],
        "inference_time": 2.1014533042907715
      },
      {
        "repetition": 8,
        "generated_text": "100",
        "token_probs": [
          [
            "100",
            0.2579139282506844
          ]
        ],
        "inference_time": 0.4859631061553955
      },
      {
        "repetition": 9,
        "generated_text": "100",
        "token_probs": [
          [
            "100",
            0.21021483067060479
          ]
        ],
        "inference_time": 0.44389843940734863
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 56,
    "sentence": "\u201cI can\u2019t say I add anything to her life but she certainly brightens up mine.\u201d  Brunero begs to differ.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5176435991448294
          ]
        ],
        "inference_time": 0.43402838706970215
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5922035198638665
          ]
        ],
        "inference_time": 0.5220181941986084
      },
      {
        "repetition": 2,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5781229334865262
          ]
        ],
        "inference_time": 0.4492485523223877
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5752617887293193
          ]
        ],
        "inference_time": 0.6477680206298828
      },
      {
        "repetition": 4,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.08203266398952201
          ]
        ],
        "inference_time": 0.42301321029663086
      },
      {
        "repetition": 5,
        "generated_text": "90",
        "token_probs": [
          [
            "90",
            0.061823715235115415
          ]
        ],
        "inference_time": 0.5276424884796143
      },
      {
        "repetition": 6,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.11287204636735218
          ]
        ],
        "inference_time": 0.44925618171691895
      },
      {
        "repetition": 7,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.19441473492965633
          ]
        ],
        "inference_time": 0.47205162048339844
      },
      {
        "repetition": 8,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5595736884935993
          ]
        ],
        "inference_time": 0.4838864803314209
      },
      {
        "repetition": 9,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.6061439200343123
          ]
        ],
        "inference_time": 0.4321250915527344
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 57,
    "sentence": "But while Leo Woodall is enjoying a career boost for his portrayal as 'pampered Southern toff' Dexter Mayhew, the 2011 film adaptation had the exact opposite effect for actor Jim Sturgess.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.21086578122463262
          ]
        ],
        "inference_time": 0.7110180854797363
      },
      {
        "repetition": 1,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.38997314877283756
          ]
        ],
        "inference_time": 0.4202911853790283
      },
      {
        "repetition": 2,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.05178134615221089
          ]
        ],
        "inference_time": 0.4077584743499756
      },
      {
        "repetition": 3,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.03625476535536817
          ]
        ],
        "inference_time": 0.5113973617553711
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.2173832479173632
          ]
        ],
        "inference_time": 0.4091835021972656
      },
      {
        "repetition": 5,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.1913965753207826
          ]
        ],
        "inference_time": 0.5125057697296143
      },
      {
        "repetition": 6,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.04328838684958974
          ]
        ],
        "inference_time": 0.4415123462677002
      },
      {
        "repetition": 7,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.18073463532501433
          ]
        ],
        "inference_time": 0.47916221618652344
      },
      {
        "repetition": 8,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.3476588987678515
          ]
        ],
        "inference_time": 0.4084639549255371
      },
      {
        "repetition": 9,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.357575878109424
          ]
        ],
        "inference_time": 0.44675421714782715
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 58,
    "sentence": "I scribbled down what I saw and what I felt and the song kind of wrote itself.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.6220525710434126
          ]
        ],
        "inference_time": 0.5764284133911133
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5558328140976271
          ]
        ],
        "inference_time": 0.612804651260376
      },
      {
        "repetition": 2,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.12169867915437278
          ]
        ],
        "inference_time": 0.5125672817230225
      },
      {
        "repetition": 3,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.1260490375372596
          ]
        ],
        "inference_time": 0.5128507614135742
      },
      {
        "repetition": 4,
        "generated_text": "90",
        "token_probs": [
          [
            "90",
            0.23933289938824834
          ]
        ],
        "inference_time": 0.407895565032959
      },
      {
        "repetition": 5,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.1595606843240175
          ]
        ],
        "inference_time": 0.40954089164733887
      },
      {
        "repetition": 6,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.6056221530396634
          ]
        ],
        "inference_time": 0.4597816467285156
      },
      {
        "repetition": 7,
        "generated_text": "90",
        "token_probs": [
          [
            "90",
            0.23215942580205046
          ]
        ],
        "inference_time": 0.3714487552642822
      },
      {
        "repetition": 8,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5543127616509763
          ]
        ],
        "inference_time": 0.9089486598968506
      },
      {
        "repetition": 9,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5909384484907751
          ]
        ],
        "inference_time": 0.5118441581726074
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 59,
    "sentence": "In the first image, the Emmy-nominated actress embraced Blanco, who has a passion for cooking, while he was preparing a platter of meatballs.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.4580319049579758
          ]
        ],
        "inference_time": 0.5105726718902588
      },
      {
        "repetition": 1,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.5145778385984485
          ]
        ],
        "inference_time": 0.5085263252258301
      },
      {
        "repetition": 2,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.8300729163321052
          ]
        ],
        "inference_time": 0.4134101867675781
      },
      {
        "repetition": 3,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.40814636574426094
          ]
        ],
        "inference_time": 0.5098719596862793
      },
      {
        "repetition": 4,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.7030534422336028
          ]
        ],
        "inference_time": 0.5119161605834961
      },
      {
        "repetition": 5,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.5109531187995588
          ]
        ],
        "inference_time": 0.4102463722229004
      },
      {
        "repetition": 6,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.4580319049579758
          ]
        ],
        "inference_time": 0.408968448638916
      },
      {
        "repetition": 7,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.6274069100066464
          ]
        ],
        "inference_time": 0.40407776832580566
      },
      {
        "repetition": 8,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.4105487346954103
          ]
        ],
        "inference_time": 0.37205982208251953
      },
      {
        "repetition": 9,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.4003334845285448
          ]
        ],
        "inference_time": 0.7584841251373291
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 60,
    "sentence": "It follows their range of Unmanned Surface Vehicles (USVs) which have been hugely successful in Black Sea attacks.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.09109632791525003
          ]
        ],
        "inference_time": 0.4738352298736572
      },
      {
        "repetition": 1,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.15602776157748666
          ]
        ],
        "inference_time": 0.5128157138824463
      },
      {
        "repetition": 2,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5764591796285417
          ]
        ],
        "inference_time": 0.3497042655944824
      },
      {
        "repetition": 3,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5582297372124747
          ]
        ],
        "inference_time": 0.8770785331726074
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.28065809869388153
          ]
        ],
        "inference_time": 0.45642614364624023
      },
      {
        "repetition": 5,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5963480779696502
          ]
        ],
        "inference_time": 0.4647402763366699
      },
      {
        "repetition": 6,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.14848778943825808
          ]
        ],
        "inference_time": 0.4096667766571045
      },
      {
        "repetition": 7,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5882964370670656
          ]
        ],
        "inference_time": 0.6155276298522949
      },
      {
        "repetition": 8,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.27455747170752665
          ]
        ],
        "inference_time": 0.40819501876831055
      },
      {
        "repetition": 9,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.15339853745854154
          ]
        ],
        "inference_time": 0.38123059272766113
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 61,
    "sentence": "But one person who knows exactly what's that like after getting the winning number on a scratchcard has told how they were left bitterly \"disappointed.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.23987591169781933
          ]
        ],
        "inference_time": 0.7193460464477539
      },
      {
        "repetition": 1,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.4723599644606641
          ]
        ],
        "inference_time": 0.45180630683898926
      },
      {
        "repetition": 2,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.29200507645102397
          ]
        ],
        "inference_time": 0.3832998275756836
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.42637303143622257
          ]
        ],
        "inference_time": 0.5206365585327148
      },
      {
        "repetition": 4,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.13842306492148623
          ]
        ],
        "inference_time": 0.5120198726654053
      },
      {
        "repetition": 5,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.29548183366979036
          ]
        ],
        "inference_time": 5.725973844528198
      },
      {
        "repetition": 6,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.0988221906388827
          ]
        ],
        "inference_time": 0.41606926918029785
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.45738475959481023
          ]
        ],
        "inference_time": 0.4515237808227539
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.2730843745457574
          ]
        ],
        "inference_time": 0.3673083782196045
      },
      {
        "repetition": 9,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.20184402782741995
          ]
        ],
        "inference_time": 0.41072750091552734
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 62,
    "sentence": "Selena looked chic in a brown turtleneck, with her hair brushed back into a ponytail, while her other half rocked a white tee, and gold chains.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.5348362205701744
          ]
        ],
        "inference_time": 0.3423776626586914
      },
      {
        "repetition": 1,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.526037549784291
          ]
        ],
        "inference_time": 0.47368669509887695
      },
      {
        "repetition": 2,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5930763780598652
          ]
        ],
        "inference_time": 0.43958234786987305
      },
      {
        "repetition": 3,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.05943314828797577
          ]
        ],
        "inference_time": 0.48114562034606934
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3331000760574191
          ]
        ],
        "inference_time": 0.820631742477417
      },
      {
        "repetition": 5,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.6365652124416935
          ]
        ],
        "inference_time": 0.5106980800628662
      },
      {
        "repetition": 6,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4144316005205696
          ]
        ],
        "inference_time": 0.5107858180999756
      },
      {
        "repetition": 7,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4740830511008456
          ]
        ],
        "inference_time": 0.4100472927093506
      },
      {
        "repetition": 8,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.26535986802386335
          ]
        ],
        "inference_time": 0.42206406593322754
      },
      {
        "repetition": 9,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.4498741173239277
          ]
        ],
        "inference_time": 0.39852142333984375
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 63,
    "sentence": "The refreshing beer-and-fizzy-pop combination bubbled away as a quietly constant \u2013 if not cult \u2013 pub choice for over half my lifetime, then seemed to fizzle out over the past 15 years.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.43143374770372683
          ]
        ],
        "inference_time": 0.7128574848175049
      },
      {
        "repetition": 1,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.44801889789542154
          ]
        ],
        "inference_time": 0.4100792407989502
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.4473794198783603
          ]
        ],
        "inference_time": 0.5034852027893066
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.342563947625147
          ]
        ],
        "inference_time": 0.41649460792541504
      },
      {
        "repetition": 4,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.10395206323183998
          ]
        ],
        "inference_time": 0.41365790367126465
      },
      {
        "repetition": 5,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.4007152872077334
          ]
        ],
        "inference_time": 0.41474461555480957
      },
      {
        "repetition": 6,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.34471443841018884
          ]
        ],
        "inference_time": 0.5023050308227539
      },
      {
        "repetition": 7,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.3734875929085486
          ]
        ],
        "inference_time": 0.5717611312866211
      },
      {
        "repetition": 8,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.4473794198783603
          ]
        ],
        "inference_time": 0.5554547309875488
      },
      {
        "repetition": 9,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.34200551078261154
          ]
        ],
        "inference_time": 0.39748072624206543
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 64,
    "sentence": "Kyiv continues to target Russia\u2019s Black Sea Fleet with great effectDr Bastian Giegerich, IISS security analyst  And Vlad's Black Sea fleet was \"put on the defensive by several events\", which included the sea drone attack in December that \"badly damaged a landing ship off Novorossiysk\".",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.09197836813749535
          ]
        ],
        "inference_time": 0.41939496994018555
      },
      {
        "repetition": 1,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4729700795295222
          ]
        ],
        "inference_time": 0.4671924114227295
      },
      {
        "repetition": 2,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.40643408171342493
          ]
        ],
        "inference_time": 0.45289158821105957
      },
      {
        "repetition": 3,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.49198029638488233
          ]
        ],
        "inference_time": 0.3654787540435791
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.17211828407469967
          ]
        ],
        "inference_time": 0.4544858932495117
      },
      {
        "repetition": 5,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.21754848717673186
          ]
        ],
        "inference_time": 3.0706827640533447
      },
      {
        "repetition": 6,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.15848971573245707
          ]
        ],
        "inference_time": 0.4273254871368408
      },
      {
        "repetition": 7,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.02486518653696765
          ]
        ],
        "inference_time": 1.8948402404785156
      },
      {
        "repetition": 8,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.17211828407469967
          ]
        ],
        "inference_time": 0.3391289710998535
      },
      {
        "repetition": 9,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4919810881419111
          ]
        ],
        "inference_time": 0.8789613246917725
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 65,
    "sentence": "\u201cIt\u2019s such a bonus \u2013 sometimes I cook for her, sometimes she cooks for me, we play cards, we watch TV and we chat,\u201d Hamilton says.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.3519012279757267
          ]
        ],
        "inference_time": 0.8907339572906494
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.2088173638664326
          ]
        ],
        "inference_time": 0.6855247020721436
      },
      {
        "repetition": 2,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.4266046904250621
          ]
        ],
        "inference_time": 0.5113208293914795
      },
      {
        "repetition": 3,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3815704460928602
          ]
        ],
        "inference_time": 0.5117588043212891
      },
      {
        "repetition": 4,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.19812799738069217
          ]
        ],
        "inference_time": 4.50636100769043
      },
      {
        "repetition": 5,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3048510401996591
          ]
        ],
        "inference_time": 0.5120868682861328
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.41305221680853754
          ]
        ],
        "inference_time": 0.7158384323120117
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.3206122542550523
          ]
        ],
        "inference_time": 0.8182961940765381
      },
      {
        "repetition": 8,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.30151622330807987
          ]
        ],
        "inference_time": 0.409595251083374
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.3614899122749284
          ]
        ],
        "inference_time": 0.7739913463592529
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 66,
    "sentence": "She was fairly close to Wangari, and recalls with sadness how she had promised to send her money the following week so she could move to a new flat.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.6553833726426558
          ]
        ],
        "inference_time": 0.45284175872802734
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5965531729999888
          ]
        ],
        "inference_time": 1.7405214309692383
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.10049308987957824
          ]
        ],
        "inference_time": 0.5112035274505615
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.16284861473332138
          ]
        ],
        "inference_time": 0.5131514072418213
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.6334851381116872
          ]
        ],
        "inference_time": 0.9211716651916504
      },
      {
        "repetition": 5,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.16284865355946135
          ]
        ],
        "inference_time": 0.44422197341918945
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.6553276113075075
          ]
        ],
        "inference_time": 0.47612762451171875
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.12469201470017321
          ]
        ],
        "inference_time": 0.47895097732543945
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.6379280939275508
          ]
        ],
        "inference_time": 2.79669189453125
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.10083636643071438
          ]
        ],
        "inference_time": 0.5122153759002686
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 67,
    "sentence": "And it could even be used to gather intelligence on Russian operations.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.49858306238749833
          ]
        ],
        "inference_time": 0.8170561790466309
      },
      {
        "repetition": 1,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.09817682604315948
          ]
        ],
        "inference_time": 0.4443247318267822
      },
      {
        "repetition": 2,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.47668440313267385
          ]
        ],
        "inference_time": 0.3569972515106201
      },
      {
        "repetition": 3,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.48183097279191356
          ]
        ],
        "inference_time": 0.42972254753112793
      },
      {
        "repetition": 4,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.47668440313267385
          ]
        ],
        "inference_time": 0.4076073169708252
      },
      {
        "repetition": 5,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.49858306238749833
          ]
        ],
        "inference_time": 0.511110782623291
      },
      {
        "repetition": 6,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.36203553571046315
          ]
        ],
        "inference_time": 0.9205276966094971
      },
      {
        "repetition": 7,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3695036426541093
          ]
        ],
        "inference_time": 0.5120704174041748
      },
      {
        "repetition": 8,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.28912370550678357
          ]
        ],
        "inference_time": 0.4089031219482422
      },
      {
        "repetition": 9,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.44684980235255845
          ]
        ],
        "inference_time": 0.7169456481933594
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 68,
    "sentence": "\"I'm not really a gambler - it was a $10k (\u00a37.9k) a week for life scratch card and I scratched it off.\"",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.21296148048996588
          ]
        ],
        "inference_time": 0.6126415729522705
      },
      {
        "repetition": 1,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.09764608021563113
          ]
        ],
        "inference_time": 0.45318126678466797
      },
      {
        "repetition": 2,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.06642122722762457
          ]
        ],
        "inference_time": 0.36461424827575684
      },
      {
        "repetition": 3,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.2113645131866569
          ]
        ],
        "inference_time": 0.41132354736328125
      },
      {
        "repetition": 4,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.38222772638257463
          ]
        ],
        "inference_time": 0.401841402053833
      },
      {
        "repetition": 5,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.09996943621229303
          ]
        ],
        "inference_time": 0.6197834014892578
      },
      {
        "repetition": 6,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.36844496445391745
          ]
        ],
        "inference_time": 0.4099314212799072
      },
      {
        "repetition": 7,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.0881098378553545
          ]
        ],
        "inference_time": 0.5119025707244873
      },
      {
        "repetition": 8,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.1668597348866233
          ]
        ],
        "inference_time": 3.8913891315460205
      },
      {
        "repetition": 9,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.09996943621229303
          ]
        ],
        "inference_time": 0.7206234931945801
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 69,
    "sentence": "When it was an Emma and Dex day I felt good about it.'",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.31755113368091337
          ]
        ],
        "inference_time": 0.5050256252288818
      },
      {
        "repetition": 1,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.30769651604931547
          ]
        ],
        "inference_time": 0.32155919075012207
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.2010375557030218
          ]
        ],
        "inference_time": 0.49770545959472656
      },
      {
        "repetition": 3,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.3532663596798246
          ]
        ],
        "inference_time": 0.3709554672241211
      },
      {
        "repetition": 4,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.2575921290775005
          ]
        ],
        "inference_time": 0.44841647148132324
      },
      {
        "repetition": 5,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.3976779773539021
          ]
        ],
        "inference_time": 0.40803003311157227
      },
      {
        "repetition": 6,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.2085439443978573
          ]
        ],
        "inference_time": 0.40973639488220215
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.23963428764755
          ]
        ],
        "inference_time": 0.4095034599304199
      },
      {
        "repetition": 8,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.34305900204710404
          ]
        ],
        "inference_time": 0.513139009475708
      },
      {
        "repetition": 9,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.2872700819259049
          ]
        ],
        "inference_time": 0.8126785755157471
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 70,
    "sentence": "RULE 10: BE HAPPY  She then advised: \u201cLike the song don\u2019t worry be happy and create a life of meaningful memories.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.09310203839209513
          ]
        ],
        "inference_time": 0.4983670711517334
      },
      {
        "repetition": 1,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.06778238134042121
          ]
        ],
        "inference_time": 0.4223449230194092
      },
      {
        "repetition": 2,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3749910647047848
          ]
        ],
        "inference_time": 0.39554286003112793
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.26984863590820735
          ]
        ],
        "inference_time": 0.5128092765808105
      },
      {
        "repetition": 4,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.23069716256746356
          ]
        ],
        "inference_time": 0.8182101249694824
      },
      {
        "repetition": 5,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.2438225125705564
          ]
        ],
        "inference_time": 0.5120506286621094
      },
      {
        "repetition": 6,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.16260147996379284
          ]
        ],
        "inference_time": 0.5114445686340332
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.27785503956803154
          ]
        ],
        "inference_time": 0.40985941886901855
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3585226674146952
          ]
        ],
        "inference_time": 0.8185300827026367
      },
      {
        "repetition": 9,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.16902532177636181
          ]
        ],
        "inference_time": 0.5116970539093018
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 71,
    "sentence": "But perhaps most impressively, Ukrainian forces managed to blow up Russia's flagship vessel - the Moskva - in April 2022.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.1952668098320983
          ]
        ],
        "inference_time": 0.349149227142334
      },
      {
        "repetition": 1,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.1874735620439455
          ]
        ],
        "inference_time": 0.4688117504119873
      },
      {
        "repetition": 2,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.30099796806529344
          ]
        ],
        "inference_time": 0.6140596866607666
      },
      {
        "repetition": 3,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.21896851663771036
          ]
        ],
        "inference_time": 0.5378110408782959
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.35295170796965
          ]
        ],
        "inference_time": 0.38330984115600586
      },
      {
        "repetition": 5,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.32194054283193735
          ]
        ],
        "inference_time": 0.40845227241516113
      },
      {
        "repetition": 6,
        "generated_text": "50",
        "token_probs": [
          [
            "50",
            0.030795278796926253
          ]
        ],
        "inference_time": 0.3610198497772217
      },
      {
        "repetition": 7,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.06756775383737544
          ]
        ],
        "inference_time": 0.45767879486083984
      },
      {
        "repetition": 8,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.2578456817473603
          ]
        ],
        "inference_time": 0.4614386558532715
      },
      {
        "repetition": 9,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.1474029929742378
          ]
        ],
        "inference_time": 0.4591643810272217
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 72,
    "sentence": "But Michelle evidently didn't hold the blunder against him; the couple have been married since 2015 after meeting in late 2012.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5953179116193676
          ]
        ],
        "inference_time": 0.4082627296447754
      },
      {
        "repetition": 1,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.25612421601279284
          ]
        ],
        "inference_time": 0.4159247875213623
      },
      {
        "repetition": 2,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5953179116193676
          ]
        ],
        "inference_time": 0.3572559356689453
      },
      {
        "repetition": 3,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.2907522548241642
          ]
        ],
        "inference_time": 0.4543342590332031
      },
      {
        "repetition": 4,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.6131924920393742
          ]
        ],
        "inference_time": 0.38645005226135254
      },
      {
        "repetition": 5,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.614199661762215
          ]
        ],
        "inference_time": 0.43269920349121094
      },
      {
        "repetition": 6,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4630465543991743
          ]
        ],
        "inference_time": 0.4093170166015625
      },
      {
        "repetition": 7,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5489877057377428
          ]
        ],
        "inference_time": 0.6603102684020996
      },
      {
        "repetition": 8,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5953179116193676
          ]
        ],
        "inference_time": 0.46538519859313965
      },
      {
        "repetition": 9,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.46165051620627007
          ]
        ],
        "inference_time": 0.4014122486114502
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 73,
    "sentence": "Vigils, dubbed \u201cDark Valentine\u201d, were held across Kenya this week after a month in which more than a dozen women have been killed, allegedly by their partners.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.148372865135255
          ]
        ],
        "inference_time": 0.41658520698547363
      },
      {
        "repetition": 1,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.655803522237536
          ]
        ],
        "inference_time": 0.5112526416778564
      },
      {
        "repetition": 2,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.6390100178245168
          ]
        ],
        "inference_time": 0.6138534545898438
      },
      {
        "repetition": 3,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.655803522237536
          ]
        ],
        "inference_time": 0.4089672565460205
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.6649610678287999
          ]
        ],
        "inference_time": 0.5126407146453857
      },
      {
        "repetition": 5,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.19295788208952097
          ]
        ],
        "inference_time": 0.511359453201294
      },
      {
        "repetition": 6,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.2834036442201905
          ]
        ],
        "inference_time": 6.5536699295043945
      },
      {
        "repetition": 7,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.6858592858909548
          ]
        ],
        "inference_time": 0.4105713367462158
      },
      {
        "repetition": 8,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.12018281058594171
          ]
        ],
        "inference_time": 0.36907410621643066
      },
      {
        "repetition": 9,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.1155529173288649
          ]
        ],
        "inference_time": 0.5514075756072998
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 74,
    "sentence": "The radio presenter revealed the Fool Me Once star rumbled his porky pies the next day and fumed: 'Mark, you're a liar!'",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.20369399098212038
          ]
        ],
        "inference_time": 0.6107926368713379
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.6261762262145573
          ]
        ],
        "inference_time": 0.4117145538330078
      },
      {
        "repetition": 2,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.6869465229015005
          ]
        ],
        "inference_time": 0.6120510101318359
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5704254365965317
          ]
        ],
        "inference_time": 0.5123255252838135
      },
      {
        "repetition": 4,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5986658822471991
          ]
        ],
        "inference_time": 0.40847182273864746
      },
      {
        "repetition": 5,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.6261762262145573
          ]
        ],
        "inference_time": 0.6139914989471436
      },
      {
        "repetition": 6,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.2155661949492551
          ]
        ],
        "inference_time": 0.5111491680145264
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.2407682867459031
          ]
        ],
        "inference_time": 0.6148319244384766
      },
      {
        "repetition": 8,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5859697054871352
          ]
        ],
        "inference_time": 0.479372501373291
      },
      {
        "repetition": 9,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5605521249410302
          ]
        ],
        "inference_time": 1.2618622779846191
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 75,
    "sentence": "The snap comes after Selena surprised fans on Monday with a very racy photo of Benny grabbing her cleavage  Gomez has been linked with Blanco, a musical artist, producer, and songwriter, since last year  In the first image from the post, the Emmy-nominated actress embraced Blanco, who has a passion for cooking, while he was preparing a platter of meatballs  Blanco was posed behind Gomez as they relaxed in the kitchen area of a home alongside friends including The Bear actor Matty Matheson  On Sunday, the couple was seen kissing one another while posed against a velvet red couch in a shot Gomez posted to Instagram  Gomez and Blanco have frequently shared their light-hearted and romantic moments via Instagram in the early days of their relationship.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.22951996041678457
          ]
        ],
        "inference_time": 0.41683459281921387
      },
      {
        "repetition": 1,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.14614095474134706
          ]
        ],
        "inference_time": 0.39612245559692383
      },
      {
        "repetition": 2,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.20661525103061518
          ]
        ],
        "inference_time": 0.5172824859619141
      },
      {
        "repetition": 3,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.22951996041678457
          ]
        ],
        "inference_time": 0.3690969944000244
      },
      {
        "repetition": 4,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.06955584431133123
          ]
        ],
        "inference_time": 0.44869160652160645
      },
      {
        "repetition": 5,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5235767762297527
          ]
        ],
        "inference_time": 0.6879873275756836
      },
      {
        "repetition": 6,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4812854703067643
          ]
        ],
        "inference_time": 0.5407888889312744
      },
      {
        "repetition": 7,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5318057761497872
          ]
        ],
        "inference_time": 0.37961244583129883
      },
      {
        "repetition": 8,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.11689796047310556
          ]
        ],
        "inference_time": 0.4384148120880127
      },
      {
        "repetition": 9,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.12358986997104748
          ]
        ],
        "inference_time": 0.8212306499481201
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 76,
    "sentence": "November 17, 2023  Sir, your article \u2018BBC crisis over \u00a31.7bn pension bill for stars\u2019 (4/11/2023) is incorrect and significantly inflates the BBC\u2019s obligation to fund its defined benefit pension scheme shortfall and employer contribution rate.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.6070193971708348
          ]
        ],
        "inference_time": 0.7129909992218018
      },
      {
        "repetition": 1,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.23912511492191557
          ]
        ],
        "inference_time": 0.6144073009490967
      },
      {
        "repetition": 2,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.08554554293605632
          ]
        ],
        "inference_time": 0.4132106304168701
      },
      {
        "repetition": 3,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.442719382769041
          ]
        ],
        "inference_time": 0.6104960441589355
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.28485908211631317
          ]
        ],
        "inference_time": 0.4657707214355469
      },
      {
        "repetition": 5,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3383391452828276
          ]
        ],
        "inference_time": 0.5580360889434814
      },
      {
        "repetition": 6,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.6123695200068033
          ]
        ],
        "inference_time": 0.42566490173339844
      },
      {
        "repetition": 7,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5843787311352577
          ]
        ],
        "inference_time": 0.49820923805236816
      },
      {
        "repetition": 8,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.4180270516365045
          ]
        ],
        "inference_time": 0.4060978889465332
      },
      {
        "repetition": 9,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.064891693162232
          ]
        ],
        "inference_time": 0.4095876216888428
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 77,
    "sentence": "The crime currently falls under homicide provisions, which rights groups say do not account for the unequal power relations between men and women that drive and characterise the killings.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5690538280629326
          ]
        ],
        "inference_time": 0.6128723621368408
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.4268786338220619
          ]
        ],
        "inference_time": 0.4707155227661133
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5431477404249776
          ]
        ],
        "inference_time": 0.8476161956787109
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.48722012238227375
          ]
        ],
        "inference_time": 0.4226539134979248
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3473707740219255
          ]
        ],
        "inference_time": 0.7699260711669922
      },
      {
        "repetition": 5,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3451485731745512
          ]
        ],
        "inference_time": 0.43860697746276855
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3473707740219255
          ]
        ],
        "inference_time": 0.486971378326416
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5690538280629326
          ]
        ],
        "inference_time": 0.4462599754333496
      },
      {
        "repetition": 8,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.45235905194414106
          ]
        ],
        "inference_time": 0.5190422534942627
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5415374473867707
          ]
        ],
        "inference_time": 0.4083073139190674
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 78,
    "sentence": "Fr\u00fch Natur Radler  2.5%; The Real Ale Store, \u00a31.85 for 500ml; Hop Burns & Black, \u00a32.30  If grapefruit is not your bag, seek out this lemony-fresh delight from Fr\u00fch.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.057120444793463634
          ]
        ],
        "inference_time": 0.4077174663543701
      },
      {
        "repetition": 1,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.2381439352304912
          ]
        ],
        "inference_time": 0.4092576503753662
      },
      {
        "repetition": 2,
        "generated_text": "45",
        "token_probs": [
          [
            "45",
            0.037912233266393335
          ]
        ],
        "inference_time": 0.6143348217010498
      },
      {
        "repetition": 3,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.054187971882764266
          ]
        ],
        "inference_time": 0.4105875492095947
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.39263299490549397
          ]
        ],
        "inference_time": 0.3879685401916504
      },
      {
        "repetition": 5,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.35334996314503975
          ]
        ],
        "inference_time": 0.42913055419921875
      },
      {
        "repetition": 6,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.09927316181437046
          ]
        ],
        "inference_time": 0.40990638732910156
      },
      {
        "repetition": 7,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.13386497664199706
          ]
        ],
        "inference_time": 0.4116535186767578
      },
      {
        "repetition": 8,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.08934086185921392
          ]
        ],
        "inference_time": 0.4073772430419922
      },
      {
        "repetition": 9,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.3546421985134848
          ]
        ],
        "inference_time": 0.4227259159088135
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 79,
    "sentence": "Following on from this, Jim went on to star in the 2012 adaptation of David Mitchell's Cloud Atlas, which also divided audiences.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.22142431173329594
          ]
        ],
        "inference_time": 0.4951035976409912
      },
      {
        "repetition": 1,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5436670753202696
          ]
        ],
        "inference_time": 0.4558439254760742
      },
      {
        "repetition": 2,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5365051198251534
          ]
        ],
        "inference_time": 0.5700929164886475
      },
      {
        "repetition": 3,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.2039646745607749
          ]
        ],
        "inference_time": 1.094290018081665
      },
      {
        "repetition": 4,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5207879658813039
          ]
        ],
        "inference_time": 0.37140870094299316
      },
      {
        "repetition": 5,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.13746057176961393
          ]
        ],
        "inference_time": 0.47823596000671387
      },
      {
        "repetition": 6,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5170451624745946
          ]
        ],
        "inference_time": 0.37241649627685547
      },
      {
        "repetition": 7,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.29886888291895825
          ]
        ],
        "inference_time": 0.5485372543334961
      },
      {
        "repetition": 8,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.48846100673804776
          ]
        ],
        "inference_time": 0.4345378875732422
      },
      {
        "repetition": 9,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5140747391537175
          ]
        ],
        "inference_time": 0.3868875503540039
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 80,
    "sentence": "Limit your spending and you have limited your income too.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.5329839661849877
          ]
        ],
        "inference_time": 0.36544036865234375
      },
      {
        "repetition": 1,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.4914299232304195
          ]
        ],
        "inference_time": 0.37347936630249023
      },
      {
        "repetition": 2,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.07073929085852285
          ]
        ],
        "inference_time": 0.42980265617370605
      },
      {
        "repetition": 3,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.09274627631663405
          ]
        ],
        "inference_time": 0.7134807109832764
      },
      {
        "repetition": 4,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.29806012031675433
          ]
        ],
        "inference_time": 0.44266796112060547
      },
      {
        "repetition": 5,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.04290554875202372
          ]
        ],
        "inference_time": 0.3861844539642334
      },
      {
        "repetition": 6,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.45449897726369537
          ]
        ],
        "inference_time": 0.43259310722351074
      },
      {
        "repetition": 7,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.35396413830021123
          ]
        ],
        "inference_time": 0.7190368175506592
      },
      {
        "repetition": 8,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.4551399506901823
          ]
        ],
        "inference_time": 0.4088764190673828
      },
      {
        "repetition": 9,
        "generated_text": "25",
        "token_probs": [
          [
            "25",
            0.04192975313331285
          ]
        ],
        "inference_time": 0.7174053192138672
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 81,
    "sentence": "Unlike some of the other lemon offerings out there, this isn\u2019t soapy at all and has a very natural lemon flavouring.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5736371086768228
          ]
        ],
        "inference_time": 0.40514397621154785
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.16434979308893066
          ]
        ],
        "inference_time": 0.4008605480194092
      },
      {
        "repetition": 2,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.16434979308893066
          ]
        ],
        "inference_time": 0.5313186645507812
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5940439565556631
          ]
        ],
        "inference_time": 0.39804959297180176
      },
      {
        "repetition": 4,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5867288706225121
          ]
        ],
        "inference_time": 0.5117530822753906
      },
      {
        "repetition": 5,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5736371086768228
          ]
        ],
        "inference_time": 0.4620673656463623
      },
      {
        "repetition": 6,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5883824232211537
          ]
        ],
        "inference_time": 0.45992088317871094
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5883824232211537
          ]
        ],
        "inference_time": 0.4090461730957031
      },
      {
        "repetition": 8,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5883824232211537
          ]
        ],
        "inference_time": 0.5115096569061279
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5736371086768228
          ]
        ],
        "inference_time": 0.40927815437316895
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 82,
    "sentence": "Blanco was past rumored to be in a romance with Elsie Hewitt, a 27-year-old model-actress from London (who has since been linked with Jason Sudeikis, 48).",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5876955162624217
          ]
        ],
        "inference_time": 0.4485208988189697
      },
      {
        "repetition": 1,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.6118918657547971
          ]
        ],
        "inference_time": 0.4704782962799072
      },
      {
        "repetition": 2,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.11573320703376973
          ]
        ],
        "inference_time": 0.5118606090545654
      },
      {
        "repetition": 3,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.21620108521499273
          ]
        ],
        "inference_time": 0.5406286716461182
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.19349829609423383
          ]
        ],
        "inference_time": 0.5858137607574463
      },
      {
        "repetition": 5,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.6149108765295517
          ]
        ],
        "inference_time": 0.510958194732666
      },
      {
        "repetition": 6,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5877417568663375
          ]
        ],
        "inference_time": 0.5132095813751221
      },
      {
        "repetition": 7,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.6202004345710965
          ]
        ],
        "inference_time": 0.5037477016448975
      },
      {
        "repetition": 8,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.25646405299652314
          ]
        ],
        "inference_time": 6.218044281005859
      },
      {
        "repetition": 9,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5937875533630024
          ]
        ],
        "inference_time": 0.44513869285583496
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 83,
    "sentence": "The Schedule of Contributions agreed with the Scheme Trustee as part of the 2022 actuarial valuation states that the employer contribution rate for the defined benefit pension scheme is currently set to 30% of members\u2019 pensionable salaries.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999912237620663
          ]
        ],
        "inference_time": 0.412400484085083
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.999997779927489
          ]
        ],
        "inference_time": 1.2237889766693115
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999988527586979
          ]
        ],
        "inference_time": 0.511155366897583
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.999997303114013
          ]
        ],
        "inference_time": 0.42616724967956543
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999975415208362
          ]
        ],
        "inference_time": 0.4844183921813965
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.999997303114013
          ]
        ],
        "inference_time": 0.6265420913696289
      },
      {
        "repetition": 6,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999983759447105
          ]
        ],
        "inference_time": 0.5096373558044434
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999992103693378
          ]
        ],
        "inference_time": 0.6510493755340576
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.999997779927489
          ]
        ],
        "inference_time": 0.5785930156707764
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.9999988527586979
          ]
        ],
        "inference_time": 0.4239380359649658
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 84,
    "sentence": "So I wanted more.'",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.08948571620598839
          ]
        ],
        "inference_time": 0.39400672912597656
      },
      {
        "repetition": 1,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.08948571620598839
          ]
        ],
        "inference_time": 0.5109877586364746
      },
      {
        "repetition": 2,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.3857947224162789
          ]
        ],
        "inference_time": 0.4084007740020752
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.17872494804384026
          ]
        ],
        "inference_time": 0.40953516960144043
      },
      {
        "repetition": 4,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.33390216167518855
          ]
        ],
        "inference_time": 0.351978063583374
      },
      {
        "repetition": 5,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.18223653395559788
          ]
        ],
        "inference_time": 0.4663867950439453
      },
      {
        "repetition": 6,
        "generated_text": "90",
        "token_probs": [
          [
            "90",
            0.18223653395559788
          ]
        ],
        "inference_time": 0.42516374588012695
      },
      {
        "repetition": 7,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.3925986411712086
          ]
        ],
        "inference_time": 0.3934156894683838
      },
      {
        "repetition": 8,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.06822341000317496
          ]
        ],
        "inference_time": 0.41148924827575684
      },
      {
        "repetition": 9,
        "generated_text": "90",
        "token_probs": [
          [
            "90",
            0.2092867996070155
          ]
        ],
        "inference_time": 0.4082818031311035
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 85,
    "sentence": "Nearly half of Republicans and right-leaning independents said the US was providing too much aid to Ukraine, according to a survey by the Pew Research Center conducted late last year.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.42630690982216257
          ]
        ],
        "inference_time": 0.4399375915527344
      },
      {
        "repetition": 1,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.23508998406301454
          ]
        ],
        "inference_time": 2.044018268585205
      },
      {
        "repetition": 2,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.647250140335172
          ]
        ],
        "inference_time": 0.48330163955688477
      },
      {
        "repetition": 3,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.5902926768203147
          ]
        ],
        "inference_time": 0.4303445816040039
      },
      {
        "repetition": 4,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.6212191333653717
          ]
        ],
        "inference_time": 0.5933670997619629
      },
      {
        "repetition": 5,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.24473700906978
          ]
        ],
        "inference_time": 0.35542821884155273
      },
      {
        "repetition": 6,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.692914779842496
          ]
        ],
        "inference_time": 0.46147656440734863
      },
      {
        "repetition": 7,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.4066694992304953
          ]
        ],
        "inference_time": 0.40940332412719727
      },
      {
        "repetition": 8,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.375623443655994
          ]
        ],
        "inference_time": 0.5123121738433838
      },
      {
        "repetition": 9,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.0443381492852235
          ]
        ],
        "inference_time": 0.40848827362060547
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 86,
    "sentence": "Meanwhile, some arch-conservatives suggested it was time for McConnell to step down.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.35425629603054976
          ]
        ],
        "inference_time": 0.4082357883453369
      },
      {
        "repetition": 1,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.04677201627789608
          ]
        ],
        "inference_time": 0.4103701114654541
      },
      {
        "repetition": 2,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.24347655420599768
          ]
        ],
        "inference_time": 0.36994004249572754
      },
      {
        "repetition": 3,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.23041028309372907
          ]
        ],
        "inference_time": 0.7571654319763184
      },
      {
        "repetition": 4,
        "generated_text": "45",
        "token_probs": [
          [
            "45",
            0.0327640573867537
          ]
        ],
        "inference_time": 0.43194055557250977
      },
      {
        "repetition": 5,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.3469603554513451
          ]
        ],
        "inference_time": 0.48703885078430176
      },
      {
        "repetition": 6,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.2407531039637537
          ]
        ],
        "inference_time": 0.37851381301879883
      },
      {
        "repetition": 7,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.27589508075656755
          ]
        ],
        "inference_time": 0.4401967525482178
      },
      {
        "repetition": 8,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.16923381508605767
          ]
        ],
        "inference_time": 0.4705643653869629
      },
      {
        "repetition": 9,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.06697555658965054
          ]
        ],
        "inference_time": 0.5532312393188477
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 87,
    "sentence": "\u201cI maintain a healthy weight that preserves my facial structure and collagen.\u201d",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.3047439618588551
          ]
        ],
        "inference_time": 0.4088318347930908
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.2745577990057332
          ]
        ],
        "inference_time": 0.4100816249847412
      },
      {
        "repetition": 2,
        "generated_text": "100",
        "token_probs": [
          [
            "100",
            0.09099421874032065
          ]
        ],
        "inference_time": 0.5096843242645264
      },
      {
        "repetition": 3,
        "generated_text": "90",
        "token_probs": [
          [
            "90",
            0.20975734068134663
          ]
        ],
        "inference_time": 0.41187381744384766
      },
      {
        "repetition": 4,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.15533600473711384
          ]
        ],
        "inference_time": 0.5104496479034424
      },
      {
        "repetition": 5,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.30519512984450453
          ]
        ],
        "inference_time": 0.37046051025390625
      },
      {
        "repetition": 6,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.12155841340035463
          ]
        ],
        "inference_time": 0.4483063220977783
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.09649303084261204
          ]
        ],
        "inference_time": 0.3668222427368164
      },
      {
        "repetition": 8,
        "generated_text": "90",
        "token_probs": [
          [
            "90",
            0.29037127523902706
          ]
        ],
        "inference_time": 0.4199376106262207
      },
      {
        "repetition": 9,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.19211851627427862
          ]
        ],
        "inference_time": 0.7037661075592041
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 88,
    "sentence": "Later in a campaign speech, Trump rattled American allies in Europe when he claimed that he would encourage Russia to attack Nato allies who did not pay enough to maintain the security alliance.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4729252012468004
          ]
        ],
        "inference_time": 0.4091641902923584
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.057594585063936374
          ]
        ],
        "inference_time": 0.44379258155822754
      },
      {
        "repetition": 2,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.2183621999549845
          ]
        ],
        "inference_time": 0.6013689041137695
      },
      {
        "repetition": 3,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.10251712121127148
          ]
        ],
        "inference_time": 0.4607663154602051
      },
      {
        "repetition": 4,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.20936665141479002
          ]
        ],
        "inference_time": 0.4811530113220215
      },
      {
        "repetition": 5,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4585002442480735
          ]
        ],
        "inference_time": 0.41054534912109375
      },
      {
        "repetition": 6,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.043183778420504804
          ]
        ],
        "inference_time": 0.5110735893249512
      },
      {
        "repetition": 7,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.1984652047376752
          ]
        ],
        "inference_time": 0.5613522529602051
      },
      {
        "repetition": 8,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4005830367176162
          ]
        ],
        "inference_time": 0.7437331676483154
      },
      {
        "repetition": 9,
        "generated_text": "60",
        "token_probs": [
          [
            "60",
            0.03956600592940473
          ]
        ],
        "inference_time": 0.433635950088501
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 89,
    "sentence": "Mark made the cheeky confession on-air while hosting his Heart FM radio programme on Monday, admitting he got 'clocked' by Michelle when she found the restaurant takeaway bag in the bin.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.2490363552181903
          ]
        ],
        "inference_time": 0.5119526386260986
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.1455771748592695
          ]
        ],
        "inference_time": 0.37955451011657715
      },
      {
        "repetition": 2,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.17859251844974502
          ]
        ],
        "inference_time": 0.5409502983093262
      },
      {
        "repetition": 3,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.2832310925417337
          ]
        ],
        "inference_time": 0.4011800289154053
      },
      {
        "repetition": 4,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.39347062906166136
          ]
        ],
        "inference_time": 0.41774797439575195
      },
      {
        "repetition": 5,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.5291453436602056
          ]
        ],
        "inference_time": 0.5117218494415283
      },
      {
        "repetition": 6,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.27042816099199335
          ]
        ],
        "inference_time": 0.4094548225402832
      },
      {
        "repetition": 7,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.39347062906166136
          ]
        ],
        "inference_time": 0.4082345962524414
      },
      {
        "repetition": 8,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.24001618471890954
          ]
        ],
        "inference_time": 0.4121270179748535
      },
      {
        "repetition": 9,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.27042816099199335
          ]
        ],
        "inference_time": 0.3773918151855469
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 90,
    "sentence": "\u201cIt has my facial expressions \u2013 my eyes, lips, hair, arms, legs, chest and butt, all dimples and textures fully integrated.\u201d  Fabulous will pay for your exclusive stories.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.6006526260043691
          ]
        ],
        "inference_time": 0.4956345558166504
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5321794377049763
          ]
        ],
        "inference_time": 0.4342010021209717
      },
      {
        "repetition": 2,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.4809246676745317
          ]
        ],
        "inference_time": 0.4102966785430908
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.6006526260043691
          ]
        ],
        "inference_time": 0.4100809097290039
      },
      {
        "repetition": 4,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.19212632612134972
          ]
        ],
        "inference_time": 0.3830235004425049
      },
      {
        "repetition": 5,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.23181158345079153
          ]
        ],
        "inference_time": 0.41460394859313965
      },
      {
        "repetition": 6,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.22284440201745168
          ]
        ],
        "inference_time": 0.35166501998901367
      },
      {
        "repetition": 7,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5317671058806702
          ]
        ],
        "inference_time": 0.4866018295288086
      },
      {
        "repetition": 8,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.6042857335239722
          ]
        ],
        "inference_time": 0.5127301216125488
      },
      {
        "repetition": 9,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.4809246676745317
          ]
        ],
        "inference_time": 0.3857285976409912
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 91,
    "sentence": "Since the 2022 valuation, funding has improved.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.45617863472718156
          ]
        ],
        "inference_time": 0.432995080947876
      },
      {
        "repetition": 1,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.39997371586973895
          ]
        ],
        "inference_time": 0.39667344093322754
      },
      {
        "repetition": 2,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.2785130752847565
          ]
        ],
        "inference_time": 0.5221459865570068
      },
      {
        "repetition": 3,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.4039487526553096
          ]
        ],
        "inference_time": 0.45018696784973145
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.20774807039192575
          ]
        ],
        "inference_time": 0.4710712432861328
      },
      {
        "repetition": 5,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.2922194088853158
          ]
        ],
        "inference_time": 0.36831116676330566
      },
      {
        "repetition": 6,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.2785130752847565
          ]
        ],
        "inference_time": 0.5537562370300293
      },
      {
        "repetition": 7,
        "generated_text": "10",
        "token_probs": [
          [
            "10",
            0.2785130752847565
          ]
        ],
        "inference_time": 0.4085080623626709
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.3995666356311358
          ]
        ],
        "inference_time": 0.5125918388366699
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.34251866260207553
          ]
        ],
        "inference_time": 0.5115399360656738
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 92,
    "sentence": "He said: 'At a very young age, the local theatre in my town went to local schools to cast a load of kids to be in a professional production of Wind In The Willows.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.1004348374608693
          ]
        ],
        "inference_time": 0.4816749095916748
      },
      {
        "repetition": 1,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.641160685576252
          ]
        ],
        "inference_time": 0.43801045417785645
      },
      {
        "repetition": 2,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.6942268917553013
          ]
        ],
        "inference_time": 0.3974418640136719
      },
      {
        "repetition": 3,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.6942268917553013
          ]
        ],
        "inference_time": 0.4211862087249756
      },
      {
        "repetition": 4,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.6942748725345633
          ]
        ],
        "inference_time": 0.3424651622772217
      },
      {
        "repetition": 5,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.8804839424627088
          ]
        ],
        "inference_time": 0.4314761161804199
      },
      {
        "repetition": 6,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.1004348374608693
          ]
        ],
        "inference_time": 0.453563928604126
      },
      {
        "repetition": 7,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.6742974285591528
          ]
        ],
        "inference_time": 0.4097781181335449
      },
      {
        "repetition": 8,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.6615718261093892
          ]
        ],
        "inference_time": 0.5106117725372314
      },
      {
        "repetition": 9,
        "generated_text": "0",
        "token_probs": [
          [
            "0",
            0.6615718261093892
          ]
        ],
        "inference_time": 0.4091362953186035
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 93,
    "sentence": "RULE 9: LOVE  According to Gina, you should love yourself, love your life, love others.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.24838855818268935
          ]
        ],
        "inference_time": 0.5145857334136963
      },
      {
        "repetition": 1,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.3977592173897015
          ]
        ],
        "inference_time": 0.46404552459716797
      },
      {
        "repetition": 2,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.1139599305700456
          ]
        ],
        "inference_time": 6.859303712844849
      },
      {
        "repetition": 3,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.45189566581050794
          ]
        ],
        "inference_time": 0.3380100727081299
      },
      {
        "repetition": 4,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.2595996369403638
          ]
        ],
        "inference_time": 0.3432774543762207
      },
      {
        "repetition": 5,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.21468431836542184
          ]
        ],
        "inference_time": 0.4384641647338867
      },
      {
        "repetition": 6,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.2733756619466882
          ]
        ],
        "inference_time": 1.1776318550109863
      },
      {
        "repetition": 7,
        "generated_text": "30",
        "token_probs": [
          [
            "30",
            0.4353487095786733
          ]
        ],
        "inference_time": 0.5117142200469971
      },
      {
        "repetition": 8,
        "generated_text": "40",
        "token_probs": [
          [
            "40",
            0.239907883526892
          ]
        ],
        "inference_time": 0.41001105308532715
      },
      {
        "repetition": 9,
        "generated_text": "20",
        "token_probs": [
          [
            "20",
            0.3154893805585301
          ]
        ],
        "inference_time": 0.4089629650115967
      }
    ],
    "predicted_label": 0
  },
  {
    "sample_idx": 94,
    "sentence": "Anne Hathaway is not it.",
    "true_label": 1,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.6343129139976756
          ]
        ],
        "inference_time": 0.8161311149597168
      },
      {
        "repetition": 1,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.24683357930748517
          ]
        ],
        "inference_time": 0.4099586009979248
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.16526792248816619
          ]
        ],
        "inference_time": 0.4094834327697754
      },
      {
        "repetition": 3,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.22842802023438505
          ]
        ],
        "inference_time": 0.4107472896575928
      },
      {
        "repetition": 4,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5541244678319279
          ]
        ],
        "inference_time": 0.39018940925598145
      },
      {
        "repetition": 5,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.24683357930748517
          ]
        ],
        "inference_time": 0.42677831649780273
      },
      {
        "repetition": 6,
        "generated_text": "90",
        "token_probs": [
          [
            "90",
            0.07370681200975393
          ]
        ],
        "inference_time": 0.3983774185180664
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.17129320397580536
          ]
        ],
        "inference_time": 0.5239195823669434
      },
      {
        "repetition": 8,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.4492448173038371
          ]
        ],
        "inference_time": 0.40912485122680664
      },
      {
        "repetition": 9,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.15095593047971995
          ]
        ],
        "inference_time": 0.6800532341003418
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 95,
    "sentence": "As she watches her granddaughters play, Wairimu wonders if things could have played out differently.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.1991248439084303
          ]
        ],
        "inference_time": 0.36546945571899414
      },
      {
        "repetition": 1,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.2692870450130274
          ]
        ],
        "inference_time": 0.47449588775634766
      },
      {
        "repetition": 2,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.6133477175241061
          ]
        ],
        "inference_time": 0.4232754707336426
      },
      {
        "repetition": 3,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.6155910836414891
          ]
        ],
        "inference_time": 0.6913642883300781
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5700807127456144
          ]
        ],
        "inference_time": 0.40262579917907715
      },
      {
        "repetition": 5,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.2897586492793883
          ]
        ],
        "inference_time": 0.43956971168518066
      },
      {
        "repetition": 6,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.29208692556638105
          ]
        ],
        "inference_time": 0.5128986835479736
      },
      {
        "repetition": 7,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5665332296046208
          ]
        ],
        "inference_time": 0.7376275062561035
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.5779719546897107
          ]
        ],
        "inference_time": 0.3901362419128418
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.31591868126320916
          ]
        ],
        "inference_time": 0.6118154525756836
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 96,
    "sentence": "RULE 5: ATTITUDE IS EVERYTHING  Gina stressed the importance of \"thinking yourself young\" as she suggested: \"You are what you think.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5329970548935273
          ]
        ],
        "inference_time": 0.334367036819458
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5293725084930461
          ]
        ],
        "inference_time": 0.6874487400054932
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.1622433170468846
          ]
        ],
        "inference_time": 0.5116617679595947
      },
      {
        "repetition": 3,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.18649544406910862
          ]
        ],
        "inference_time": 0.36416125297546387
      },
      {
        "repetition": 4,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5818935995387692
          ]
        ],
        "inference_time": 0.38562941551208496
      },
      {
        "repetition": 5,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.18891319283029287
          ]
        ],
        "inference_time": 0.37639403343200684
      },
      {
        "repetition": 6,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.1819037830602
          ]
        ],
        "inference_time": 0.9200718402862549
      },
      {
        "repetition": 7,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.5770576227401423
          ]
        ],
        "inference_time": 0.4097740650177002
      },
      {
        "repetition": 8,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.19343870067674918
          ]
        ],
        "inference_time": 0.41845273971557617
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.18891319283029287
          ]
        ],
        "inference_time": 0.5045669078826904
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 97,
    "sentence": "However, Variety wasn't so gushing - and said the drama 'should have stayed in quarantine'.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.12502861278951408
          ]
        ],
        "inference_time": 0.4093015193939209
      },
      {
        "repetition": 1,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5553573670253348
          ]
        ],
        "inference_time": 0.40819430351257324
      },
      {
        "repetition": 2,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.10742516150005321
          ]
        ],
        "inference_time": 0.4074273109436035
      },
      {
        "repetition": 3,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5479027288961617
          ]
        ],
        "inference_time": 0.5116393566131592
      },
      {
        "repetition": 4,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.2511069463681459
          ]
        ],
        "inference_time": 0.6143360137939453
      },
      {
        "repetition": 5,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.545550050268645
          ]
        ],
        "inference_time": 0.4090752601623535
      },
      {
        "repetition": 6,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.18992384608541119
          ]
        ],
        "inference_time": 0.5119223594665527
      },
      {
        "repetition": 7,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.08311215441237113
          ]
        ],
        "inference_time": 0.4096100330352783
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.22403668826445927
          ]
        ],
        "inference_time": 0.40953707695007324
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5447525612149918
          ]
        ],
        "inference_time": 0.4057614803314209
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 98,
    "sentence": "The Ohio senator JD Vance, another Trump loyalist, claimed the effort to replenish Ukraine\u2019s war chest was a \u201cplot\u201d by the Republican establishment to \u201cstop the election of Donald Trump\u201d.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "80",
        "token_probs": [
          [
            "80",
            0.0911818977260989
          ]
        ],
        "inference_time": 0.5356993675231934
      },
      {
        "repetition": 1,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.7400209813379492
          ]
        ],
        "inference_time": 0.6940672397613525
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.23986558896717597
          ]
        ],
        "inference_time": 1.1263997554779053
      },
      {
        "repetition": 3,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.8258560830571395
          ]
        ],
        "inference_time": 0.6143844127655029
      },
      {
        "repetition": 4,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.7348191968398691
          ]
        ],
        "inference_time": 0.40929436683654785
      },
      {
        "repetition": 5,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.7348191968398691
          ]
        ],
        "inference_time": 0.4090080261230469
      },
      {
        "repetition": 6,
        "generated_text": "85",
        "token_probs": [
          [
            "85",
            0.7637652952712886
          ]
        ],
        "inference_time": 0.4092686176300049
      },
      {
        "repetition": 7,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.13272250327444654
          ]
        ],
        "inference_time": 0.41095948219299316
      },
      {
        "repetition": 8,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.10893054188076962
          ]
        ],
        "inference_time": 0.5120368003845215
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.10779224596506266
          ]
        ],
        "inference_time": 0.35930848121643066
      }
    ],
    "predicted_label": 1
  },
  {
    "sample_idx": 99,
    "sentence": "It\u2019s made me realise how much we take older people for granted.\u201d  Both Brunero and Hamilton can see how mutually beneficial a multigenerational community such as Ayrton House could be.",
    "true_label": 0,
    "repetitions": [
      {
        "repetition": 0,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.36092161861893723
          ]
        ],
        "inference_time": 0.4559965133666992
      },
      {
        "repetition": 1,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.4364157585034751
          ]
        ],
        "inference_time": 0.4092848300933838
      },
      {
        "repetition": 2,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.5024115287572005
          ]
        ],
        "inference_time": 0.409451961517334
      },
      {
        "repetition": 3,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.41583274192638436
          ]
        ],
        "inference_time": 0.40720391273498535
      },
      {
        "repetition": 4,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.4417367780508845
          ]
        ],
        "inference_time": 0.34097838401794434
      },
      {
        "repetition": 5,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.4479342541892292
          ]
        ],
        "inference_time": 0.48018956184387207
      },
      {
        "repetition": 6,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.4396627588932406
          ]
        ],
        "inference_time": 0.5971784591674805
      },
      {
        "repetition": 7,
        "generated_text": "65",
        "token_probs": [
          [
            "65",
            0.07698148137123968
          ]
        ],
        "inference_time": 0.5287384986877441
      },
      {
        "repetition": 8,
        "generated_text": "70",
        "token_probs": [
          [
            "70",
            0.442298085726776
          ]
        ],
        "inference_time": 0.438643217086792
      },
      {
        "repetition": 9,
        "generated_text": "75",
        "token_probs": [
          [
            "75",
            0.507050285566375
          ]
        ],
        "inference_time": 0.7900552749633789
      }
    ],
    "predicted_label": 1
  }
]